{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43c5ca6a-125a-4118-b3d2-1e45626d1212",
   "metadata": {},
   "source": [
    "# Current Trends in Bioinformatics Software Development and Archiving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3dd4e1-df0d-4f4f-87ec-c6b495d1d050",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2092ef92-81df-4128-a1fa-f728c558bac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import xmltodict\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "sys.path.append('../scripts')\n",
    "import pbmd_tools as pbmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cef688b-1a6a-4d7a-b017-1ecee4ae40e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.9.16\n",
      "IPython version      : 8.11.0\n",
      "\n",
      "Compiler    : GCC 11.2.0\n",
      "OS          : Linux\n",
      "Release     : 5.19.0-45-generic\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 4\n",
      "Architecture: 64bit\n",
      "\n",
      "jupyterlab: 3.5.3\n",
      "\n",
      "re        : 2.2.1\n",
      "numpy     : 1.23.5\n",
      "pandas    : 1.5.3\n",
      "sys       : 3.9.16 (main, Mar  8 2023, 14:00:05) \n",
      "[GCC 11.2.0]\n",
      "xmltodict : 0.12.0\n",
      "matplotlib: 3.7.1\n",
      "requests  : 2.28.2\n",
      "json      : 2.0.9\n",
      "\n",
      "Watermark: 2.3.1\n",
      "\n",
      "conda environment: bioinfosoft\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark --python --machine\n",
    "# Python packages versions\n",
    "%watermark --packages jupyterlab --iversions --watermark\n",
    "# conda environment name\n",
    "%watermark --conda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6a89ef-d688-4096-8a94-1d10b97f533c",
   "metadata": {},
   "source": [
    "### Import tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e66c109-89bd-4f6f-8d99-89ed18a4be3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pbmd.read_tokens(\"../.env\")\n",
    "GITHUB_TOKEN = os.environ.get(\"GITHUB_TOKEN\")\n",
    "PUBMED_TOKEN = os.environ.get(\"PUBMED_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0068b37-9ae4-444b-874d-2cd5e173b7e5",
   "metadata": {},
   "source": [
    "## 1. PubMed API Entrez Interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81134853-e4da-4e60-aff1-f34443f4ae7b",
   "metadata": {},
   "source": [
    "First of all we are going to explore PubMed in order to find out how many publications for each among 5 forges are there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "188978bd-1f8f-4fc5-9928-9157a341cda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_github = []\n",
    "queries_gitlab = []\n",
    "queries_sourceforge = []\n",
    "queries_googlecode = []\n",
    "queries_bitbucket = []\n",
    "\n",
    "#creating queries for every forge and every year\n",
    "for year in range(2009, 2023):\n",
    "    queries_github.append(f'((github.com[Title/Abstract])) AND ((\"{year}/01/01\"[Date - Publication] : \"{year}/12/31\"[Date - Publication]))')\n",
    "    queries_gitlab.append(f'((https://gitlab[Title/Abstract])) OR ((http://gitlab[Title/Abstract])) OR ((gitlab.[Title/Abstract])) AND ((\"{year}/01/01\"[Date - Publication] : \"{year}/12/31\"[Date - Publication]))')\n",
    "    queries_sourceforge.append(f'((sourceforge.net[Title/Abstract])) AND ((\"{year}/01/01\"[Date - Publication] : \"{year}/12/31\"[Date - Publication]))')\n",
    "    queries_googlecode.append(f'((googlecode) OR (\"code.google.com\") AND (\"{year}/01/01\"[Date - Publication] : \"{year}/12/31\"[Date - Publication]))')\n",
    "    queries_bitbucket.append(f'((bitbucket.org[Title/Abstract]) AND (\"{year}/01/01\"[Date - Publication] : \"{year}/12/31\"[Date - Publication]))')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "975bb2c5-a417-48a3-adcd-198c2cb08332",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:08<00:00,  1.66it/s]\n",
      "100%|██████████| 14/14 [00:08<00:00,  1.63it/s]\n",
      "100%|██████████| 14/14 [00:08<00:00,  1.57it/s]\n",
      "100%|██████████| 14/14 [00:09<00:00,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10861 articles with 'github.com' found in PubMed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#dictionaries for stocking the number of articles for each forge for each year\n",
    "#example: {'2009': 0, '2010': 5, '2011': 15, ... }\n",
    "\n",
    "PMIDs = []\n",
    "PMIDs_all = []\n",
    "\n",
    "stats_github = pbmd.get_forges_stat(queries_github, PMIDs)\n",
    "stats_gitlab = pbmd.get_forges_stat(queries_gitlab, PMIDs_all)\n",
    "stats_sourceforge = pbmd.get_forges_stat(queries_sourceforge, PMIDs_all)\n",
    "stats_googlecode = pbmd.get_forges_stat(queries_googlecode, PMIDs_all)\n",
    "stats_bitbucket = pbmd.get_forges_stat(queries_bitbucket, PMIDs_all)\n",
    "\n",
    "print(f\"\\n{len(PMIDs)} articles with 'github.com' found in PubMed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e968d76d-0ce9-460f-80c4-1803faebded5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the statistics to reuse it in another notebook\n",
    "\n",
    "with open(\"../data/PMIDs.txt\", \"w\") as f:\n",
    "    for PMID in PMIDs:\n",
    "        f.write(str(PMID)+\"\\n\")\n",
    "with open(\"../data/stats_github.json\", \"w\") as f:\n",
    "    json.dump(stats_github, f)\n",
    "with open(\"../data/stats_gitlab.json\", \"w\") as f:\n",
    "    json.dump(stats_gitlab, f)\n",
    "with open(\"../data/stats_sourceforge.json\", \"w\") as f:\n",
    "    json.dump(stats_sourceforge, f)    \n",
    "with open(\"../data/stats_googlecode.json\", \"w\") as f:\n",
    "    json.dump(stats_googlecode, f)\n",
    "with open(\"../data/stats_bitbucket.json\", \"w\") as f:\n",
    "    json.dump(stats_bitbucket, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "98176cc7-615e-4060-84e2-f2b2dd617b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pubmed.ncbi.nlm.nih.gov/26262258/ - No DOI in PubMed although there is one in the full text of the article (not from ArXiv), and there are a lot of them\n",
    "# https://pubmed.ncbi.nlm.nih.gov/28269829/ - they give a wrong link https://github.com/SBU-BMI/imageboxs://github.com/SBU-BMI/imagebox but if you use this link :\n",
    "# https://github.com/SBU-BMI/imagebox it works. Yet, i am not sure that it is actually what we are looking for since they also provide another link to github.io \n",
    "# (also incorect) and i think it's more likely that their code is there\n",
    "# PMID = 36789260 - 2 links\n",
    "# https://github.com/tyqGitHub/TYQ/tree/master/GACNNMDA - ????\n",
    "# https://github.com/mofradlab - ?????? (PMID 36786404)\n",
    "# PMID = 26124555 - a space in the link\n",
    "# PMID = 24324759, 22151646 - no space after link\n",
    "# PMID = 23849037 - why + in the end ?\n",
    "# PMID = 36315552 - super smart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4aac81-c8b6-4712-98c2-f0a3e9ff1563",
   "metadata": {},
   "source": [
    "Next we will use API PubMed to gather the information about each article such as the publication date, the doi, the abstract, the title of the article and the journal. We will then analyse this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8425aae-1da2-443d-a325-dc4a1fbe4814",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b5aead-fa36-41c6-af77-8af8138b0ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                            | 49/10858 [00:42<2:15:43,  1.33it/s]"
     ]
    }
   ],
   "source": [
    "#API Pubmed rate limit is 10 request per second with a token and 3 request par second without it\n",
    "\n",
    "#count = 0\n",
    "for PMID in tqdm(PMIDs):\n",
    "    #count += 1\n",
    "    #if count % 10 == 0:\n",
    "    #    time.sleep(1)\n",
    "    \n",
    "    try:\n",
    "        summary = pbmd.get_summary(PMID, PUBMED_TOKEN, \"../data/log_files/status.txt\")\n",
    "    except:\n",
    "        try:\n",
    "            summary = pbmd.get_summary(PMID, PUBMED_TOKEN, \"../data/log_files/status.txt\")\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "    abstract = pbmd.get_abstract_from_summary(summary, \"../data/log_files/status.txt\")\n",
    "    pubdate = pbmd.get_pubdate_from_summary(summary, \"../data/log_files/status.txt\")\n",
    "    title = pbmd.get_title_from_summary(summary, \"../data/log_files/status.txt\")\n",
    "    journal = pbmd.get_journal_from_summary(summary, \"../data/log_files/status.txt\")\n",
    "    doi = pbmd.get_doi_from_summary(summary, \"../data/log_files/status.txt\")  \n",
    "\n",
    "    results.append((PMID, pubdate, doi, journal, title, abstract))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e11bc34d-7377-4167-8d80-48952e78323a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(results)\n",
    "df = df.rename(columns = {0: 'PMID', 1: 'PubDate', 2: 'DOI', 3: 'Journal', 4: 'Title', 5: 'Abstract'})\n",
    "df = df.drop_duplicates(subset = 'PMID')\n",
    "df = df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "9a6c9a6e-9a56-4117-b4c9-28bec1d25313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records without publication date is: 59\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of records without publication date is: {len(df[df['PubDate'].isnull()])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "94f8544e-f411-40c6-bd35-318d762992e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/articles.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d566e858-dc91-44d1-9e85-13a0fc89f892",
   "metadata": {},
   "source": [
    "## 2. Geting links from the obtained data using regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5f1cfe1c-42eb-4958-a13c-8c7d43136ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/articles.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b8ce85de-20f7-4211-830b-4c6e01e0eb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GitHub_link_raw'] = df['Abstract'].astype(str).apply(pbmd.get_link_from_abstract)\n",
    "df['GitHub_link_clean'] = df['GitHub_link_raw'].astype(str).apply(pbmd.clean_link)\n",
    "df['GitHub_owner'] = df['GitHub_link_clean'].apply(pbmd.get_owner_from_link)\n",
    "df['GitHub_repo'] = df['GitHub_link_clean'].apply(pbmd.get_repo_from_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "964e174c-558c-445e-abec-a0b0c2c16b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records with weird abstracts leading to inability to extract a link: 6\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of records with weird abstracts leading to inability to extract a link: {len(df[df['GitHub_owner'].isna()])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1d2ae2ce-d877-42af-84d7-96db53d9dae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records without a repository name: 251\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of records without a repository name: {len(df[df['GitHub_repo'].isna()])-len(df[df['GitHub_owner'].isna()])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "84639824-a280-494b-b8e8-d2a5b6981006",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/articles.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d124283b-c8d7-4c6a-913f-f64f2390d66a",
   "metadata": {},
   "source": [
    "## 3. GitHub API Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "160e77c7-4980-4dbc-bc92-ff9319cd9480",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/articles.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f6bfbf59-53a2-4a9e-93cd-f509588406a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10623"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PMIDs = df['PMID'][df['GitHub_repo'].notna()].to_list()\n",
    "len(PMIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "36dd1992-56f7-42a8-95ae-810217f93e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 905/905 [05:39<00:00,  2.67it/s]\n"
     ]
    }
   ],
   "source": [
    "for PMID in tqdm(PMIDs):\n",
    "\n",
    "    with open(\"../data/log_files/gitstat.txt\", \"a\") as f:\n",
    "        f.write(f\"\\n\\n PMID: {PMID}, GitHub link: {df[df['PMID'] == PMID]['GitHub_link_clean'].values[0]}\")\n",
    "\n",
    "    info = pbmd.get_repo_info(df[df['PMID']==PMID]['GitHub_owner'].values[0], \n",
    "                              df[df['PMID']==PMID]['GitHub_repo'].values[0], \n",
    "                              GITHUB_TOKEN, \"../data/log_files/gitstat.txt\")\n",
    "\n",
    "    if info[\"status\"]: \n",
    "        idx = df.index[df['PMID'] == PMID][0]\n",
    "    else:      \n",
    "        time.sleep(3600)      \n",
    "        info = pbmd.get_repo_info(df[df['PMID']==PMID]['GitHub_owner'].values[0], \n",
    "                                  df[df['PMID']==PMID]['GitHub_repo'].values[0], \n",
    "                                  GITHUB_TOKEN, \"../data/log_files/gitstat.txt\")\n",
    "\n",
    "    df.loc[idx, \"Repo_created_at\"] = pbmd.get_repo_date_created(info)\n",
    "    df.loc[idx, \"Repo_updated_at\"] = pbmd.get_repo_date_updated(info)\n",
    "    df.loc[idx, \"Fork\"] = pbmd.is_fork(info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682e0960-eefb-4676-a049-e22cca92418f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "758"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PMIDs = df['PMID'][df['Repo_created_at'].isna()].to_list()\n",
    "len(PMIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "fe532216-f508-4ff9-a16e-3bb957b1e344",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/articles.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad760f81-0cf8-4b5d-9015-bda6ac2d2487",
   "metadata": {},
   "source": [
    "## 4. Software Heritage API interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6aa51fd7-bd8c-472f-b659-edb3ded49461",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/articles.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca4481bb-3767-415c-bc0d-d460cdc7c5a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10847"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PMIDs = df['PMID'][df['GitHub_owner'].notna()].to_list()\n",
    "len(PMIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d60a2e7-1d01-4b23-8500-221e4a29c748",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10847/10847 [19:47<00:00,  9.13it/s]  \n"
     ]
    }
   ],
   "source": [
    "for PMID in tqdm(PMIDs):\n",
    "    \n",
    "    try:\n",
    "        info = pbmd.check_is_in_softwh(df[df['PMID']==PMID]['GitHub_link_clean'].values[0])\n",
    "    except:\n",
    "        try:\n",
    "            info = pbmd.check_is_in_softwh(df[df['PMID']==PMID]['GitHub_link_clean'].values[0])\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    idx = df.index[df['PMID'] == PMID][0]\n",
    "\n",
    "    df.loc[idx, \"In_SoftWH\"] = pbmd.is_in_softwh(info)\n",
    "    df.loc[idx, \"Archived\"] = pbmd.get_date_archived(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3954853c-f227-4a5d-8c24-99694669cdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/articles.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d478c7b-9a74-42fb-b71d-1c594eefdadc",
   "metadata": {},
   "source": [
    "## Unresolved links analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1050e30a-a3d8-435a-a015-901296b70247",
   "metadata": {},
   "source": [
    "The repositories that we were anable to access via extracted links were analysed manualy to determine the reason. The following reasons were found:\n",
    "1. Error in the link\n",
    "2. Deleted repository or user\n",
    "3. Renamed repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b597f0b6-78f4-4736-9a89-ac0191b0c702",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('no_info2.tsv', sep='\\t',usecols=['PMID', 'PubDate', 'DOI', 'Journal', 'Title', 'Abstract', 'Issue', 'GitHub_link_clean','Correct_link'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "6b70ec1b-96dd-43d1-9876-4dac90c542a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles with a wrong link (either a space in the link, or no space after link, etc) : 58\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of articles with a wrong link (either a space in the link, or no space after link, etc) : {len(df1[df1['Issue'] == 'wrong link'])}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "b34f0e2f-1e42-46ff-ae71-f984e2a433a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles with a renamed repository : 11\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of articles with a renamed repository : {len(df1[df1['Issue'] == 'renamed'])}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "a8db6bd5-d473-4a5f-85ab-e8b179186b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles with a deleted repository : 146\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of articles with a deleted repository : {len(df1[df1['Issue'] == 'owner deleted']) + len(df1[df1['Issue'] == 'repo deleted'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fd77b8-8cac-45be-af2f-928dd2d35cc5",
   "metadata": {},
   "source": [
    "Resolving unresolved but existing links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "3db1fcb0-8066-4c19-a853-34ad54833439",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.loc[df['Correct_link'].notna(),'GitHub_owner'] = df1.loc[df['Correct_link'].notna(),'Correct_link'].apply(pbmd.get_owner_from_link)\n",
    "df1.loc[df['Correct_link'].notna(),'GitHub_repo'] = df1.loc[df['Correct_link'].notna(),'Correct_link'].apply(pbmd.get_repo_from_link)\n",
    "\n",
    "df1.loc[df['Correct_link'].isna(),'GitHub_owner'] = df1.loc[df['Correct_link'].isna(),'GitHub_link_clean'].apply(pbmd.get_owner_from_link)\n",
    "df1.loc[df['Correct_link'].isna(),'GitHub_repo'] = df1.loc[df['Correct_link'].isna(),'GitHub_link_clean'].apply(pbmd.get_repo_from_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "35967c10-c389-4542-9dfb-cca1c8a61306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PMIDs = df1['PMID'][df1['GitHub_repo'].notna()].to_list()\n",
    "len(PMIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "2e7d124d-9a2b-443b-8c63-7ee3cbecc7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 215/215 [01:05<00:00,  3.30it/s]\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for PMID in tqdm(PMIDs):\n",
    "    count += 1\n",
    "    if count % 5000 == 0:\n",
    "        time.sleep(3600)\n",
    "    \n",
    "    with open(\"gitstat.txt\", \"a\") as f:\n",
    "        f.write(f\"\\n\\n PMID: {PMID}, GitHub link: {df1[df1['PMID'] == PMID]['Correct_link'].values[0]}\")\n",
    "\n",
    "    info = pbmd.get_repo_info(df1[df1['PMID']==PMID]['GitHub_owner'].values[0], df1[df1['PMID']==PMID]['GitHub_repo'].values[0], GITHUB_TOKEN, \"gitstat.txt\")\n",
    "\n",
    "    idx = df1.index[df['PMID'] == PMID][0]\n",
    "\n",
    "    df1.loc[idx, \"Repo_created_at\"] = pbmd.get_repo_date_created(info)\n",
    "    df1.loc[idx, \"Repo_updated_at\"] = pbmd.get_repo_date_updated(info)\n",
    "    df1.loc[idx, \"Fork\"] = pbmd.is_fork(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "ae1722cd-c089-456a-97b4-5267d944a463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PMIDs = df1['PMID'][df1['Correct_link'].notna()].to_list()\n",
    "len(PMIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "3ea729a9-2a5a-4d81-99c8-7e2718000724",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 69/69 [00:13<00:00,  5.03it/s]\n"
     ]
    }
   ],
   "source": [
    "for PMID in tqdm(PMIDs):\n",
    "    \n",
    "    info = pbmd.check_is_in_softwh(df1[df1['PMID']==PMID]['Correct_link'].values[0])\n",
    "\n",
    "    idx = df1.index[df1['PMID'] == PMID][0]\n",
    "    \n",
    "    df1.loc[idx, \"In_SoftWH\"] = pbmd.is_in_softwh(info)\n",
    "    df1.loc[idx, \"Archived\"] = pbmd.get_date_archived(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "d3c3010b-1b18-4875-bf57-c3e100883ef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PMIDs = df1['PMID'][df1['Correct_link'].isna()].to_list()\n",
    "len(PMIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "0d615f28-b18d-4cd0-9407-5d6e88b9e7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 146/146 [00:56<00:00,  2.60it/s]\n"
     ]
    }
   ],
   "source": [
    "for PMID in tqdm(PMIDs):\n",
    "    \n",
    "    info = pbmd.check_is_in_softwh(df1[df1['PMID']==PMID]['GitHub_link_clean'].values[0])\n",
    "\n",
    "    idx = df1.index[df1['PMID'] == PMID][0]\n",
    "    \n",
    "    df1.loc[idx, \"In_SoftWH\"] = pbmd.is_in_softwh(info)\n",
    "    df1.loc[idx, \"Archived\"] = pbmd.get_date_archived(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "414b497b-bf2c-432e-86c7-cfe37b3af1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repositories that are forks : 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Repositories that are forks : {len(df1[df1['Fork'] == 1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "2433e02b-40b0-4b61-8636-a35d3954f887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not in SoftWH : 118\n"
     ]
    }
   ],
   "source": [
    "print(f\"Not in SoftWH : {len(df1[df1['In_SoftWH'] == 0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b561b266-3336-4238-8827-87c3bef2740d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In SoftWH : 97\n"
     ]
    }
   ],
   "source": [
    "print(f\"In SoftWH : {len(df1[df1['In_SoftWH'] == 1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fad432-e0f1-4cb4-991b-a88ca809422d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Were deleted but archived in SoftWH : 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nadia\\AppData\\Local\\Temp\\ipykernel_9668\\3996960915.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  print(f\"Were deleted but archived in SoftWH : {len(df[df['Correct_link'].isna()][df['In_SoftWH'] == 1])}\")\n"
     ]
    }
   ],
   "source": [
    "print(f\"Were deleted but archived in SoftWH : {len(df1[df1['Correct_link'].isna()][df1['In_SoftWH'] == 1])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
