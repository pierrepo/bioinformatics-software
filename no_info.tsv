PMID	PubDate	DOI	Journal	Title	Abstract	GitHub_link_raw	GitHub_link_clean	GitHub_owner	GitHub_repo	Repo_created_at	Repo_updated_at	Fork	In_SoftWH	Archived	Issue	Correct_link
28269829	07/17/2017		AMIA ... Annual Symposium proceedings. AMIA Symposium	"Safe ""cloudification"" of large images through picker APIs."	"The ""Box model"" allows users with no particular training in informatics, or access to specialized infrastructure, operate generic cloud computing resources through a temporary URI dereferencing mechanism known as ""drop-file-picker API"" (""picker API"" for sort). This application programming interface (API) was popularized in the web app development community by DropBox, and is now a consumer-facing feature of all major cloud computing platforms such as Box.com, Google Drive and Amazon S3. This reports describes a prototype web service application that uses picker APIs to expose a new, ""cloudified"", API tailored for image analysis, without compromising the private governance of the data exposed. In order to better understand this cross-platform cloud computing landscape, we first measured the time for both transfer and traversing of large image files generated by whole slide imaging (WSI) in Digital Pathology. The verification that there is extensive interconnectivity between cloud resources let to the development of a prototype software application that exposes an image-traversing REST API to image files stored in any of the consumer-facing ""boxes"". In summary, an image file can be upload/synchronized into a any cloud resource with a file picker API and the prototype service described here will expose an HTTP REST API that remains within the safety of the user's own governance. The open source prototype is publicly available at sbu-bmi.github.io/imagebox. Availability The accompanying prototype application is made publicly available, fully functional, with open source, at http://sbu-bmi.github.io/imagebox://sbu-bmi.github.io/imagebox. An illustrative webcasted use of this Web App is included with the project codebase at https://github.com/SBU-BMI/imageboxs://github.com/SBU-BMI/imagebox."	github.com/SBU-BMI/imageboxs	https://github.com/SBU-BMI/imageboxs/	SBU-BMI	imageboxs			0	0		repo deleted	
33691015	04/21/2021		Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing	AeQTL: eQTL analysis using region-based aggregation of rare genomic variants.	"Concurrently available genomic and transcriptomic data from large cohorts provide opportunities to discover expression quantitative trait loci (eQTLs)-genetic variants associated with gene expression changes. However, the statistical power of detecting rare variant eQTLs is often limited and most existing eQTL tools are not compatible with sequence variant file formats. We have developed AeQTL (Aggregated eQTL), a software tool that performs eQTL analysis on variants aggregated according to user-specified regions and is designed to accommodate standard genomic files. AeQTL consistently yielded similar or higher powers for identifying rare variant eQTLs than single-variant tests. Using AeQTL, we discovered that aggregated rare germline truncations in cis exomic regions are significantly associated with the expression of BRCA1 and SLC25A39 in breast tumors. In a somatic mutation pan-cancer analysis, aggregated mutations of those predicted to be missense versus truncations were differentially associated with gene expressions of cancer drivers, and somatic truncation eQTLs were further identified as a new multi-omic classifier of oncogenes versus tumor-suppressor genes. AeQTL is easy to use and customize, allowing a broad application for discovering rare variants, including coding and noncoding variants, associated with gene expression. AeQTL is implemented in Python and the source code is freely available at https://github.com/Huan-glab/AeQTL under the MIT license."	github.com/Huan-glab/AeQTL	https://github.com/Huan-glab/AeQTL/	Huan-glab	AeQTL			0	0		owner deleted	
35239482	03/15/2022	10.1109/TIP.2022.3154614	IEEE transactions on image processing : a publication of the IEEE Signal Processing Society	TDPN: Texture and Detail-Preserving Network for Single Image Super-Resolution.	"Single image super-resolution (SISR) using deep convolutional neural networks (CNNs) achieves the state-of-the-art performance. Most existing SISR models mainly focus on pursuing high peak signal-to-noise ratio (PSNR) and neglect textures and details. As a result, the recovered images are often perceptually unpleasant. To address this issue, in this paper, we propose a texture and detail-preserving network (TDPN), which focuses not only on local region feature recovery but also on preserving textures and details. Specifically, the high-resolution image is recovered from its corresponding low-resolution input in two branches. First, a multi-reception field based branch is designed to let the network fully learn local region features by adaptively selecting local region features in different reception fields. Then, a texture and detail-learning branch supervised by the textures and details decomposed from the ground-truth high resolution image is proposed to provide additional textures and details for the super-resolution process to improve the perceptual quality. Finally, we introduce a gradient loss into the SISR field and define a novel hybrid loss to strengthen boundary information recovery and to avoid overly smooth boundary in the final recovered high-resolution image caused by using only the MAE loss. More importantly, the proposed method is model-agnostic, which can be applied to most off-the-shelf SISR networks. The experimental results on public datasets demonstrate the superiority of our TDPN on most state-of-the-art SISR methods in PSNR, SSIM and perceptual quality. We will share our code on https://github.com/tocaiqing/TDPN."	github.com/tocaiqing/TDPN.	https://github.com/tocaiqing/TDPN/	tocaiqing	TDPN			0	0		repo deleted	
37126636	05/01/2023	10.1109/TNNLS.2023.3264730	IEEE transactions on neural networks and learning systems	BViT: Broad Attention-Based Vision Transformer.	"Recent works have demonstrated that transformer can achieve promising performance in computer vision, by exploiting the relationship among image patches with self-attention. They only consider the attention in a single feature layer, but ignore the complementarity of attention in different layers. In this article, we propose broad attention to improve the performance by incorporating the attention relationship of different layers for vision transformer (ViT), which is called BViT. The broad attention is implemented by broad connection and parameter-free attention. Broad connection of each transformer layer promotes the transmission and integration of information for BViT. Without introducing additional trainable parameters, parameter-free attention jointly focuses on the already available attention information in different layers for extracting useful information and building their relationship. Experiments on image classification tasks demonstrate that BViT delivers superior accuracy of 75.0%/81.6% top-1 accuracy on ImageNet with 5M/22M parameters. Moreover, we transfer BViT to downstream object recognition benchmarks to achieve 98.9% and 89.9% on CIFAR10 and CIFAR100, respectively, that exceed ViT with fewer parameters. For the generalization test, the broad attention in Swin Transformer, T2T-ViT and LVT also brings an improvement of more than 1%. To sum up, broad attention is promising to promote the performance of attention-based models. Code and pretrained models are available at https://github.com/DRL/BViT."	github.com/DRL/BViT.	https://github.com/DRL/BViT/	DRL	BViT			0	0		repo deleted	
33831109	09/23/2021	10.1371/journal.pone.0249957	PloS one	A computational lens into how music characterizes genre in film.	"Film music varies tremendously across genre in order to bring about different responses in an audience. For instance, composers may evoke passion in a romantic scene with lush string passages or inspire fear throughout horror films with inharmonious drones. This study investigates such phenomena through a quantitative evaluation of music that is associated with different film genres. We construct supervised neural network models with various pooling mechanisms to predict a film's genre from its soundtrack. We use these models to compare handcrafted music information retrieval (MIR) features against VGGish audio embedding features, finding similar performance with the top-performing architectures. We examine the best-performing MIR feature model through permutation feature importance (PFI), determining that mel-frequency cepstral coefficient (MFCC) and tonal features are most indicative of musical differences between genres. We investigate the interaction between musical and visual features with a cross-modal analysis, and do not find compelling evidence that music characteristic of a certain genre implies low-level visual features associated with that genre. Furthermore, we provide software code to replicate this study at https://github.com/usc-sail/mica-music-in-media. This work adds to our understanding of music's use in multi-modal contexts and offers the potential for future inquiry into human affective experiences."	github.com/usc-sail/mica-music-in-media.	https://github.com/usc-sail/mica-music-in-media/	usc-sail	mica-music-in-media			0	0		repo deleted	
31714232	01/03/2022	10.1109/TCBB.2019.2951557	IEEE/ACM transactions on computational biology and bioinformatics	Inferring Synergistic Drug Combinations Based on Symmetric Meta-Path in a Novel Heterogeneous Network.	"Combinatorial drug therapy is a promising way for treating cancers, which can reduce drug side effects and improve drug efficacy. However, due to the large-scale combinatorial space, it is difficult to quickly and effectively identify novel synergistic drug combinations for further implementing combinatorial drug therapy. The computational method of fusing multi-source knowledge is a time- and cost-efficient strategy to infer synergistic drug combinations for testing. However, for the existing computational methods of inferring synergistic drug combinations, it still remains a challenging to effectively combine multi-source information to achieve the desired results. Hence, in this study, we developed a novel Inference method of Synergistic Drug Combinations based on Symmetric Meta-Path (ISDCSMP), which can systematically and accurately prioritize synergistic drug combinations in a novel drug-target heterogeneous network integrating multi-source information. In the experiment, ISDCSMP outperformed the state-of-the-art methods in terms of AUC and precision on the benchmark dataset in five-fold cross validation. Moreover, we further illustrated performances of different ways for obtaining the combination coefficients, and analyzed the influences of the maximum meta-path length. The performances of various single meta-paths were described in five-fold cross validation. Finally, we confirmed the practical usefulness of ISDCSMP with the predicted novel synergistic drug combinations. The source code of ISDCSMP is available at https://github.com/KDDing/ISDCSMP."	github.com/KDDing/ISDCSMP.	https://github.com/KDDing/ISDCSMP/	KDDing	ISDCSMP			0	1	05/07/2020	repo deleted	
36219665	04/10/2023	10.1109/TPAMI.2022.3213755	IEEE transactions on pattern analysis and machine intelligence	Defensive Few-Shot Learning.	"This article investigates a new challenging problem called defensive few-shot learning in order to learn a robust few-shot model against adversarial attacks. Simply applying the existing adversarial defense methods to few-shot learning cannot effectively solve this problem. This is because the commonly assumed sample-level distribution consistency between the training and test sets can no longer be met in the few-shot setting. To address this situation, we develop a general defensive few-shot learning (DFSL) framework to answer the following two key questions: (1) how to transfer adversarial defense knowledge from one sample distribution to another? (2) how to narrow the distribution gap between clean and adversarial examples under the few-shot setting? To answer the first question, we propose an episode-based adversarial training mechanism by assuming a task-level distribution consistency to better transfer the adversarial defense knowledge. As for the second question, within each few-shot task, we design two kinds of distribution consistency criteria to narrow the distribution gap between clean and adversarial examples from the feature-wise and prediction-wise perspectives, respectively. Extensive experiments demonstrate that the proposed framework can effectively make the existing few-shot models robust against adversarial attacks. Code is available at https://github.com/WenbinLee/DefensiveFSL.git."	github.com/WenbinLee/DefensiveFSL.git.	https://github.com/WenbinLee/DefensiveFSL/	WenbinLee	DefensiveFSL			0	0		repo deleted	
26500705	10/27/2015	10.1186/s13321-015-0098-y	Journal of cheminformatics	Target prediction utilising negative bioactivity data covering large chemical space.	"In silico analyses are increasingly being used to support mode-of-action investigations; however many such approaches do not utilise the large amounts of inactive data held in chemogenomic repositories. The objective of this work is concerned with the integration of such bioactivity data in the target prediction of orphan compounds to produce the probability of activity and inactivity for a range of targets. To this end, a novel human bioactivity data set was constructed through the assimilation of over 195 million bioactivity data points deposited in the ChEMBL and PubChem repositories, and the subsequent application of a sphere-exclusion selection algorithm to oversample presumed inactive compounds. A Bernoulli Na?ve Bayes algorithm was trained using the data and evaluated using fivefold cross-validation, achieving a mean recall and precision of 67.7 and 63.8 % for active compounds and 99.6 and 99.7 % for inactive compounds, respectively. We show the performances of the models are considerably influenced by the underlying intraclass training similarity, the size of a given class of compounds, and the degree of additional oversampling. The method was also validated using compounds extracted from WOMBAT producing average precision-recall AUC and BEDROC scores of 0.56 and 0.85, respectively. Inactive data points used for this test are based on presumed inactivity, producing an approximated indication of the true extrapolative ability of the models. A distance-based applicability domain analysis was also conducted; indicating an average Tanimoto Coefficient distance of 0.3 or greater between a test and training set can be used to give a global measure of confidence in model predictions. A final comparison to a method trained solely on active data from ChEMBL performed with precision-recall AUC and BEDROC scores of 0.45 and 0.76. The inclusion of inactive data for model training produces models with superior AUC and improved early recognition capabilities, although the results from internal and external validation of the models show differing performance between the breadth of models. The realised target prediction protocol is available at https://github.com/lhm30/PIDGIN.Graphical abstractThe inclusion of large scale negative training data for in silico target prediction improves the precision and recall AUC and BEDROC scores for target models. "	github.com/lhm30/PIDGIN.Graphical	https://github.com/lhm30/PIDGIN.Graphical/	lhm30	PIDGIN.Graphical			0	0		wrong link	https://github.com/lhm30/PIDGIN/
36528809	01/23/2023	10.1093/bib/bbac548	Briefings in bioinformatics	Multi-view contrastive heterogeneous graph attention network for lncRNA-disease association prediction.	"Exploring the potential long noncoding RNA (lncRNA)-disease associations (LDAs) plays a critical role for understanding disease etiology and pathogenesis. Given the high cost of biological experiments, developing a computational method is a practical necessity to effectively accelerate experimental screening process of candidate LDAs. However, under the high sparsity of LDA dataset, many computational models hardly exploit enough knowledge to learn comprehensive patterns of node representations. Moreover, although the metapath-based GNN has been recently introduced into LDA prediction, it discards intermediate nodes along the meta-path and results in information loss. This paper presents a new multi-view contrastive heterogeneous graph attention network (GAT) for lncRNA-disease association prediction, MCHNLDA for brevity. Specifically, MCHNLDA firstly leverages rich biological data sources of lncRNA, gene and disease to construct two-view graphs, feature structural graph of feature schema view and lncRNA-gene-disease heterogeneous graph of network topology view. Then, we design a cross-contrastive learning task to collaboratively guide graph embeddings of the two views without relying on any labels. In this way, we can pull closer the nodes of similar features and network topology, and push other nodes away. Furthermore, we propose a heterogeneous contextual GAT, where long short-term memory network is incorporated into attention mechanism to effectively capture sequential structure information along the meta-path. Extensive experimental comparisons against several state-of-the-art methods show the effectiveness of proposed framework.The code and data of proposed framework is freely available at https://github.com/zhaoxs686/MCHNLDA. "	github.com/zhaoxs686/MCHNLDA.	https://github.com/zhaoxs686/MCHNLDA/	zhaoxs686	MCHNLDA			0	0		repo deleted	
33187537	05/14/2021	10.1186/s12967-020-02602-7	Journal of translational medicine	DLDTI: a learning-based framework for drug-target interaction identification using neural networks and network representation.	"Drug repositioning, the strategy of unveiling novel targets of existing drugs could reduce costs and accelerate the pace of drug development. To elucidate the novel molecular mechanism of known drugs, considering the long time and high cost of experimental determination, the efficient and feasible computational methods to predict the potential associations between drugs and targets are of great aid. A novel calculation model for drug-target interaction (DTI) prediction based on network representation learning and convolutional neural networks, called DLDTI, was generated. The proposed approach simultaneously fused the topology of complex networks and diverse information from heterogeneous data sources, and coped with the noisy, incomplete, and high-dimensional nature of large-scale biological data by learning the low-dimensional and rich depth features of drugs and proteins. The low-dimensional feature vectors were used to train DLDTI to obtain the optimal mapping space and to infer new DTIs by ranking candidates according to their proximity to the optimal mapping space. More specifically, based on the results from the DLDTI, we experimentally validated the predicted targets of tetramethylpyrazine (TMPZ) on atherosclerosis progression in vivo. The experimental results showed that the DLDTI model achieved promising performance under fivefold cross-validations with AUC values of 0.9172, which was higher than the methods using different classifiers or different feature combination methods mentioned in this paper. For the validation study of TMPZ on atherosclerosis, a total of 288 targets were identified and 190 of them were involved in platelet activation. The pathway analysis indicated signaling pathways, namely PI3K/Akt, cAMP and calcium pathways might be the potential targets. Effects and molecular mechanism of TMPZ on atherosclerosis were experimentally confirmed in animal models. DLDTI model can serve as a useful tool to provide promising DTI candidates for experimental validation. Based on the predicted results of DLDTI model, we found TMPZ could attenuate atherosclerosis by inhibiting signal transductions in platelets. The source code and datasets explored in this work are available at https://github.com/CUMTzackGit/DLDTI . "	github.com/CUMTzackGit/DLDTI	https://github.com/CUMTzackGit/DLDTI/	CUMTzackGit	DLDTI			0	0		repo deleted	
30873528	07/01/2020	10.1093/bioinformatics/btz183	"Bioinformatics (Oxford, England)"	Classical scoring functions for docking are unable to exploit large volumes of structural and interaction data.	"Studies have shown that the accuracy of random forest (RF)-based scoring functions (SFs), such as RF-Score-v3, increases with more training samples, whereas that of classical SFs, such as X-Score, does not. Nevertheless, the impact of the similarity between training and test samples on this matter has not been studied in a systematic manner. It is therefore unclear how these SFs would perform when only trained on protein-ligand complexes that are highly dissimilar or highly similar to the test set. It is also unclear whether SFs based on machine learning algorithms other than RF can also improve accuracy with increasing training set size and to what extent they learn from dissimilar or similar training complexes. We present a systematic study to investigate how the accuracy of classical and machine-learning SFs varies with protein-ligand complex similarities between training and test sets. We considered three types of similarity metrics, based on the comparison of either protein structures, protein sequences or ligand structures. Regardless of the similarity metric, we found that incorporating a larger proportion of similar complexes to the training set did not make classical SFs more accurate. In contrast, RF-Score-v3 was able to outperform X-Score even when trained on just 32% of the most dissimilar complexes, showing that its superior performance owes considerably to learning from dissimilar training complexes to those in the test set. In addition, we generated the first SF employing Extreme Gradient Boosting (XGBoost), XGB-Score, and observed that it also improves with training set size while outperforming the rest of SFs. Given the continuous growth of training datasets, the development of machine-learning SFs has become very appealing. https://github.com/HongjianLi/MLSF. Supplementary data are available at Bioinformatics online. "	github.com/HongjianLi/MLSF.	https://github.com/HongjianLi/MLSF/	HongjianLi	MLSF			0	1	09/09/2021	repo deleted	
37015122	05/02/2023	10.1109/TIP.2023.3261755	IEEE transactions on image processing : a publication of the IEEE Signal Processing Society	Revisiting Multi-Codebook Quantization.	"Multi-Codebook Quantization (MCQ) is a generalized version of existing codebook-based quantizations for Approximate Nearest Neighbor (ANN) search. Specifically, MCQ picks one codeword for each sub-codebook independently and takes the sum of picked codewords to approximate the original vector. The objective function involves no constraints, therefore, MCQ theoretically has the potential to achieve the best performance because solutions of other codebook-based quantization methods are all covered by MCQ's solution space under the same codebook size setting. However, finding the optimal solution to MCQ is proved to be NP-hard due to its encoding process, i.e., converting an input vector to a binary code. To tackle this, researchers apply constraints to it to find near-optimal solutions or employ heuristic algorithms that are still time-consuming for encoding. Different from previous approaches, this paper takes the first attempt to find a deep solution to MCQ. The encoding network is designed to be as simple as possible, so the very complex encoding problem becomes simply a feed-forward. Compared with other methods on three datasets, our method shows state-of-the-art performance. Notably, our method is 11? - 38? faster than heuristic algorithms for encoding, which makes it more practical for the real scenery of large-scale retrieval. Our code is publicly available: https://github.com/DeepMCQ/DeepQ."	github.com/DeepMCQ/DeepQ.	https://github.com/DeepMCQ/DeepQ/	DeepMCQ	DeepQ			0	1	04/29/2023	repo deleted	
28172557	08/10/2018	10.1093/bioinformatics/btw645	"Bioinformatics (Oxford, England)"	CloudPhylo: a fast and scalable tool for phylogeny reconstruction.	"Phylogeny reconstruction is fundamentally crucial for molecular evolutionary studies but remains computationally challenging. Here we present CloudPhylo, a tool built on Spark that is capable of processing large-scale datasets for phylogeny reconstruction. As testified on empirical data, CloudPhylo is well suited for big data analysis, achieving high efficiency and good scalability on phylogenetic tree inference. https://github.com/XingjianXu/cloudphylo zhangzhang@big.ac.cn Supplementary data are available at Bioinformatics online. "	github.com/XingjianXu/cloudphylo	https://github.com/XingjianXu/cloudphylo/	XingjianXu	cloudphylo			0	1	11/12/2019	repo deleted	
35645759	05/13/2022	10.3389/fnbot.2022.843026	Frontiers in neurorobotics	An Intelligent Self-Driving Truck System for Highway Transportation.	"Recently, there have been many advances in autonomous driving society, attracting a lot of attention from academia and industry. However, existing studies mainly focus on cars, extra development is still required for self-driving truck algorithms and models. In this article, we introduce an intelligent self-driving truck system. Our presented system consists of three main components, 1) a realistic traffic simulation module for generating realistic traffic flow in testing scenarios, 2) a high-fidelity truck model which is designed and evaluated for mimicking real truck response in real world deployment, and 3) an intelligent planning module with learning-based decision making algorithm and multi-mode trajectory planner, taking into account the truck's constraints, road slope changes, and the surrounding traffic flow. We provide quantitative evaluations for each component individually to demonstrate the fidelity and performance of each part. We also deploy our proposed system on a real truck and conduct real world experiments which show our system's capacity of mitigating sim-to-real gap. Our code is available at https://github.com/InceptioResearch/IITS."	github.com/InceptioResearch/IITS.	https://github.com/InceptioResearch/IITS/	InceptioResearch	IITS			0	0		repo deleted	
36709557	02/22/2023	10.1016/j.cmpb.2023.107355	Computer methods and programs in biomedicine	High-throughput 3DRA segmentation of brain vasculature and aneurysms using deep learning.	"Automatic segmentation of the cerebral vasculature and aneurysms facilitates incidental detection of aneurysms. The assessment of aneurysm rupture risk assists with pre-operative treatment planning and enables in-silico investigation of cerebral hemodynamics within and in the vicinity of aneurysms. However, ensuring precise and robust segmentation of cerebral vessels and aneurysms in neuroimaging modalities such as three-dimensional rotational angiography (3DRA) is challenging. The vasculature constitutes a small proportion of the image volume, resulting in a large class imbalance (relative to surrounding brain tissue). Additionally, aneurysms and vessels have similar image/appearance characteristics, making it challenging to distinguish the aneurysm sac from the vessel lumen. We propose a novel multi-class convolutional neural network to tackle these challenges and facilitate the automatic segmentation of cerebral vessels and aneurysms in 3DRA images. The proposed model is trained and evaluated on an internal multi-center dataset and an external publicly available challenge dataset. On the internal clinical dataset, our method consistently outperformed several state-of-the-art approaches for vessel and aneurysm segmentation, achieving an average Dice score of 0.81 (0.15 higher than nnUNet) and an average surface-to-surface error of 0.20 mm (less than the in-plane resolution (0.35 mm/pixel)) for aneurysm segmentation; and an average Dice score of 0.91 and average surface-to-surface error of 0.25 mm for vessel segmentation. In 223 cases of a clinical dataset, our method accurately segmented 190 aneurysm cases. The proposed approach can help address class imbalance problems and inter-class interference problems in multi-class segmentation. Besides, this method performs consistently on clinical datasets from four different sources and the generated results are qualified for hemodynamic simulation. Code available at https://github.com/cistib/vessel-aneurysm-segmentation. "	github.com/cistib/vessel-aneurysm-segmentation.	https://github.com/cistib/vessel-aneurysm-segmentation/	cistib	vessel-aneurysm-segmentation			0	0		repo deleted	
32764847	12/03/2019	10.1007/s00180-019-00937-4	Computational statistics	Efficient inference in state-space models through adaptive learning in online Monte Carlo expectation maximization.	"Expectation maximization (EM) is a technique for estimating maximum-likelihood parameters of a latent variable model given observed data by alternating between taking expectations of sufficient statistics, and maximizing the expected log likelihood. For situations where sufficient statistics are intractable, stochastic approximation EM (SAEM) is often used, which uses Monte Carlo techniques to approximate the expected log likelihood. Two common implementations of SAEM, Batch EM (BEM) and online EM (OEM), are parameterized by a ""learning rate"", and their efficiency depend strongly on this parameter. We propose an extension to the OEM algorithm, termed Introspective Online Expectation Maximization (IOEM), which removes the need for specifying this parameter by adapting the learning rate to trends in the parameter updates. We show that our algorithm matches the efficiency of the optimal BEM and OEM algorithms in multiple models, and that the efficiency of IOEM can exceed that of BEM/OEM methods with optimal learning rates when the model has many parameters. Finally we use IOEM to fit two models to a financial time series. A Python implementation is available at https://github.com/luntergroup/IOEM.git."	github.com/luntergroup/IOEM.git.	https://github.com/luntergroup/IOEM/	luntergroup	IOEM			0	1	06/02/2021	repo deleted	
32725163	11/22/2021	10.1093/bib/bbaa146	Briefings in bioinformatics	Predicting human microbe-disease associations via graph attention networks with inductive matrix completion.	"human microbes play a critical role in an extensive range of complex human diseases and become a new target in precision medicine. In silico methods of identifying microbe-disease associations not only can provide a deep insight into understanding the pathogenic mechanism of complex human diseases but also assist pharmacologists to screen candidate targets for drug development. However, the majority of existing approaches are based on linear models or label propagation, which suffers from limitations in capturing nonlinear associations between microbes and diseases. Besides, it is still a great challenge for most previous methods to make predictions for new diseases (or new microbes) with few or without any observed associations. in this work, we construct features for microbes and diseases by fully exploiting multiply sources of biomedical data, and then propose a novel deep learning framework of graph attention networks with inductive matrix completion for human microbe-disease association prediction, named GATMDA. To our knowledge, this is the first attempt to leverage graph attention networks for this important task. In particular, we develop an optimized graph attention network with talking-heads to learn representations for nodes (i.e. microbes and diseases). To focus on more important neighbours and filter out noises, we further design a bi-interaction aggregator to enforce representation aggregation of similar neighbours. In addition, we combine inductive matrix completion to reconstruct microbe-disease associations to capture the complicated associations between diseases and microbes. Comprehensive experiments on two data sets (i.e. HMDAD and Disbiome) demonstrated that our proposed model consistently outperformed baseline methods. Case studies on two diseases, i.e. asthma and inflammatory bowel disease, further confirmed the effectiveness of our proposed model of GATMDA. python codes and data set are available at: https://github.com/yahuilong/GATMDA. luojiawei@hnu.edu.cn. "	github.com/yahuilong/GATMDA.	https://github.com/yahuilong/GATMDA/	yahuilong	GATMDA			0	1	07/17/2022	repo deleted	
36288235	04/11/2023	10.1109/TMI.2022.3217218	IEEE transactions on medical imaging	Radiomics-Guided Global-Local Transformer for Weakly Supervised Pathology Localization in Chest X-Rays.	"Before the recent success of deep learning methods for automated medical image analysis, practitioners used handcrafted radiomic features to quantitatively describe local patches of medical images. However, extracting discriminative radiomic features relies on accurate pathology localization, which is difficult to acquire in real-world settings. Despite advances in disease classification and localization from chest X-rays, many approaches fail to incorporate clinically-informed domainspecific radiomic features. For these reasons, we propose a Radiomics-Guided Transformer (RGT) that fuses global image information with local radiomics-guided auxiliary information to provide accurate cardiopulmonary pathology localization and classification without any bounding box annotations. RGT consists of an image Transformer branch, a radiomics Transformer branch, and fusion layers that aggregate image and radiomics information. Using the learned self-attention of its image branch, RGT extracts a bounding box for which to compute radiomic features, which are further processed by the radiomics branch; learned image and radiomic features are then fused and mutually interact via cross-attention layers. Thus, RGT utilizes a novel end-to-end feedback loop that can bootstrap accurate pathology localization only using image-level disease labels. Experiments on the NIH ChestXRay dataset demonstrate that RGT outperforms prior works in weakly supervised disease localization (by an average margin of 3.6% over various intersection-over-union thresholds) and classification (by 1.1% in average area under the receiver operating characteristic curve). We publicly release our codes and pre-trained models at https://github.com/VITAGroup/chext."	github.com/VITAGroup/chext.	https://github.com/VITAGroup/chext/	VITAGroup	chext			0	0		repo deleted	
27667790	12/07/2017	10.1093/bioinformatics/btw612	"Bioinformatics (Oxford, England)"	cMapper: gene-centric connectivity mapper for EBI-RDF platform.	"In this era of biological big data, data integration has become a common task and a challenge for biologists. The Resource Description Framework (RDF) was developed to enable interoperability of heterogeneous datasets. The EBI-RDF platform enables an efficient data integration of six independent biological databases using RDF technologies and shared ontologies. However, to take advantage of this platform, biologists need to be familiar with RDF technologies and SPARQL query language. To overcome this practical limitation of the EBI-RDF platform, we developed cMapper, a web-based tool that enables biologists to search the EBI-RDF databases in a gene-centric manner without a thorough knowledge of RDF and SPARQL. cMapper allows biologists to search data entities in the EBI-RDF platform that are connected to genes or small molecules of interest in multiple biological contexts. The input to cMapper consists of a set of genes or small molecules, and the output are data entities in six independent EBI-RDF databases connected with the given genes or small molecules in the user's query. cMapper provides output to users in the form of a graph in which nodes represent data entities and the edges represent connections between data entities and inputted set of genes or small molecules. Furthermore, users can apply filters based on database, taxonomy, organ and pathways in order to focus on a core connectivity graph of their interest. Data entities from multiple databases are differentiated based on background colors. cMapper also enables users to investigate shared connections between genes or small molecules of interest. Users can view the output graph on a web browser or download it in either GraphML or JSON formats. cMapper is available as a web application with an integrated MySQL database. The web application was developed using Java and deployed on Tomcat server. We developed the user interface using HTML5, JQuery and the Cytoscape Graph API. cMapper can be accessed at http://cmapper.ewostech.net Readers can download the development manual from the website http://cmapper.ewostech.net/docs/cMapperDocumentation.pdf. Source Code is available at https://github.com/muhammadshoaib/cmapperContact:smahn@gachon.ac.krSupplementary information: Supplementary data are available at Bioinformatics online. "	github.com/muhammadshoaib/cmapperContact	https://github.com/muhammadshoaib/cmapperContact/	muhammadshoaib	cmapperContact			0	0		repo deleted	
28369195	03/26/2018	10.1093/bioinformatics/btx174	"Bioinformatics (Oxford, England)"	Mining heterogeneous causal effects for personalized cancer treatment.	"Cancer is not a single disease and involves different subtypes characterized by different sets of molecules. Patients with different subtypes of cancer often react heterogeneously towards the same treatment. Currently, clinical diagnoses rather than molecular profiles are used to determine the most suitable treatment. A molecular level approach will allow a more precise and informed way for making treatment decisions, leading to a better survival chance and less suffering of patients. Although many computational methods have been proposed to identify cancer subtypes at molecular level, to the best of our knowledge none of them are designed to discover subtypes with heterogeneous treatment responses. In this article we propose the Survival Causal Tree (SCT) method. SCT is designed to discover patient subgroups with heterogeneous treatment effects from censored observational data. Results on TCGA breast invasive carcinoma and glioma datasets have shown that for each subtype identified by SCT, the patients treated with radiotherapy exhibit significantly different relapse free survival pattern when compared to patients without the treatment. With the capability to identify cancer subtypes with heterogeneous treatment responses, SCT is useful in helping to choose the most suitable treatment for individual patients. Data and code are available at https://github.com/WeijiaZhang24/SurvivalCausalTree . weijia.zhang@mymail.uinsa.edu.au. Supplementary data are available at Bioinformatics online. "	github.com/WeijiaZhang24/SurvivalCausalTree	https://github.com/WeijiaZhang24/SurvivalCausalTree/	WeijiaZhang24	SurvivalCausalTree			0	1	01/22/2021	repo deleted	
33200119	09/16/2020	10.26434/chemrxiv.12915779	ChemRxiv : the preprint server for chemistry	REDIAL-2020: A Suite of Machine Learning Models to Estimate Anti-SARS-CoV-2 Activities.	"Strategies for drug discovery and repositioning are an urgent need with respect to COVID-19. We developed ""REDIAL-2020"", a suite of machine learning models for estimating small molecule activity from molecular structure, for a range of SARS-CoV-2 related assays. Each classifier is based on three distinct types of descriptors (fingerprint, physicochemical, and pharmacophore) for parallel model development. These models were trained using high throughput screening data from the NCATS COVID19 portal (https://opendata.ncats.nih.gov/covid19/index.html), with multiple categorical machine learning algorithms. The ""best models"" are combined in an ensemble consensus predictor that outperforms single models where external validation is available. This suite of machine learning models is available through the DrugCentral web portal (<a href=""https://drugdiscovery.utep.edu/redial"">http://drugcentral.org/Redial</a>). Acceptable input formats are: drug name, PubChem CID, or SMILES; the output is an estimate of anti-SARS-CoV-2 activities. The web application reports estimated activity across three areas (,  and ) spanning six independent models, followed by a similarity search that displays the most similar molecules to the query among experimentally determined data. The ML models have 60% to 74% external predictivity, based on three separate datasets. Complementing the NCATS COVID19 portal, REDIAL-2020 can serve as a rapid online tool for identifying active molecules for COVID-19 treatment. The source code and specific models are available through Github (<a href=""https://github.com/sirimullalab/ncats_covid"">https://github.com/sirimullalab/</a>redial-2020), or via Docker Hub (https://hub.docker.com/r/sirimullalab/redial-2020) for users preferring a containerized version. "	"github.com/sirimullalab/ncats_covid"""	https://github.com/sirimullalab/ncats_covid/	sirimullalab	ncats_covid			0	0		repo deleted	
35143604	02/02/2023	10.1093/bioinformatics/btac074	"Bioinformatics (Oxford, England)"	Identify connectome between genotypes and brain network phenotypes via deep self-reconstruction sparse canonical correlation analysis.	"As a rising research topic, brain imaging genetics aims to investigate the potential genetic architecture of both brain structure and function. It should be noted that in the brain, not all variations are deservedly caused by genetic effect, and it is generally unknown which imaging phenotypes are promising for genetic analysis. In this work, genetic variants (i.e. the single nucleotide polymorphism, SNP) can be correlated with brain networks (i.e. quantitative trait, QT), so that the connectome (including the brain regions and connectivity features) of functional brain networks from the functional magnetic resonance imaging data is identified. Specifically, a connection matrix is firstly constructed, whose upper triangle elements are selected to be connectivity features. Then, the PageRank algorithm is exploited for estimating the importance of different brain regions as the brain region features. Finally, a deep self-reconstruction sparse canonical correlation analysis (DS-SCCA) method is developed for the identification of genetic associations with functional connectivity phenotypic markers. This approach is a regularized, deep extension, scalable multi-SNP-multi-QT method, which is well-suited for applying imaging genetic association analysis to the Alzheimer's Disease Neuroimaging Initiative datasets. It is further optimized by adopting a parametric approach, augmented Lagrange and stochastic gradient descent. Extensive experiments are provided to validate that the DS-SCCA approach realizes strong associations and discovers functional connectivity and brain region phenotypic biomarkers to guide disease interpretation. The Matlab code is available at https://github.com/meimeiling/DS-SCCA/tree/main. Supplementary data are available at Bioinformatics online. "	github.com/meimeiling/DS-SCCA/tree/main.	https://github.com/meimeiling/DS-SCCA/tree/main/	meimeiling	DS-SCCA			0	0		repo deleted	
33594415	11/24/2021	10.1093/jamia/ocaa346	Journal of the American Medical Informatics Association : JAMIA	Deep propensity network using a sparse autoencoder for estimation of treatment effects.	"Drawing causal estimates from observational data is problematic, because datasets often contain underlying bias (eg, discrimination in treatment assignment). To examine causal effects, it is important to evaluate what-if scenarios-the so-called ""counterfactuals."" We propose a novel deep learning architecture for propensity score matching and counterfactual prediction-the deep propensity network using a sparse autoencoder (DPN-SA)-to tackle the problems of high dimensionality, nonlinear/nonparallel treatment assignment, and residual confounding when estimating treatment effects. We used 2 randomized prospective datasets, a semisynthetic one with nonlinear/nonparallel treatment selection bias and simulated counterfactual outcomes from the Infant Health and Development Program and a real-world dataset from the LaLonde's employment training program. We compared different configurations of the DPN-SA against logistic regression and LASSO as well as deep counterfactual networks with propensity dropout (DCN-PD). Models' performances were assessed in terms of average treatment effects, mean squared error in precision on effect's heterogeneity, and average treatment effect on the treated, over multiple training/test runs. The DPN-SA outperformed logistic regression and LASSO by 36%-63%, and DCN-PD by 6%-10% across all datasets. All deep learning architectures yielded average treatment effects close to the true ones with low variance. Results were also robust to noise-injection and addition of correlated variables. Code is publicly available at https://github.com/Shantanu48114860/DPN-SAz. Deep sparse autoencoders are particularly suited for treatment effect estimation studies using electronic health records because they can handle high-dimensional covariate sets, large sample sizes, and complex heterogeneity in treatment assignments. "	github.com/Shantanu48114860/DPN-SAz.	https://github.com/Shantanu48114860/DPN-SAz/	Shantanu48114860	DPN-SAz			0	0		repo deleted	
32649284	10/12/2021	10.1109/TCYB.2020.2999492	IEEE transactions on cybernetics	Self-Supervised Multiscale Adversarial Regression Network for Stereo Disparity Estimation.	"Deep learning approaches have significantly contributed to recent progress in stereo matching. These deep stereo matching methods are usually based on supervised training, which requires a large amount of high-quality ground-truth depth map annotations that are expensive to collect. Furthermore, only a limited quantity of stereo vision training data are currently available, obtained either by active sensors (Lidar and ToF cameras) or through computer graphics simulations and not meeting requirements for deep supervised training. Here, we propose a novel deep stereo approach called the ""self-supervised multiscale adversarial regression network (SMAR-Net),"" which relaxes the need for ground-truth depth maps for training. Specifically, we design a two-stage network. The first stage is a disparity regressor, in which a regression network estimates disparity values from stacked stereo image pairs. Stereo image stacking method is a novel contribution as it not only contains the spatial appearances of stereo images but also implies matching correspondences with different disparity values. In the second stage, a synthetic left image is generated based on the left-right consistency assumption. Our network is trained by minimizing a hybrid loss function composed of a content loss and an adversarial loss. The content loss minimizes the average warping error between the synthetic images and the real ones. In contrast to the generative adversarial loss, our proposed adversarial loss penalizes mismatches using multiscale features. This constrains the synthetic image and real image as being pixelwise identical instead of just belonging to the same distribution. Furthermore, the combined utilization of multiscale feature extraction in both the content loss and adversarial loss further improves the adaptability of SMAR-Net in ill-posed regions. Experiments on multiple benchmark datasets show that SMAR-Net outperforms the current state-of-the-art self-supervised methods and achieves comparable outcomes to supervised methods. The source code can be accessed at: https://github.com/Dawnstar8411/SMAR-Net."	github.com/Dawnstar8411/SMAR-Net.	https://github.com/Dawnstar8411/SMAR-Net/	Dawnstar8411	SMAR-Net			0	1	05/15/2020	repo deleted	
36971393	03/27/2023	10.1093/bib/bbad111	Briefings in bioinformatics	A feature extraction method based on noise reduction for circRNA-miRNA interaction prediction combining multi-structure features in the association networks.	"A large number of studies have shown that circular RNA (circRNA) affects biological processes by competitively binding miRNA, providing a new perspective for the diagnosis, and treatment of human diseases. Therefore, exploring the potential circRNA-miRNA interactions (CMIs) is an important and urgent task at present. Although some computational methods have been tried, their performance is limited by the incompleteness of feature extraction in sparse networks and the low computational efficiency of lengthy data. In this paper, we proposed JSNDCMI, which combines the multi-structure feature extraction framework and Denoising Autoencoder (DAE) to meet the challenge of CMI prediction in sparse networks. In detail, JSNDCMI integrates functional similarity and local topological structure similarity in the CMI network through the multi-structure feature extraction framework, then forces the neural network to learn the robust representation of features through DAE and finally uses the Gradient Boosting Decision Tree classifier to predict the potential CMIs. JSNDCMI produces the best performance in the 5-fold cross-validation of all data sets. In the case study, seven of the top 10 CMIs with the highest score were verified in PubMed. The data and source code can be found at https://github.com/1axin/JSNDCMI. "	github.com/1axin/JSNDCMI.	https://github.com/1axin/JSNDCMI/	1axin	JSNDCMI			0	0		repo deleted	
36433795	04/18/2023	10.1002/mp.16120	Medical physics	An efficient interactive segmentation framework for medical images without pre-training.	"Accurate and efficient medical image segmentation plays an important role in subsequent clinical applications such as diagnosis and surgical planning. This paper proposes an efficient interactive framework based on a graph convolutional network (GCN) for medical image segmentation. The initial segmentation results showed that a set of boundary control points can be generated for further interactive segmentation. We presented an adaptive interactive manner that allows the user to click on the boundary for fast interaction or drag the erroneous predicted control points for accurate correction. Furthermore, we proposed an interactive segmentation network (referred to as IVIF-GCN) to learn user experience in the interactive process by transforming interactive cues into annotations. In IVIF-GCN, a module of information fusion of image features and vertex position features (IVIF) is proposed to learn the location relationship between the current vertex and the neighboring vertices. Finally, the locations of control points around the interaction point is predicted and updated automatically. The proposed method achieves mean Dice of 96.6% and 91.3% on PROMISE12 and our in-house nasopharyngeal carcinoma (NPC) test sets, respectively. The experimental results showed that the proposed method outperforms the state-of-the-art segmentation methods. The proposed interactive medical image segmentation method can efficiently improve segmentation results for clinical applications in the absence of training data. The GUI tool based on our method is available at https://github.com/Tian-lab/IGMedSeg. "	github.com/Tian-lab/IGMedSeg.	https://github.com/Tian-lab/IGMedSeg/	Tian-lab	IGMedSeg			0	0		repo deleted	
37018113	04/05/2023	10.1109/TMI.2023.3264433	IEEE transactions on medical imaging	MISSU: 3D Medical Image Segmentation via Self-distilling TransUNet.	"U-Nets have achieved tremendous success in medical image segmentation. Nevertheless, it may have limitations in global (long-range) contextual interactions and edge-detail preservation. In contrast, the Transformer module has an excellent ability to capture long-range dependencies by leveraging the self-attention mechanism into the encoder. Although the Transformer module was born to model the long-range dependency on the extracted feature maps, it still suffers high computational and spatial complexities in processing high-resolution 3D feature maps. This motivates us to design an efficient Transformer-based UNet model and study the feasibility of Transformer-based network architectures for medical image segmentation tasks. To this end, we propose to self-distill a Transformer-based UNet for medical image segmentation, which simultaneously learns global semantic information and local spatial-detailed features. Meanwhile, a local multi-scale fusion block is first proposed to refine fine-grained details from the skipped connections in the encoder by the main CNN stem through self-distillation, only computed during training and removed at inference with minimal overhead. Extensive experiments on BraTS 2019 and CHAOS datasets show that our MISSU achieves the best performance over previous state-of-the-art methods. Code and models are available at: https: //github.com/wangn123/MISSU.git."	github.com/wangn123/MISSU.git.	https://github.com/wangn123/MISSU/	wangn123	MISSU			0	0		repo deleted	
37027662	02/22/2023	10.1109/TMI.2023.3247941	IEEE transactions on medical imaging	Shape-aware Joint Distribution Alignment for Cross-domain Image Segmentation.	"We present an unsupervised domain adaptation method for image segmentation which aligns high-order statistics, computed for the source and target domains, encoding domain-invariant spatial relationships between segmentation classes. Our method first estimates the joint distribution of predictions for pair of pixels whose relative position corresponds to a given spatial displacement. Domain adaptation is then achieved by aligning the joint distributions of source and target images, computed for a set of displacements. Two enhancements of this method are proposed. The first one uses an efficient multi-scale strategy that enables capturing long-range relationships in the statistics. The second one extends the joint distribution alignment loss to features in intermediate layers of the network by computing their cross-correlation. We test our method on the task of unpaired multi-modal cardiac segmentation using the Multi-Modality Whole Heart Segmentation Challenge dataset and prostate segmentation task where images from two datasets are taken as data in different domains. Our results show the advantages of our method compared to recent approaches for cross-domain image segmentation. Code is available at https://github.com/WangPing521/Domain_adaptation_shape_prior."	github.com/WangPing521/Domain_adaptation_shape_prior.	https://github.com/WangPing521/Domain_adaptation_shape_prior/	WangPing521	Domain_adaptation_shape_prior			0	0		repo deleted	
32572768	09/17/2021	10.1007/s12539-020-00379-3	"Interdisciplinary sciences, computational life sciences"	AC-Caps: Attention Based Capsule Network for Predicting RBP Binding Sites of LncRNA.	"Long non-coding RNA(lncRNA) is one of the non-coding RNAs longer than 200 nucleotides and it has no protein encoding function. LncRNA plays a key role in many biological processes. Studying the RNA-binding protein (RBP) binding sites on the lncRNA chain helps to reveal epigenetic and post-transcriptional mechanisms, to explore the physiological and pathological processes of cancer, and to discover new therapeutic breakthroughs. To improve the recognition rate of RBP binding sites and reduce the experimental time and cost, many calculation methods based on domain knowledge to predict RBP binding sites have emerged. However, these prediction methods are independent of nucleotides and do not take into account nucleotide statistics. In this paper, we use a high-order statistical-based encoding scheme, then the encoded lncRNA sequences are fed into a hybrid deep learning architecture named AC-Caps. It consists of a joint processing layer(composed of attention mechanism and convolutional neural network) and a capsule network. The AC-Caps model was evaluated using 31 independent experimental data sets from 12 lncRNA-binding proteins. In experiments, our method achieves excellent performance, with an average area under the curve (AUC) of 0.967 and an average accuracy (ACC) of 92.5%, which are 0.014, 2.3%, 0.261, 28.9%, 0.189, and 21.8% higher than HOCCNNLB, iDeepS, and DeepBind, respectively. The results show that the AC-Caps method can reliably process the large-scale RBP binding site data on the lncRNA chain, and the prediction performance is better than existing deep-learning models. The source code of AC-Caps and the datasets used in this paper are available at https://github.com/JinmiaoS/AC-Caps ."	github.com/JinmiaoS/AC-Caps	https://github.com/JinmiaoS/AC-Caps/	JinmiaoS	AC-Caps			0	1	04/21/2022	repo deleted	
36619138	01/03/2023	10.1007/s11831-022-09863-z	Archives of computational methods in engineering : state of the art reviews	Mental Health Analysis in Social Media Posts: A Survey.	"The surge in internet use to express personal thoughts and beliefs makes it increasingly feasible for the social NLP research community to find and validate associations between  and . Cross-sectional and longitudinal studies of social media data bring to fore the importance of real-time responsible AI models for mental health analysis. Aiming to classify the research directions for social computing and tracking advances in the development of machine learning (ML) and deep learning (DL) based models, we propose a comprehensive survey on . We compose a taxonomy for mental healthcare and highlight recent attempts in examining social well-being with personal writings on social media. We define all the possible research directions for mental healthcare and investigate a thread of handling online social media data for stress, depression and suicide detection for this work. The key features of this manuscript are (i) feature extraction and classification, (ii) recent advancements in AI models, (iii) publicly available dataset, (iv) new frontiers and future research directions. We compile this information to introduce young research and academic practitioners with the field of computational intelligence for mental health analysis on social media. In this manuscript, we carry out a quantitative synthesis and a qualitative review with the corpus of over 92 potential research articles. In this context, we release the collection of existing work on suicide detection in an easily accessible and updatable repository:https://github.com/drmuskangarg/mentalhealthcare. "	github.com/drmuskangarg/mentalhealthcare.	https://github.com/drmuskangarg/mentalhealthcare/	drmuskangarg	mentalhealthcare			0	0		repo deleted	
30192920	02/18/2020	10.1093/bioinformatics/bty790	"Bioinformatics (Oxford, England)"	smCounter2: an accurate low-frequency variant caller for targeted sequencing data with unique molecular identifiers.	"Low-frequency DNA mutations are often confounded with technical artifacts from sample preparation and sequencing. With unique molecular identifiers (UMIs), most of the sequencing errors can be corrected. However, errors before UMI tagging, such as DNA polymerase errors during end repair and the first PCR cycle, cannot be corrected with single-strand UMIs and impose fundamental limits to UMI-based variant calling. We developed smCounter2, a UMI-based variant caller for targeted sequencing data and an upgrade from the current version of smCounter. Compared to smCounter, smCounter2 features lower detection limit that decreases from 1 to 0.5%, better overall accuracy (particularly in non-coding regions), a consistent threshold that can be applied to both deep and shallow sequencing runs, and easier use via a Docker image and code for read pre-processing. We benchmarked smCounter2 against several state-of-the-art UMI-based variant calling methods using multiple datasets and demonstrated smCounter2's superior performance in detecting somatic variants. At the core of smCounter2 is a statistical test to determine whether the allele frequency of the putative variant is significantly above the background error rate, which was carefully modeled using an independent dataset. The improved accuracy in non-coding regions was mainly achieved using novel repetitive region filters that were specifically designed for UMI data. The entire pipeline is available at https://github.com/qiaseq/qiaseq-dna under MIT license. Supplementary data are available at Bioinformatics online. "	github.com/qiaseq/qiaseq-dna	https://github.com/qiaseq/qiaseq-dna/	qiaseq	qiaseq-dna			0	1	02/13/2020	repo deleted	
35561198	05/17/2022	10.1093/bioinformatics/btac167	"Bioinformatics (Oxford, England)"	Context-aware learning for cancer cell nucleus recognition in pathology images.	"Nucleus identification supports many quantitative analysis studies that rely on nuclei positions or categories. Contextual information in pathology images refers to information near the to-be-recognized cell, which can be very helpful for nucleus subtyping. Current CNN-based methods do not explicitly encode contextual information within the input images and point annotations. In this article, we propose a novel framework with context to locate and classify nuclei in microscopy image data. Specifically, first we use state-of-the-art network architectures to extract multi-scale feature representations from multi-field-of-view, multi-resolution input images and then conduct feature aggregation on-the-fly with stacked convolutional operations. Then, two auxiliary tasks are added to the model to effectively utilize the contextual information. One for predicting the frequencies of nuclei, and the other for extracting the regional distribution information of the same kind of nuclei. The entire framework is trained in an end-to-end, pixel-to-pixel fashion. We evaluate our method on two histopathological image datasets with different tissue and stain preparations, and experimental results demonstrate that our method outperforms other recent state-of-the-art models in nucleus identification. The source code of our method is freely available at https://github.com/qjxjy123/DonRabbit. Supplementary data are available at Bioinformatics online. "	github.com/qjxjy123/DonRabbit.	https://github.com/qjxjy123/DonRabbit/	qjxjy123	DonRabbit			0	0		repo deleted	
29352257	11/27/2018	10.1038/s41598-018-19635-0	Scientific reports	Robust phenotype prediction from gene expression data using differential shrinkage of co-regulated genes.	"Discovery of robust diagnostic or prognostic biomarkers is a key to optimizing therapeutic benefit for select patient cohorts - an idea commonly referred to as precision medicine. Most discovery studies to derive such markers from high-dimensional transcriptomics datasets are weakly powered with sample sizes in the tens of patients. Therefore, highly regularized statistical approaches are essential to making generalizable predictions. At the same time, prior knowledge-driven approaches have been successfully applied to the manual interpretation of high-dimensional transcriptomics datasets. In this work, we assess the impact of combining two orthogonal approaches for the discovery of biomarker signatures, namely (1) well-known lasso-based regression approaches and its more recent derivative, the group lasso, and (2) the discovery of significant upstream regulators in literature-derived biological networks. Our method integrates both approaches in a weighted group-lasso model and differentially weights gene sets based on inferred active regulatory mechanism. Using nested cross-validation as well as independent clinical datasets, we demonstrate that our approach leads to increased accuracy and generalizable results. We implement our approach in a computationally efficient, user-friendly R package called creNET. The package can be downloaded at https://github.com/kouroshz/creNethttps://github.com/kouroshz/creNet and is accompanied by a parsed version of the STRING DB data base."	github.com/kouroshz/creNethttps	https://github.com/kouroshz/creNethttps/	kouroshz	creNethttps			0	0		wrong link	https://github.com/kouroshz/creNet/
27504009	11/20/2017	10.1093/database/baw112	Database : the journal of biological databases and curation	Improving the dictionary lookup approach for disease normalization using enhanced dictionary and query expansion.	"The rapidly increasing biomedical literature calls for the need of an automatic approach in the recognition and normalization of disease mentions in order to increase the precision and effectivity of disease based information retrieval. A variety of methods have been proposed to deal with the problem of disease named entity recognition and normalization. Among all the proposed methods, conditional random fields (CRFs) and dictionary lookup method are widely used for named entity recognition and normalization respectively. We herein developed a CRF-based model to allow automated recognition of disease mentions, and studied the effect of various techniques in improving the normalization results based on the dictionary lookup approach. The dataset from the BioCreative V CDR track was used to report the performance of the developed normalization methods and compare with other existing dictionary lookup based normalization methods. The best configuration achieved an F-measure of 0.77 for the disease normalization, which outperformed the best dictionary lookup based baseline method studied in this work by an F-measure of 0.13.Database URL: https://github.com/TCRNBioinformatics/DiseaseExtract."	github.com/TCRNBioinformatics/DiseaseExtract.	https://github.com/TCRNBioinformatics/DiseaseExtract/	TCRNBioinformatics	DiseaseExtract			0	1	01/12/2021	repo deleted	
31397851	09/17/2020	10.1093/bioinformatics/btz621	"Bioinformatics (Oxford, England)"	Graph convolution for predicting associations between miRNA and drug resistance.	"MicroRNA (miRNA) therapeutics is becoming increasingly important. However, aberrant expression of miRNAs is known to cause drug resistance and can become an obstacle for miRNA-based therapeutics. At present, little is known about associations between miRNA and drug resistance and there is no computational tool available for predicting such association relationship. Since it is known that miRNAs can regulate genes that encode specific proteins that are keys for drug efficacy, we propose here a computational approach, called GCMDR, for finding a three-layer latent factor model that can be used to predict miRNA-drug resistance associations. In this paper, we discuss how the problem of predicting such associations can be formulated as a link prediction problem involving a bipartite attributed graph. GCMDR makes use of the technique of graph convolution to build a latent factor model, which can effectively utilize information of high-dimensional attributes of miRNA/drug in an end-to-end learning scheme. In addition, GCMDR also learns graph embedding features for miRNAs and drugs. We leveraged the data from multiple databases storing miRNA expression profile, drug substructure fingerprints, gene ontology and disease ontology. The test for performance shows that the GCMDR prediction model can achieve AUCs of 0.9301 ± 0.0005, 0.9359 ± 0.0006 and 0.9369 ± 0.0003 based on 2-fold, 5-fold and 10-fold cross validation, respectively. Using this model, we show that the associations between miRNA and drug resistance can be reliably predicted by properly introducing useful side information like miRNA expression profile and drug structure fingerprints. Python codes and dataset are available at https://github.com/yahuang1991polyu/GCMDR/. Supplementary data are available at Bioinformatics online. "	github.com/yahuang1991polyu/GCMDR/.	https://github.com/yahuang1991polyu/GCMDR/	yahuang1991polyu	GCMDR			0	0		repo deleted	
24034598	07/25/2014	10.1111/1755-0998.12160	Molecular ecology resources	HeFPipe: a complete analytical pipeline for heterozygosity-fitness correlation studies.	"As the body of heterozygosity-fitness correlation (HFC) research grows, more and increasingly complicated tests have become an integral part of a typical HFC analysis (Chapman et al. 2009). Currently, no software is available to undertake conversion between the file formats required to conduct all of these tests and to conduct the main regression analyses at the core of all HFCs. Heterozygosity-Fitness Pipeline (HeFPipe) is a script written in Python that accomplishes both of these tasks for studies based on microsatellite data. HeFPipe is designed to be used from the command line terminal and will run on any Mac OSX computer. The script takes input in the form of allele reports from either the genotype-calling software, GeneMapper or GeneMarker, and reconfigures the data into GENEPOP (Raymond & Rousset 1995), Rhh (Alho et al. 2010), RMES (David et al. 2007) and GEPHAST (Amos & Acevedo-Whitehouse 2009) formats. The script is also equipped to reformat the output from GENEPOP on the Web (option 5) and Rhh into csv spreadsheets that can be incorporated into downstream analyses. HeFPipe accommodates user-provided lists of samples and markers to be included in or excluded from analyses. HeFPipe is equipped to create generalized linear models (GLMs) from both the main data set and subsets of the data. Finally, HeFPipe allows users to explore single-marker effects and conduct correlation analyses. The script, a comprehensive manual, a link to a series of video tutorials, and an example data set are available from GitHub (http://github.com/Atticus29/HeFPipe_rpos)."	github.com/Atticus29/HeFPipe_rpos	https://github.com/Atticus29/HeFPipe_rpos/	Atticus29	HeFPipe_rpos			0	0		renamed	https://github.com/Atticus29/HeFPipe/
36535036	01/19/2023	10.1088/1741-2552/acacca	Journal of neural engineering	Transfer learning of an ensemble of DNNs for SSVEP BCI spellers without user-specific training.	"Steady-state visually evoked potentials (SSVEPs), measured with electroencephalogram (EEG), yield decent information transfer rates (ITRs) in brain-computer interface (BCI) spellers. However, the current high performing SSVEP BCI spellers in the literature require an initial lengthy and tiring user-specific training for each new user for system adaptation, including data collection with EEG experiments, algorithm training and calibration (all are before the actual use of the system). This impedes the widespread use of BCIs. To ensure practicality, we propose a novel target identification method based on an ensemble of deep neural networks (DNNs), which does not require any sort of user-specific training.We exploit already-existing literature datasets from participants of previously conducted EEG experiments to train a global target identifier DNN first, which is then fine-tuned to each participant. We transfer this ensemble of fine-tuned DNNs to the new user instance, determine themost representative DNNs according to the participants' statistical similarities to the new user, and predict the target character through a weighted combination of the ensemble predictions.The proposed method significantly outperforms all the state-of-the-art alternatives for all stimulation durations in [0.2-1.0] s on two large-scale benchmark and BETA datasets, and achieves impressive 155.51?bits/min and 114.64?bits/min ITRs. Code is available for reproducibility:https://github.com/osmanberke/Ensemble-of-DNNs.Our Ensemble-DNN method has the potential to promote the practical widespread deployment of BCI spellers in daily lives as we provide the highest performance while enabling the immediate system use without any user-specific training. "	github.com/osmanberke/Ensemble-of-DNNs.Our	https://github.com/osmanberke/Ensemble-of-DNNs.Our/	osmanberke	Ensemble-of-DNNs.Our			0	0		wrong link	https://github.com/osmanberke/Ensemble-of-DNNs/
35388017	04/08/2022	10.1038/s41598-022-08555-9	Scientific reports	A hybrid feature extraction scheme for efficient malonylation site prediction.	"Lysine malonylation is one of the most important post-translational modifications (PTMs). It affects the functionality of cells. Malonylation site prediction in proteins can unfold the mechanisms of cellular functionalities. Experimental methods are one of the due prediction approaches. But they are typically costly and time-consuming to implement. Recently, methods based on machine-learning solutions have been proposed to tackle this problem. Such practices have been shown to reduce costs and time complexities and increase accuracy. However, these approaches also have specific shortcomings, including inappropriate feature extraction out of protein sequences, high-dimensional features, and inefficient underlying classifiers. A machine learning-based method is proposed in this paper to cope with these problems. In the proposed approach, seven different features are extracted. Then, the extracted features are combined, ranked based on the Fisher's score (F-score), and the most efficient ones are selected. Afterward, malonylation sites are predicted using various classifiers. Simulation results show that the proposed method has acceptable performance compared with some state-of-the-art approaches. In addition, the XGBOOST classifier, founded on extracted features such as TFCRF, has a higher prediction rate than the other methods. The codes are publicly available at: https://github.com/jimy2020/Malonylation-site-prediction."	github.com/jimy2020/Malonylation-site-prediction.	https://github.com/jimy2020/Malonylation-site-prediction/	jimy2020	Malonylation-site-prediction			0	0		repo deleted	
30759232	10/28/2019	10.1093/nar/gkz067	Nucleic acids research	Structural variation and fusion detection using targeted sequencing data from circulating cell free DNA.	"Cancer is a complex disease that involves rapidly evolving cells, often forming multiple distinct clones. In order to effectively understand progression of a patient-specific tumor, one needs to comprehensively sample tumor DNA at multiple time points, ideally obtained through inexpensive and minimally invasive techniques. Current sequencing technologies make the 'liquid biopsy' possible, which involves sampling a patient's blood or urine and sequencing the circulating cell free DNA (cfDNA). A certain percentage of this DNA originates from the tumor, known as circulating tumor DNA (ctDNA). The ratio of ctDNA may be extremely low in the sample, and the ctDNA may originate from multiple tumors or clones. These factors present unique challenges for applying existing tools and workflows to the analysis of ctDNA, especially in the detection of structural variations which rely on sufficient read coverage to be detectable. Here we introduce SViCT?, a structural variation (SV) detection tool designed to handle the challenges associated with cfDNA analysis. SViCT?can detect breakpoints and sequences of various structural variations including deletions, insertions, inversions, duplications and translocations. SViCT?extracts discordant read pairs, one-end anchors and soft-clipped/split reads, assembles them into contigs, and re-maps contig intervals to a reference genome using an efficient k-mer indexing approach. The intervals are then joined using a combination of graph and greedy algorithms to identify specific structural variant signatures. We assessed the performance of SViCT?and compared it to state-of-the-art tools using simulated cfDNA datasets with properties matching those of real cfDNA samples. The positive predictive value and sensitivity of our tool was superior to all the tested tools and reasonable performance was maintained down to the lowest dilution of 0.01% tumor DNA in simulated datasets. Additionally, SViCT?was able to detect all known SVs in two real cfDNA reference datasets (at 0.6-5% ctDNA) and predict a novel structural variant in a prostate cancer cohort. SViCT?is available at https://github.com/vpc-ccg/svict. Contact:faraz.hach@ubc.ca. "	github.com/vpc-ccg/svict.\xa0Contact	https://github.com/vpc-ccg/svict.\xa0Contact/	vpc-ccg	svict.\xa0Contact			0	0		repo deleted	
29363427	08/29/2018	10.1186/s12864-017-4334-x	BMC genomics	GT-WGS: an efficient and economic tool for large-scale WGS analyses based on the AWS cloud service.	"Whole-genome sequencing (WGS) plays an increasingly important role in clinical practice and public health. Due to the big data size, WGS data analysis is usually compute-intensive and IO-intensive. Currently it usually takes 30 to 40 h to finish a 50? WGS analysis task, which is far from the ideal speed required by the industry. Furthermore, the high-end infrastructure required by WGS computing is costly in terms of time and money. In this paper, we aim to improve the time efficiency of WGS analysis and minimize the cost by elastic cloud computing. We developed a distributed system, GT-WGS, for large-scale WGS analyses utilizing the Amazon Web Services (AWS). Our system won the first prize on the Wind and Cloud challenge held by Genomics and Cloud Technology Alliance conference (GCTA) committee. The system makes full use of the dynamic pricing mechanism of AWS. We evaluate the performance of GT-WGS with a 55? WGS dataset (400GB fastq) provided by the GCTA 2017 competition. In the best case, it only took 18.4 min to finish the analysis and the AWS cost of the whole process is only 16.5 US dollars. The accuracy of GT-WGS is 99.9% consistent with that of the Genome Analysis Toolkit (GATK) best practice. We also evaluated the performance of GT-WGS performance on a real-world dataset provided by the XiangYa hospital, which consists of 5? whole-genome dataset with 500 samples, and on average GT-WGS managed to finish one 5? WGS analysis task in 2.4 min at a cost of $3.6. WGS is already playing an important role in guiding therapeutic intervention. However, its application is limited by the time cost and computing cost. GT-WGS excelled as an efficient and affordable WGS analyses tool to address this problem. The demo video and supplementary materials of GT-WGS can be accessed at https://github.com/Genetalks/wgs_analysis_demo . "	github.com/Genetalks/wgs_analysis_demo	https://github.com/Genetalks/wgs_analysis_demo/	Genetalks	wgs_analysis_demo			0	1	01/19/2021	repo deleted	
37028083	03/03/2023	10.1109/TBME.2023.3252368	IEEE transactions on bio-medical engineering	MSED: A Multi-Modal Sleep Event Detection Model for Clinical Sleep Analysis.	"Clinical sleep analysis require manual analysis of sleep patterns for correct diagnosis of sleep disorders. However, several studies have shown significant variability in manual scoring of clinically relevant discrete sleep events, such as arousals, leg movements, and sleep disordered breathing (apneas and hypopneas). We investigated whether an automatic method could be used for event detection and if a model trained on all events (joint model) performed better than corresponding event-specific models (single-event models). We trained a deep neural network event detection model on 1653 individual recordings and tested the optimized model on 1000 separate hold-out recordings. F1 scores for the optimized joint detection model were 0.70, 0.63, and 0.62 for arousals, leg movements, and sleep disordered breathing, respectively, compared to 0.65, 0.61, and 0.60 for the optimized single-event models. Index values computed from detected events correlated positively with manual annotations (r = 0.73, r = 0.77, r = 0.78, respectively). We furthermore quantified model accuracy based on temporal difference metrics, which improved overall by using the joint model compared to single-event models. Our automatic model jointly detects arousals, leg movements and sleep disordered breathing events with high correlation with human annotations. Finally, we benchmark against previous state-of-the-art multi-event detection models and found an overall increase in F1 score with our proposed model despite a 97.5% reduction in model size. Source code for training and inference is available at https://github.com/neergaard/msed.git. "	github.com/neergaard/msed.git.	https://github.com/neergaard/msed/	neergaard	msed			0	0		repo deleted	
32252628	12/18/2020	10.1186/s12864-020-6685-y	BMC genomics	Assessing graph-based read mappers against a baseline approach highlights strengths and weaknesses of current methods.	"Graph-based reference genomes have become popular as they allow read mapping and follow-up analyses in settings where the exact haplotypes underlying a high-throughput sequencing experiment are not precisely known. Two recent papers show that mapping to graph-based reference genomes can improve accuracy as compared to methods using linear references. Both of these methods index the sequences for most paths up to a certain length in the graph in order to enable direct mapping of reads containing common variants. However, the combinatorial explosion of possible paths through nearby variants also leads to a huge search space and an increased chance of false positive alignments to highly variable regions. We here assess three prominent graph-based read mappers against a hybrid baseline approach that combines an initial path determination with a tuned linear read mapping method. We show, using a previously proposed benchmark, that this simple approach is able to improve overall accuracy of read-mapping to graph-based reference genomes. Our method is implemented in a tool Two-step Graph Mapper, which is available at https://github.com/uio-bmi/two_step_graph_mapperalong with data and scripts for reproducing the experiments. Our method highlights characteristics of the current generation of graph-based read mappers and shows potential for improvement for future graph-based read mappers. "	github.com/uio-bmi/two_step_graph_mapperalong	https://github.com/uio-bmi/two_step_graph_mapperalong/	uio-bmi	two_step_graph_mapperalong			0	0		wrong link	https://github.com/uio-bmi/two_step_graph_mapper/
25135245	01/22/2015	10.1016/j.jclinepi.2014.06.012	Journal of clinical epidemiology	Open-source electronic data capture system offered increased accuracy and cost-effectiveness compared with paper methods in Africa.	"Existing electronic data capture options are often financially unfeasible in resource-poor settings or difficult to support technically in the field. To help facilitate large-scale multicenter studies in sub-Saharan Africa, the African Partnership for Chronic Disease Research (APCDR) has developed an open-source electronic questionnaire (EQ). To assess its relative validity, we compared the EQ against traditional pen-and-paper methods using 200 randomized interviews conducted in an ongoing type 2 diabetes case-control study in South Africa. During its 3-month validation, the EQ had a lower frequency of errors (EQ, 0.17 errors per 100 questions; paper, 0.73 errors per 100 questions; P-value ?0.001), and a lower monetary cost per correctly entered question, compared with the pen-and-paper method. We found no marked difference in the average duration of the interview between methods (EQ, 5.4 minutes; paper, 5.6 minutes). This validation study suggests that the EQ may offer increased accuracy, similar interview duration, and increased cost-effectiveness compared with paper-based data collection methods. The APCDR EQ software is freely available (https://github.com/apcdr/questionnaire). "	github.com/apcdr/questionnaire	https://github.com/apcdr/questionnaire/	apcdr	questionnaire			0	1	09/05/2016	owner deleted	
29722882	10/21/2019	10.1093/bioinformatics/bty353	"Bioinformatics (Oxford, England)"	Modeling one thousand intron length distributions with fitild.	"Intron length distribution (ILD) is a specific feature of a genome that exhibits extensive species-specific variation. Whereas ILD contributes to up to 30% of the total information content for intron recognition in some species, rendering it an important component of computational gene prediction, very few studies have been conducted to quantitatively characterize ILDs of various species. We developed a set of computer programs (fitild, compild, etc.) to build statistical models of ILDs and compare them with one another. Each ILD of more than 1000 genomes was fitted with fitild to a statistical model consisting of one, two, or three components of Frechet distributions. Several measures of distances between ILDs were calculated by compild. A theoretical model was presented to better understand the origin of the observed shape of an ILD. The C++?source codes are available at https://github.com/ogotoh/fitild.git/. Supplementary data are available at Bioinformatics online. "	github.com/ogotoh/fitild.git/.	https://github.com/ogotoh/fitild.git/	ogotoh	fitild.git			0	0		wrong link	https://github.com/ogotoh/fitild/
36279331	10/24/2022	10.1109/TNNLS.2022.3211149	IEEE transactions on neural networks and learning systems	Multimodal Moore-Penrose Inverse-Based Recomputation Framework for Big Data Analysis.	"Most multilayer Moore-Penrose inverse (MPI)-based neural networks, such as deep random vector functional link (RVFL), are structured with two separate stages: unsupervised feature encoding and supervised pattern classification. Once the unsupervised learning is finished, the latent encoding is fixed without supervised fine-tuning. However, in complex tasks such as handling the ImageNet dataset, there are often many more clues that can be directly encoded, while unsupervised learning, by definition, cannot know exactly what is useful for a certain task. There is a need to retrain the latent space representations in the supervised pattern classification stage to learn some clues that unsupervised learning has not yet been learned. In particular, the residual error in the output layer is pulled back to each hidden layer, and the parameters of the hidden layers are recalculated with MPI for more robust representations. In this article, a recomputation-based multilayer network using Moore-Penrose inverse (RML-MP) is developed. A sparse RML-MP (SRML-MP) model to boost the performance of RML-MP is then proposed. The experimental results with varying training samples (from 3k to 1.8 million) show that the proposed models provide higher Top-1 testing accuracy than most representation learning algorithms. For reproducibility, the source codes are available at https://github.com/W1AE/Retraining."	github.com/W1AE/Retraining.	https://github.com/W1AE/Retraining/	W1AE	Retraining			0	1	02/10/2023	repo deleted	
34061735	08/04/2022	10.1109/TPAMI.2021.3085525	IEEE transactions on pattern analysis and machine intelligence	Learning by Distillation: A Self-Supervised Learning Framework for Optical Flow Estimation.	"We present DistillFlow, a knowledge distillation approach to learning optical flow. DistillFlow trains multiple teacher models and a student model, where challenging transformations are applied to the input of the student model to generate hallucinated occlusions as well as less confident predictions. Then, a self-supervised learning framework is constructed: confident predictions from teacher models are served as annotations to guide the student model to learn optical flow for those less confident predictions. The self-supervised learning framework enables us to effectively learn optical flow from unlabeled data, not only for non-occluded pixels, but also for occluded pixels. DistillFlow achieves state-of-the-art unsupervised learning performance on both KITTI and Sintel datasets. Our self-supervised pre-trained model also provides an excellent initialization for supervised fine-tuning, suggesting an alternate training paradigm in contrast to current supervised learning methods that highly rely on pre-training on synthetic data. At the time of writing, our fine-tuned models ranked 1st among all monocular methods on the KITTI 2015 benchmark, and outperform all published methods on the Sintel Final benchmark. More importantly, we demonstrate the generalization capability of DistillFlow in three aspects: framework generalization, correspondence generalization and cross-dataset generalization. Our code and models will be available on https://github.com/ppliuboy/DistillFlow."	github.com/ppliuboy/DistillFlow.	https://github.com/ppliuboy/DistillFlow/	ppliuboy	DistillFlow			0	0		repo deleted	
26568629	08/04/2017	10.1093/bioinformatics/btv674	"Bioinformatics (Oxford, England)"	Accurate estimation of isoelectric point of protein and peptide based on amino acid sequences.	"In any macromolecular polyprotic system-for example protein, DNA or RNA-the isoelectric point-commonly referred to as the pI-can be defined as the point of singularity in a titration curve, corresponding to the solution pH value at which the net overall surface charge-and thus the electrophoretic mobility-of the ampholyte sums to zero. Different modern analytical biochemistry and proteomics methods depend on the isoelectric point as a principal feature for protein and peptide characterization. Protein separation by isoelectric point is a critical part of 2-D gel electrophoresis, a key precursor of proteomics, where discrete spots can be digested in-gel, and proteins subsequently identified by analytical mass spectrometry. Peptide fractionation according to their pI is also widely used in current proteomics sample preparation procedures previous to the LC-MS/MS analysis. Therefore accurate theoretical prediction of pI would expedite such analysis. While such pI calculation is widely used, it remains largely untested, motivating our efforts to benchmark pI prediction methods. Using data from the database PIP-DB and one publically available dataset as our reference gold standard, we have undertaken the benchmarking of pI calculation methods. We find that methods vary in their accuracy and are highly sensitive to the choice of basis set. The machine-learning algorithms, especially the SVM-based algorithm, showed a superior performance when studying peptide mixtures. In general, learning-based pI prediction methods (such as Cofactor, SVM and Branca) require a large training dataset and their resulting performance will strongly depend of the quality of that data. In contrast with Iterative methods, machine-learning algorithms have the advantage of being able to add new features to improve the accuracy of prediction. yperez@ebi.ac.uk The software and data are freely available at https://github.com/ypriverol/pIRSupplementary information: Supplementary data are available at Bioinformatics online. "	github.com/ypriverol/pIRSupplementary	https://github.com/ypriverol/pIRSupplementary/	ypriverol	pIRSupplementary			0	0		wrong link	https://github.com/bigbio/pIR/
29993710	05/25/2018	10.1109/TPAMI.2018.2840724	IEEE transactions on pattern analysis and machine intelligence	A Deep Network Solution for Attention and Aesthetics Aware Photo Cropping.	"We study the problem of photo cropping, which aims to find a cropping window of an input image to preserve as much as possible its important parts while being aesthetically pleasant. Seeking a deep learning-based solution, we design a neural network that has two branches for attention box prediction (ABP) and aesthetics assessment (AA), respectively. Given the input image, the ABP network predicts an attention bounding box as an initial minimum cropping window, around which a set of cropping candidates are generated with little loss of important information. Then, the AA network is employed to select the final cropping window with the best aesthetic quality among the candidates. The two sub-networks are designed to share the same full-image convolutional feature map, and thus are computationally efficient. By leveraging attention prediction and aesthetics assessment, the cropping model produces high-quality cropping results, even with the limited availability of training data for photo cropping. The experimental results on benchmark datasets clearly validate the effectiveness of the proposed approach. In addition, our approach runs at 5 fps, outperforming most previous solutions. The code and results are available at: https://github.com/shenjianbing/DeepCropping."	github.com/shenjianbing/DeepCropping.	https://github.com/shenjianbing/DeepCropping/	shenjianbing	DeepCropping			0	0		repo deleted	
35050855	01/28/2022	10.1109/TIP.2022.3142999	IEEE transactions on image processing : a publication of the IEEE Signal Processing Society	Learning Discrete Representations From Reference Images for Large Scale Factor Image Super-Resolution.	"Image super-resolution (SR) task aims to recover high-resolution (HR) images from degraded low-resolution (LR) images, which has achieved great progress due to the recent advances of deep neural networks. Due to severe information loss of the LR images, it is more challenging to reconstruct high quality HR images at large scale factors, i. e., higher than 4? . Traditional reference image based SR methods usually perform patch matching to locate detailed texture from HR reference images which could provide fine details from similar image contents. But it suffers from difficulties in achieving good matching in the largely downscaled image space or feature space due to the ill-posed nature between LR and HR mapping. In this paper, we tackle this problem by exploiting fine details contained in reference HR images. Inspired by vector quantization (VQ), we propose a simple yet effective auto-encoder convolutional neural network (CNN) module to learn discrete representations of images. Furthermore, we propose to progressively learn pairs of cross-scale discrete feature representations using paired LR and HR reference images. The coarser scale of the discrete representation is responsible for encoding the global image structure while the paired finer scale of the discrete representation takes charge of capturing missing details in the finer image scale. During inference, continuous features of the test LR image are used as queries to retrieve finer scale discrete representations (value) by searching the nearest coarser scale discrete representations (key). Then, the queries and retrieved values are combined to progressively recover the HR image. Experimental results indicate that when compared with the state-of-the-art image SR models, the proposed method can achieve advanced performance in terms of both objective quality and subjective quality. The code will be available on URL: https://github.com/sunwj/refsr."	github.com/sunwj/refsr.	https://github.com/sunwj/refsr/	sunwj	refsr			0	0		repo deleted	
27587659	07/31/2017	10.1093/bioinformatics/btw438	"Bioinformatics (Oxford, England)"	Combining dependent P-values with an empirical adaptation of Brown's method.	"Combining P-values from multiple statistical tests is a common exercise in bioinformatics. However, this procedure is non-trivial for dependent P-values. Here, we discuss an empirical adaptation of Brown's method (an extension of Fisher's method) for combining dependent P-values which is appropriate for the large and correlated datasets found in high-throughput biology. We show that the Empirical Brown's method (EBM) outperforms Fisher's method as well as alternative approaches for combining dependent P-values using both noisy simulated data and gene expression data from The Cancer Genome Atlas. The Empirical Brown's method is available in Python, R, and MATLAB and can be obtained from https://github.com/IlyaLab/CombiningDependentPvalues UsingEBM The R code is also available as a Bioconductor package from https://www.bioconductor.org/packages/devel/bioc/html/EmpiricalBrownsMethod.html Theo.Knijnenburg@systemsbiology.org Supplementary data are available at Bioinformatics online. "	github.com/IlyaLab/CombiningDependentPvalues	https://github.com/IlyaLab/CombiningDependentPvalues/	IlyaLab	CombiningDependentPvalues			0	0		wrong link	https://github.com/IlyaLab/CombiningDependentPvaluesUsingEBM/
34550884	09/29/2021	10.1109/TIP.2021.3113114	IEEE transactions on image processing : a publication of the IEEE Signal Processing Society	Action Anticipation Using Pairwise Human-Object Interactions and Transformers.	"The ability to anticipate future actions of humans is useful in application areas such as automated driving, robot-assisted manufacturing, and smart homes. These applications require representing and anticipating human actions involving the use of objects. Existing methods that use human-object interactions for anticipation require object affordance labels for every relevant object in the scene that match the ongoing action. Hence, we propose to represent every pairwise human-object (HO) interaction using only their visual features. Next, we use cross-correlation to capture the second-order statistics across human-object pairs in a frame. Cross-correlation produces a holistic representation of the frame that can also handle a variable number of human-object pairs in every frame of the observation period. We show that cross-correlation based frame representation is more suited for action anticipation than attention-based and other second-order approaches. Furthermore, we observe that using a transformer model for temporal aggregation of frame-wise HO representations results in better action anticipation than other temporal networks. So, we propose two approaches for constructing an end-to-end trainable multi-modal transformer (MM-Transformer; code at https://github.com/debadityaroy/MM-Transformer_ActAnt) model that combines the evidence across spatio-temporal, motion, and HO representations. We show the performance of MM-Transformer on procedural datasets like 50 Salads and Breakfast, and an unscripted dataset like EPIC-KITCHENS55. Finally, we demonstrate that the combination of human-object representation and MM-Transformers is effective even for long-term anticipation."	github.com/debadityaroy/MM-Transformer_ActAnt	https://github.com/debadityaroy/MM-Transformer_ActAnt/	debadityaroy	MM-Transformer_ActAnt			0	0		repo deleted	
30592175	07/25/2019	10.1002/brb3.1191	Brain and behavior	Copula directional dependence for inference and statistical analysis of whole-brain connectivity from fMRI data.	"Inferring connectivity between brain regions has been raising a lot of attention in recent decades. Copula directional dependence (CDD) is a statistical measure of directed connectivity, which does not require strict assumptions on probability distributions and linearity. In this work, CDDs between pairs of local brain areas were estimated based on the fMRI responses of human participants watching a Pixar animation movie. A directed connectivity map of fourteen predefined local areas was obtained for each participant, where the network structure was determined by the strengths of the CDDs. A resampling technique was further applied to determine the statistical significance of the connectivity directions in the networks. In order to demonstrate the effectiveness of the suggested method using CDDs, statistical group analysis was conducted based on graph theoretic measures of the inferred directed networks and CDD intensities. When the 129 fMRI participants were grouped by their age (3-5 year-old, 7-12 year-old, adult) and gender (F, M), nonparametric two-way analysis of variance (ANOVA) results could identify which cortical regions and connectivity structures correlated with the two physiological factors. Especially, we could identify that (a) graph centrality measures of the frontal eye fields (FEF), the inferior temporal gyrus (ITG), and the temporopolar area (TP) were significantly affected by aging, (b) CDD intensities between FEF and the primary motor cortex (M1) and between ITG and TP were highly significantly affected by aging, and (c) CDDs between M1 and the anterior prefrontal cortex (aPFC) were highly significantly affected by gender. The R source code for fMRI data preprocessing, estimation of directional dependences, network visualization, and statistical analyses are available at https://github.com/namgillee/CDDforFMRI. "	github.com/namgillee/CDDforFMRI.	https://github.com/namgillee/CDDforFMRI/	namgillee	CDDforFMRI			0	1	03/30/2020	repo deleted	
28968779	01/15/2018	10.1093/bioinformatics/btx545	"Bioinformatics (Oxford, England)"	A graph regularized non-negative matrix factorization method for identifying microRNA-disease associations.	"MicroRNAs (miRNAs) play crucial roles in post-transcriptional regulations and various cellular processes. The identification of disease-related miRNAs provides great insights into the underlying pathogenesis of diseases at a system level. However, most existing computational approaches are biased towards known miRNA-disease associations, which is inappropriate for those new diseases or miRNAs without any known association information. In this study, we propose a new method with graph regularized non-negative matrix factorization in heterogeneous omics data, called GRNMF, to discover potential associations between miRNAs and diseases, especially for new diseases and miRNAs or those diseases and miRNAs with sparse known associations. First, we integrate the disease semantic information and miRNA functional information to estimate disease similarity and miRNA similarity, respectively. Considering that there is no available interaction observed for new diseases or miRNAs, a preprocessing step is developed to construct the interaction score profiles that will assist in prediction. Next, a graph regularized non-negative matrix factorization framework is utilized to simultaneously identify potential associations for all diseases. The results indicated that our proposed method can effectively prioritize disease-associated miRNAs with higher accuracy compared with other recent approaches. Moreover, case studies also demonstrated the effectiveness of GRNMF to infer unknown miRNA-disease associations for those novel diseases and miRNAs. The code of GRNMF is freely available at https://github.com/XIAO-HN/GRNMF/. Supplementary data are available at Bioinformatics online. "	github.com/XIAO-HN/GRNMF/.	https://github.com/XIAO-HN/GRNMF/	XIAO-HN	GRNMF			0	1	01/23/2021	repo deleted	
34999162	03/21/2022	10.1016/j.mri.2022.01.004	Magnetic resonance imaging	Generalizing deep learning brain segmentation for skull removal and intracranial measurements.	"Total intracranial volume (TICV) and posterior fossa volume (PFV) are essential covariates for brain volumetric analyses with structural magnetic resonance imaging (MRI). Detailed whole brain segmentation provides a non-invasive way to measure brain regions. Furthermore, increasing neuroimaging data are distributed in a skull-stripped manner for privacy protection. Therefore, generalizing deep learning brain segmentation for skull removal and intracranial measurements is an appealing task. However, data availability is challenging due to a limited set of manually traced atlases with whole brain and TICV/PFV labels. In this paper, we employ U-Net tiles to achieve automatic TICV estimation and whole brain segmentation simultaneously on brains w/and w/o the skull. To overcome the scarcity of manually traced whole brain volumes, a transfer learning method is introduced to estimate additional TICV and PFV labels during whole brain segmentation in T1-weighted MRI. Specifically, U-Net tiles are first pre-trained using large-scale BrainCOLOR atlases without TICV and PFV labels, which are created by multi-atlas segmentation. Then the pre-trained models are refined by training the additional TICV and PFV labels using limited BrainCOLOR atlases. We also extend our method to handle skull-stripped brain MR images. From the results, our method provides promising whole brain segmentation and volume estimation results for both brains w/and w/o skull in terms of mean Dice similarity coefficients and mean surface distance and absolute volume similarity. This method has been made available in open source (https://github.com/MASILab/SLANTbrainSeg_skullstripped)."	github.com/MASILab/SLANTbrainSeg_skullstripped	https://github.com/MASILab/SLANTbrainSeg_skullstripped/	MASILab	SLANTbrainSeg_skullstripped			0	0		renamed	https://github.com/MASILab/SLANTbrainSeg/
35496629	03/23/2020	10.1039/c9ra11043g	RSC advances	Heterogeneous graph inference based on similarity network fusion for predicting lncRNA-miRNA interaction.	"LncRNA and miRNA are two non-coding RNA types that are popular in current research. LncRNA interacts with miRNA to regulate gene transcription, further affecting human health and disease. Accurate identification of lncRNA-miRNA interactions contributes to the in-depth study of the biological functions and mechanisms of non-coding RNA. However, relying on biological experiments to obtain interaction information is time-consuming and expensive. Considering the rapid accumulation of gene information and the few computational methods, it is urgent to supplement the effective computational models to predict lncRNA-miRNA interactions. In this work, we propose a heterogeneous graph inference method based on similarity network fusion (SNFHGILMI) to predict potential lncRNA-miRNA interactions. First, we calculated multiple similarity data, including lncRNA sequence similarity, miRNA sequence similarity, lncRNA Gaussian nuclear similarity, and miRNA Gaussian nuclear similarity. Second, the similarity network fusion method was employed to integrate the data and get the similarity network of lncRNA and miRNA. Then, we constructed a bipartite network by combining the known interaction network and similarity network of lncRNA and miRNA. Finally, the heterogeneous graph inference method was introduced to construct a prediction model. On the real dataset, the model SNFHGILMI achieved AUC of 0.9501 and 0.9426 ± 0.0035 based on LOOCV and 5-fold cross validation, respectively. Furthermore, case studies also demonstrate that SNFHGILMI is a high-performance prediction method that can accurately predict new lncRNA-miRNA interactions. The Matlab code and readme file of SNFHGILMI can be downloaded from https://github.com/cj-DaSE/SNFHGILMI."	github.com/cj-DaSE/SNFHGILMI.	https://github.com/cj-DaSE/SNFHGILMI/	cj-DaSE	SNFHGILMI			0	1	11/27/2020	renamed	https://github.com/cj-DaSE/SNFHGILMI-master/
36063528	09/05/2022	10.1109/TNNLS.2022.3199703	IEEE transactions on neural networks and learning systems	A Progressive Subnetwork Searching Framework for Dynamic Inference.	"Deep neural network (DNN) model compression is a popular and important optimization method for efficient and fast hardware acceleration. However, the compressed model is usually fixed, without the capability to tune the computing complexity (i.e., latency in hardware) on-the-fly, depending on dynamic latency requirements, workloads, and computing hardware resource allocation. To address this challenge, dynamic DNN with run-time adaption of computing structures has been constructed through training with a cross-entropy objective function consisting of multiple subnets sampled from the supernet. Our investigations in this work show that the performance of dynamic inference highly relies on the quality of subnet sampling. To construct a dynamic DNN with multiple high-quality subnets, we propose a progressive subnetwork searching framework, which is embedded with several proposed new techniques, including trainable noise ranking, channel-group sampling, selective fine-tuning, and subnet filtering. Our proposed framework empowers the target dynamic DNN with higher accuracy for all the subnets compared with prior works on both the Canadian Institute for Advanced Research dataset with 10 classes (CIFAR-10) and ImageNet datasets. Specifically, compared with United States-Neural Network (US-NN), our method achieves 0.9% average accuracy gain for Alexnet, 2.5% for ResNet18, 1.1% for Visual Geometry Group (VGG)11, and 0.58% for MobileNetv1, on the ImageNet dataset, respectively. Moreover, to demonstrate run-time tuning of computing latency of dynamic DNN in real computing system, we have deployed our constructed dynamic networks into Nvidia Titan graphics processing unit (GPU) and Intel Xeon central processing unit (CPU), showing great improvement over prior works. The code is available at https://github.com/ASU-ESIC-FAN-Lab/Dynamic-inference."	github.com/ASU-ESIC-FAN-Lab/Dynamic-inference.	https://github.com/ASU-ESIC-FAN-Lab/Dynamic-inference/	ASU-ESIC-FAN-Lab	Dynamic-inference			0	0		renamed	https://github.com/ASU-ESIC-FAN-Lab/TNNLS_Dynamic_inference/
34622551	03/04/2022	10.1002/minf.202100045	Molecular informatics	Generative Adversarial Networks for De Novo Molecular Design.	"In the chemical industry, the generation of novel molecular structures with beneficial pharmacological and physicochemical properties in de novo molecular design is a critical problem. The advent of deep learning and neural generative models has recently enabled significant achievements in constructing molecular design models in de novo design. Consequently, studies on new generative models continue to generate molecules that exhibit more useful chemical properties. In this study, we propose a method for de novo design that utilizes generative adversarial networks based on reinforcement learning for realistic molecule generation. This method learns to reproduce the training data distribution of simplified molecular-input line-entry system strings. The proposed method is demonstrated to effectively generate novel molecular structures from five benchmark results using a real-world public dataset, ChEMBL. The code is available at https://github.com/dudwojae/SMILES-MaskGAN."	github.com/dudwojae/SMILES-MaskGAN.	https://github.com/dudwojae/SMILES-MaskGAN/	dudwojae	SMILES-MaskGAN			0	1	04/16/2023	repo deleted	
22689644	12/12/2012	10.1093/nar/gks552	Nucleic acids research	MFEprimer-2.0: a fast thermodynamics-based program for checking PCR primer specificity.	"Evaluating the specificity of polymerase chain reaction (PCR) primers is an essential step in PCR primer design. The MFEprimer-2.0 server allows users to check primer specificity against genomic DNA and messenger RNA/complementary DNA sequence databases quickly and easily. MFEprimer-2.0 uses a k-mer index algorithm to accelerate the search process for primer binding sites and uses thermodynamics to evaluate binding stability between each primer and its DNA template. Several important characteristics, such as the sequence, melting temperature and size of each amplicon, either specific or non-specific, are reported on the results page. Based on these characteristics and the user-friendly output, users can readily draw conclusions about the specificity of PCR primers. Analyses for degenerate primers and multiple PCR primers are also supported in MFEprimer-2.0. In addition, the databases supported by MFEprimer-2.0 are comprehensive, and custom databases can also be supported on request. The MFEprimer-2.0 server does not require a login and is freely available at http://biocompute.bmi.ac.cn/CZlab/MFEprimer-2.0. More over, the MFEprimer-2.0 command-line version and local server version are open source and can be downloaded at https://github.com/quwubin/MFEprimer/wiki/Manual/."	github.com/quwubin/MFEprimer/wiki/Manual/.	https://github.com/quwubin/MFEprimer/wiki/Manual/	quwubin	MFEprimer			0	0		repo deleted	
36260571	04/11/2023	10.1109/TMI.2022.3215798	IEEE transactions on medical imaging	A Framework for Simulating Cardiac MR Images With Varying Anatomy and Contrast.	"One of the limiting factors for the development and adoption of novel deep-learning (DL) based medical image analysis methods is the scarcity of labeled medical images. Medical image simulation and synthesis can provide solutions by generating ample training data with corresponding ground truth labels. Despite recent advances, generated images demonstrate limited realism and diversity. In this work, we develop a flexible framework for simulating cardiac magnetic resonance (MR) images with variable anatomical and imaging characteristics for the purpose of creating a diversified virtual population. We advance previous works on both cardiac MR image simulation and anatomical modeling to increase the realism in terms of both image appearance and underlying anatomy. To diversify the generated images, we define parameters: 1)to alter the anatomy, 2) to assign MR tissue properties to various tissue types, and 3) to manipulate the image contrast via acquisition parameters. The proposed framework is optimized to generate a substantial number of cardiac MR images with ground truth labels suitable for downstream supervised tasks. A database of virtual subjects is simulated and its usefulness for aiding a DL segmentation method is evaluated. Our experiments show that training completely with simulated images can perform comparable with a model trained with real images for heart cavity segmentation in mid-ventricular slices. Moreover, such data can be used in addition to classical augmentation for boosting the performance when training data is limited, particularly by increasing the contrast and anatomical variation, leading to better regularization and generalization. The database is publicly available at https://osf.io/bkzhm/ and the simulation code will be available at https://github.com/sinaamirrajab/CMRI."	github.com/sinaamirrajab/CMRI.	https://github.com/sinaamirrajab/CMRI/	sinaamirrajab	CMRI			0	0		renamed	https://github.com/sinaamirrajab/CMRI_Simulation/
36244303	09/30/2022	10.1016/j.compbiomed.2022.106151	Computers in biology and medicine	NSCGCN: A novel deep GCN model to diagnosis COVID-19.	"Corona Virus Disease 2019 (COVID-19) was a lung disease with high mortality and was highly contagious. Early diagnosis of COVID-19 and distinguishing it from pneumonia was beneficial for subsequent treatment. Recently, Graph Convolutional Network (GCN) has driven a significant contribution to disease diagnosis. However, limited by the nature of the graph convolution algorithm, deep GCN has an over-smoothing problem. Most of the current GCN models are shallow neural networks, which do not exceed five layers. Furthermore, the objective of this study is to develop a novel deep GCN model based on the DenseGCN and the pre-trained model of deep Convolutional Neural Network (CNN) to complete the diagnosis of chest X-ray (CXR) images. We apply the pre-trained model of deep CNN to perform feature extraction on the data to complete the extraction of pixel-level features in the image. And then, to extract the potential relationship between the obtained features, we propose Neighbourhood Feature Reconstruction Algorithm to reconstruct them into graph-structured data. Finally, we design a deep GCN model that exploits the graph-structured data to diagnose COVID-19 effectively. In the deep GCN model, we propose a Node-Self Convolution Algorithm (NSC) based on feature fusion to construct a deep GCN model called NSCGCN (Node-Self Convolution Graph Convolutional Network). Experiments were carried out on the Computed Tomography (CT) and CXR datasets. The results on the CT dataset confirmed that: compared with the six state-of-the-art (SOTA) shallow GCN models, the accuracy and sensitivity of the proposed NSCGCN had improve 8% as sensitivity (Sen.) = 87.50%, F1 score = 97.37%, precision (Pre.) = 89.10%, accuracy (Acc.) = 97.50%, area under the ROC curve (AUC) = 97.09%. Moreover, the results on the CXR dataset confirmed that: compared with the fourteen SOTA GCN models, sixteen SOTA CNN transfer learning models and eight SOTA COVID-19 diagnosis methods on the COVID-19 dataset. Our proposed method had best performances as Sen. = 96.45%, F1 score = 96.45%, Pre. = 96.61%, Acc. = 96.45%, AUC = 99.22%. Our proposed NSCGCN model is effective and performed better than the thirty-eight SOTA methods. Thus, the proposed NSC could help build deep GCN models. Our proposed COVID-19 diagnosis method based on the NSCGCN model could help radiologists detect pneumonia from CXR images and distinguish COVID-19 from Ordinary Pneumonia (OPN). The source code of this work will be publicly available at https://github.com/TangChaosheng/NSCGCN. "	github.com/TangChaosheng/NSCGCN.	https://github.com/TangChaosheng/NSCGCN/	TangChaosheng	NSCGCN			0	0		repo deleted	
35452387	05/30/2022	10.1109/TUFFC.2022.3169684	"IEEE transactions on ultrasonics, ferroelectrics, and frequency control"	LVNet: Lightweight Model for Left Ventricle Segmentation for Short Axis Views in Echocardiographic Imaging.	"Lightweight segmentation models are becoming more popular for fast diagnosis on small and low cost medical imaging devices. This study focuses on the segmentation of the left ventricle (LV) in cardiac ultrasound (US) images. A new lightweight model [LV network (LVNet)] is proposed for segmentation, which gives the benefits of requiring fewer parameters but with improved segmentation performance in terms of Dice score (DS). The proposed model is compared with state-of-the-art methods, such as UNet, MiniNetV2, and fully convolutional dense dilated network (FCdDN). The model proposed comes with a post-processing pipeline that further enhances the segmentation results. In general, the training is done directly using the segmentation mask as the output and the US image as the input of the model. A new strategy for segmentation is also introduced in addition to the direct training method used. Compared with the UNet model, an improvement in DS performance as high as 5% for segmentation with papillary (WP) muscles was found, while showcasing an improvement of 18.5% when the papillary muscles are excluded. The model proposed requires only 5% of the memory required by a UNet model. LVNet achieves a better trade-off between the number of parameters and its segmentation performance as compared with other conventional models. The developed codes are available at https://github.com/navchetanawasthi/Left_Ventricle_Segmentation."	github.com/navchetanawasthi/Left_Ventricle_Segmentation.	https://github.com/navchetanawasthi/Left_Ventricle_Segmentation/	navchetanawasthi	Left_Ventricle_Segmentation			0	0		repo deleted	
26248314	05/06/2016	10.1371/journal.pone.0135028	PloS one	gPGA: GPU Accelerated Population Genetics Analyses.	"The isolation with migration (IM) model is important for studies in population genetics and phylogeography. IM program applies the IM model to genetic data drawn from a pair of closely related populations or species based on Markov chain Monte Carlo (MCMC) simulations of gene genealogies. But computational burden of IM program has placed limits on its application. With strong computational power, Graphics Processing Unit (GPU) has been widely used in many fields. In this article, we present an effective implementation of IM program on one GPU based on Compute Unified Device Architecture (CUDA), which we call gPGA. Compared with IM program, gPGA can achieve up to 52.30X speedup on one GPU. The evaluation results demonstrate that it allows datasets to be analyzed effectively and rapidly for research on divergence population genetics. The software is freely available with source code at https://github.com/chunbaozhou/gPGA. "	github.com/chunbaozhou/gPGA.	https://github.com/chunbaozhou/gPGA/	chunbaozhou	gPGA			0	0		repo deleted	
34459713	12/23/2022	10.1080/07391102.2021.1970628	Journal of biomolecular structure & dynamics	6 M6A-GSMS: Computational identification of N-methyladenosine sites with GBDT and stacking learning in multiple species. 	"N-methyladenosine (mA) is one of the most abundant forms of RNA methylation modifications currently known. It involves a wide range of biological processes, including degradation, stability, alternative splicing, etc. Therefore, the development of convenient and efficient mA prediction technologies are urgent. In this work, a novel predictor based on GBDT and stacking learning is developed to identify mA sites, which is called M6A-GSMS. To achieve accurate prediction, we explore RNA sequence information from four aspects: correlation, structure, physicochemical properties and pseudo ribonucleic acid composition. After using the GBDT algorithm for feature selection, a stacking model is constructed by combining seven basic classifiers. Compared with other state-of-the-art methods, the results show that M6A-GSMS can obtain excellent performance for identifying the mA sites. The prediction accuracy of , , ,  and  reaches 88.4%, 60.8%, 80.5%, 92.4% and 61.8%, respectively. This method provides an effective prediction for the investigation of mA sites. In addition, all the datasets and codes are currently available at https://github.com/Wang-Jinyue/M6A-GSMS.Communicated by Ramaswamy H. Sarma. "	github.com/Wang-Jinyue/M6A-GSMS.Communicated	https://github.com/Wang-Jinyue/M6A-GSMS.Communicated/	Wang-Jinyue	M6A-GSMS.Communicated			0	0		wrong link	https://github.com/Wang-Jinyue/M6A-GSMS/
28092529	01/16/2017	10.1109/TMI.2017.2653623	IEEE transactions on medical imaging	Sub-Category Classifiers for Multiple-Instance Learning and its Application to Retinal Nerve Fiber Layer Visibility Classification.	"We propose a novel multiple instance learning method to assess the visibility (visible/not visible) of the retinal nerve fiber layer (RNFL) in fundus camera images. Using only image-level labels, our approach learns to classify the images as well as to localize the RNFL visible regions. We transform the original feature space to a discriminative subspace, and learn a region-level classifier in that subspace. We propose a margin-based loss function to jointly learn this subspace and the region-level classifier. Experiments with a RNFL dataset containing 884 images annotated by two ophthalmologists give a system-annotator agreement (kappa values) of 0:73 and 0:72 respectively, with an inter-annotator agreement of 0:73. Our system agrees better with the more experienced annotator. Comparative tests with three public datasets (MESSIDOR and DR for diabetic retinopathy, UCSB for breast cancer) show that our novel MIL approach improves performance over the state-of-the-art. Our Matlab code is publicly available at https://github.com/ManiShiyam/Sub-category-classifiersfor- Multiple-Instance-Learning/wiki."	github.com/ManiShiyam/Sub-category-classifiersfor-	https://github.com/ManiShiyam/Sub-category-classifiersfor-/	ManiShiyam	Sub-category-classifiersfor-			0	0		wrong link	https://github.com/ManiShiyam/Sub-category-classifiers-for-Multiple-Instance-Learning/
33636485	06/03/2021	10.1016/j.neunet.2021.01.022	Neural networks : the official journal of the International Neural Network Society	Towards effective deep transfer via attentive feature alignment.	"Training a deep convolutional network from scratch requires a large amount of labeled data, which however may not be available for many practical tasks. To alleviate the data burden, a practical approach is to adapt a pre-trained model learned on the large source domain to the target domain, but the performance can be limited when the source and target domain data distributions have large differences. Some recent works attempt to alleviate this issue by imposing feature alignment over the intermediate feature maps between the source and target networks. However, for a source model, many of the channels/spatial-features for each layer can be irrelevant to the target task. Thus, directly applying feature alignment may not achieve promising performance. In this paper, we propose an Attentive Feature Alignment (AFA) method for effective domain knowledge transfer by identifying and attending on the relevant channels and spatial features between two domains. To this end, we devise two learnable attentive modules at both the channel and spatial levels. We then sequentially perform attentive spatial- and channel-level feature alignments between the source and target networks, in which the target model and attentive module are learned simultaneously. Moreover, we theoretically analyze the generalization performance of our method, which confirms its superiority to existing methods. Extensive experiments on both image classification and face recognition demonstrate the effectiveness of our method. The source code and the pre-trained models are available at https://github.com/xiezheng-cs/AFAhttps://github.com/xiezheng-cs/AFA."	github.com/xiezheng-cs/AFAhttps	https://github.com/xiezheng-cs/AFAhttps/	xiezheng-cs	AFAhttps			0	0		wrong link	https://github.com/xiezheng-cs/AFA/
34430072	08/04/2021	10.7717/peerj.11581	PeerJ	iSUMOK-PseAAC: prediction of lysine sumoylation sites using statistical moments and Chou's PseAAC.	"Sumoylation is the post-translational modification that is involved in the adaption of the cells and the functional properties of a large number of proteins. Sumoylation has key importance in subcellular concentration, transcriptional synchronization, chromatin remodeling, response to stress, and regulation of mitosis. Sumoylation is associated with developmental defects in many human diseases such as cancer, Huntington's, Alzheimer's, Parkinson's, Spin cerebellar ataxia 1, and amyotrophic lateral sclerosis. The covalent bonding of Sumoylation is essential to inheriting part of the operative characteristics of some other proteins. For that reason, the prediction of the Sumoylation site has significance in the scientific community. A novel and efficient technique is proposed to predict the Sumoylation sites in proteins by incorporating Chou's Pseudo Amino Acid Composition (PseAAC) with statistical moments-based features. The outcomes from the proposed system using 10 fold cross-validation testing are 94.51%, 94.24%, 94.79% and 0.8903% accuracy, sensitivity, specificity and MCC, respectively. The performance of the proposed system is so far the best in comparison to the other state-of-the-art methods. The codes for the current study are available on the GitHub repository using the link: https://github.com/csbioinfopk/iSumoK-PseAAC."	github.com/csbioinfopk/iSumoK-PseAAC.	https://github.com/csbioinfopk/iSumoK-PseAAC/	csbioinfopk	iSumoK-PseAAC			0	1	04/14/2023	repo deleted	
33999820	05/21/2021	10.1109/TIP.2021.3078079	IEEE transactions on image processing : a publication of the IEEE Signal Processing Society	Adaptive Linear Span Network for Object Skeleton Detection.	"Conventional networks for object skeleton detection are usually hand-crafted. Despite the effectiveness, hand-crafted network architectures lack the theoretical basis and require intensive prior knowledge to implement representation complementarity for objects/parts in different granularity. In this paper, we propose an adaptive linear span network (AdaLSN), driven by neural architecture search (NAS), to automatically configure and integrate scale-aware features for object skeleton detection. AdaLSN is formulated with the theory of linear span, which provides one of the earliest explanations for multi-scale deep feature fusion. AdaLSN is materialized by defining a mixed unit-pyramid search space, which goes beyond many existing search spaces using unit-level or pyramid-level features. Within the mixed space, we apply genetic architecture search to jointly optimize unit-level operations and pyramid-level connections for adaptive feature space expansion. AdaLSN substantiates its versatility by achieving significantly higher accuracy and latency trade-off compared with the state-of-the-arts. It also demonstrates general applicability to image-to-mask tasks such as edge detection and road extraction. Code is available at https://github.com/sunsmarterjie/SDL-Skeletongithub.com/sunsmarterjie/SDL-Skeleton."	github.com/sunsmarterjie/SDL-Skeletongithub.com/sunsmarterjie/SDL-Skeleton.	https://github.com/sunsmarterjie/SDL-Skeletongithub.com/sunsmarterjie/SDL-Skeleton/	sunsmarterjie	SDL-Skeletongithub.com			0	0		wrong link	https://github.com/sunsmarterjie/SDL-Skeleton/
36071071	09/09/2022	10.1038/s41598-022-19099-3	Scientific reports	A machine learning technique for identifying DNA enhancer regions utilizing CIS-regulatory element patterns.	"Enhancers regulate gene expression, by playing a crucial role in the synthesis of RNAs and proteins. They do not directly encode proteins or RNA molecules. In order to control gene expression, it is important to predict enhancers and their potency. Given their distance from the target gene, lack of common motifs, and tissue/cell specificity, enhancer regions are thought to be difficult to predict in DNA sequences. Recently, a number of bioinformatics tools were created to distinguish enhancers from other regulatory components and to pinpoint their advantages. However, because the quality of its prediction method needs to be improved, its practical application value must also be improved. Based on nucleotide composition and statistical moment-based features, the current study suggests a novel method for identifying enhancers and non-enhancers and evaluating their strength. The proposed study outperformed state-of-the-art techniques using fivefold and tenfold cross-validation in terms of accuracy. The accuracy from the current study results in 86.5% and 72.3% in enhancer site and its strength prediction respectively. The results of the suggested methodology point to the potential for more efficient and successful outcomes when statistical moment-based features are used. The current study's source code is available to the research community at https://github.com/csbioinfopk/enpred ."	github.com/csbioinfopk/enpred	https://github.com/csbioinfopk/enpred/	csbioinfopk	enpred			0	0		repo deleted	
32183707	06/01/2020	10.1186/s12859-020-3428-7	BMC bioinformatics	LCQS: an efficient lossless compression tool of quality scores with random access functionality.	"Advanced sequencing machines dramatically speed up the generation of genomic data, which makes the demand of efficient compression of sequencing data extremely urgent and significant. As the most difficult part of the standard sequencing data format FASTQ, compression of the quality score has become a conundrum in the development of FASTQ compression. Existing lossless compressors of quality scores mainly utilize specific patterns generated by specific sequencer and complex context modeling techniques to solve the problem of low compression ratio. However, the main drawbacks of these compressors are the problem of weak robustness which means unstable or even unavailable results of sequencing files and the problem of slow compression speed. Meanwhile, some compressors attempt to construct a fine-grained index structure to solve the problem of slow random access decompression speed. However, they solve the problem at the sacrifice of compression speed and at the expense of large index files, which makes them inefficient and impractical. Therefore, an efficient lossless compressor of quality scores with strong robustness, high compression ratio, fast compression and random access decompression speed is urgently needed and of great significance. In this paper, based on the idea of maximizing the use of hardware resources, LCQS, a lossless compression tool specialized for quality scores, was proposed. It consists of four sequential processing steps: partitioning, indexing, packing and parallelizing. Experimental results reveal that LCQS outperforms all the other state-of-the-art compressors on all criteria except for the compression speed on the dataset SRR1284073. Furthermore, LCQS presents strong robustness on all the test datasets, with its acceleration ratios of compression speed increasing by up to 29.1x, its file size reducing by up to 28.78%, and its random access decompression speed increasing by up to 2.1x. Additionally, LCQS also exhibits strong scalability. That is, the compression speed increases almost linearly as the size of input dataset increases. The ability to handle all different kinds of quality scores and superiority in compression ratio and compression speed make LCQS a high-efficient and advanced lossless quality score compressor, along with its strength of fast random access decompression. Our tool LCQS can be downloaded from https://github.com/SCUT-CCNL/LCQSand freely available for non-commercial usage. "	github.com/SCUT-CCNL/LCQSand	https://github.com/SCUT-CCNL/LCQSand/	SCUT-CCNL	LCQSand			0	0		renamed	https://github.com/SCUT-CCNL/LCQS/
31870979	12/23/2019	10.1109/TPAMI.2019.2961672	IEEE transactions on pattern analysis and machine intelligence	Learned Dynamic Guidance for Depth Image Reconstruction.	"The depth images acquired by consumer depth sensors (e.g., Kinect and ToF) usually are of low resolution and insufficient quality. One natural solution is to incorporate a high resolution RGB camera and exploit the statistical correlation of its data and depth. In recent years, both optimization-based and learning-based approaches have been proposed to deal with the guided depth reconstruction problems. In this paper, we introduce a weighted analysis sparse representation (WASR) model for guided depth image enhancement, which can be considered a generalized formulation of a wide range of previous optimization-based models. We unfold the optimization by the WASR model and conduct guided depth reconstruction with dynamically changed stage-wise operations. Such a guidance strategy enables us to dynamically adjust the stage-wise operations that update the depth image, thus improving the reconstruction quality and speed. To learn the stage-wise operations in a task-driven manner, we propose two parameterizations and their corresponding methods: dynamic guidance with Gaussian RBF nonlinearity parameterization (DG-RBF) and dynamic guidance with CNN nonlinearity parameterization (DG-CNN). The network structures of the proposed DG-RBF and DG-CNN methods are designed with the the objective function of our WASR model in mind and the optimal network parameters are learned from paired training data. Such optimization-inspired network architectures enable our models to leverage the previous expertise as well as take benefit from training data. The effectiveness is validated for guided depth image super-resolution and for realistic depth image reconstruction tasks using standard benchmarks. Our DG-RBF and DG-CNN methods achieve the best quantitative results (RMSE) and better visual quality than the state-of-the-art approaches at the time of writing. The code is available at https://github.com/ShuhangGu/GuidedDepthSR."	github.com/ShuhangGu/GuidedDepthSR.	https://github.com/ShuhangGu/GuidedDepthSR/	ShuhangGu	GuidedDepthSR			0	0		repo deleted	
31141124	06/30/2020	10.1093/bioinformatics/btz420	"Bioinformatics (Oxford, England)"	Smart computational exploration of stochastic gene regulatory network models using human-in-the-loop semi-supervised learning.	"Discrete stochastic models of gene regulatory network models are indispensable tools for biological inquiry since they allow the modeler to predict how molecular interactions give rise to nonlinear system output. Model exploration with the objective of generating qualitative hypotheses about the workings of a pathway is usually the first step in the modeling process. It involves simulating the gene network model under a very large range of conditions, due to the large uncertainty in interactions and kinetic parameters. This makes model exploration highly computational demanding. Furthermore, with no prior information about the model behavior, labor-intensive manual inspection of very large amounts of simulation results becomes necessary. This limits systematic computational exploration to simplistic models. We have developed an interactive, smart workflow for model exploration based on semi-supervised learning and human-in-the-loop labeling of data. The workflow lets a modeler rapidly discover ranges of interesting behaviors predicted by the model. Utilizing that similar simulation output is in proximity of each other in a feature space, the modeler can focus on informing the system about what behaviors are more interesting than others by labeling, rather than analyzing simulation results with custom scripts and workflows. This results in a large reduction in time-consuming manual work by the modeler early in a modeling project, which can substantially reduce the time needed to go from an initial model to testable predictions and downstream analysis. A python-package is available at https://github.com/Wrede/mio.git. Supplementary data are available at Bioinformatics online. "	github.com/Wrede/mio.git.	https://github.com/Wrede/mio/	Wrede	mio			0	0		repo deleted	
31315562	09/13/2019	10.1186/s12859-019-2980-5	BMC bioinformatics	MCtandem: an efficient tool for large-scale peptide identification on many integrated core (MIC) architecture.	"Tandem mass spectrometry (MS/MS)-based database searching is a widely acknowledged and widely used method for peptide identification in shotgun proteomics. However, due to the rapid growth of spectra data produced by advanced mass spectrometry and the greatly increased number of modified and digested peptides identified in recent years, the current methods for peptide database searching cannot rapidly and thoroughly process large MS/MS spectra datasets. A breakthrough in efficient database search algorithms is crucial for peptide identification in computational proteomics. This paper presents MCtandem, an efficient tool for large-scale peptide identification on Intel Many Integrated Core (MIC) architecture. To support big data processing capability, a novel parallel match scoring algorithm, named MIC-SDP (spectrum dot product), and its two-level parallelization are presented in MCtandem's design. In addition, a series of optimization strategies on both the host CPU side and the MIC side, which includes pre-fetching, optimized communication overlapping scheme, multithreading and hyper-threading, are exploited to improve the execution performance. For fair comparisons, we first set up experiments and verified the 28 fold times speedup on a single MIC against the original CPU-based implementation. We then execute the MCtandem for a very large dataset on an MIC cluster (a component of the Tianhe-2 supercomputer) and achieved much higher scalability than in a benchmark MapReduce-based programs, MR-Tandem. MCtandem is an open-source software tool implemented in C++. The source code and the parameter settings are available at https://github.com/LogicZY/MCtandem . "	github.com/LogicZY/MCtandem	https://github.com/LogicZY/MCtandem/	LogicZY	MCtandem			0	1	04/15/2021	repo deleted	
27153590	08/21/2017	10.1093/bioinformatics/btw149	"Bioinformatics (Oxford, England)"	chopBAI: BAM index reduction solves I/O bottlenecks in the joint analysis of large sequencing cohorts.	"Advances in sequencing capacity have led to the generation of unprecedented amounts of genomic data. The processing of this data frequently leads to I/O bottlenecks, e. g. when analyzing a small genomic region across a large number of samples. The largest I/O burden is, however, often not imposed by the amount of data needed for the analysis but rather by index files that help retrieving this data. We have developed chopBAI, a program that can chop a BAM index (BAI) file into small pieces. The program outputs a list of BAI files each indexing a specified genomic interval. The output files are much smaller in size but maintain compatibility with existing software tools. We show how preprocessing BAI files with chopBAI can lead to a reduction of I/O by more than 95% during the analysis of 10?kb genomic regions, eventually enabling the joint analysis of more than 10 000 individuals. The software is implemented in C?++, GPL licensed and available at http://github.com/DecodeGenetics/chopBAIContact:birte.kehr@decode.is. "	github.com/DecodeGenetics/chopBAIContact	https://github.com/DecodeGenetics/chopBAIContact/	DecodeGenetics	chopBAIContact			0	0		wrong link	https://github.com/DecodeGenetics/chopBAI/
33763518	03/19/2021	10.1002/trc2.12147	"Alzheimer's & dementia (New York, N. Y.)"	Multilingual automation of transcript preprocessing in Alzheimer's disease detection.	"Analyzing linguistic functions can improve early detection of Alzheimer's disease (AD). To date, no studies have focused on creating a universal pipeline for clinical transcript preprocessing. This article presents a simple and efficient method for processing linguistic and phonetic data, sequencing subproblems of cleaning, normalization, and measure extraction tasks. Because some of these tasks are language- and context- dependent, they were designed to be easily configurable, thus increasing their scalability when dealing with new corpora. Results show improved performances over previous studies in this time-consuming preprocessing task. Moreover, our findings showed that some discursive markers extracted from transcripts revealed a significant correlation (>0.5) with cognitive impairment severity. This article contributes to the literature on AD by presenting an efficient pipeline that allows speeding up the transcripts preprocessing task. We further invite other researchers to contribute to this work to help improve the quality of this pipeline (https://github.com/LiNCS-lab/usAge). "	github.com/LiNCS-lab/usAge	https://github.com/LiNCS-lab/usAge/	LiNCS-lab	usAge			0	1	04/16/2023	repo deleted	
32777813	05/20/2021	10.1093/bioinformatics/btaa710	"Bioinformatics (Oxford, England)"	A public website for the automated assessment and validation of SARS-CoV-2 diagnostic PCR assays.	"Polymerase chain reaction-based assays are the current gold standard for detecting and diagnosing SARS-CoV-2. However, as SARS-CoV-2 mutates, we need to constantly assess whether existing PCR-based assays will continue to detect all known viral strains. To enable the continuous monitoring of SARS-CoV-2 assays, we have developed a web-based assay validation algorithm that checks existing PCR-based assays against the ever-expanding genome databases for SARS-CoV-2 using both thermodynamic and edit-distance metrics. The assay-screening results are displayed as a heatmap, showing the number of mismatches between each detection and each SARS-CoV-2 genome sequence. Using a mismatch threshold to define detection failure, assay performance is summarized with the true-positive rate (recall) to simplify assay comparisons. The assay evaluation website and supporting software are Open Source and freely available at https://covid19.edgebioinformatics.org/#/assayValidation, https://github.com/jgans/thermonucleotide BLAST and https://github.com/LANL-Bioinformatics/assay_validation. Supplementary data are available at Bioinformatics online. "	github.com/jgans/thermonucleotide	https://github.com/jgans/thermonucleotide/	jgans	thermonucleotide			0	0		wrong link	https://github.com/jgans/thermonucleotideBLAST/
37018641	01/10/2023	10.1109/TIP.2023.3234497	IEEE transactions on image processing : a publication of the IEEE Signal Processing Society	Unsupervised Adaptive Feature Selection with Binary Hashing.	"Unsupervised feature selection chooses a subset of discriminative features to reduce feature dimension under the unsupervised learning paradigm. Although lots of efforts have been made so far, existing solutions perform feature selection either without any label guidance or with only single pseudo label guidance. They may cause significant information loss and lead to semantic shortage of the selected features as many real-world data, such as images and videos are generally annotated with multiple labels. In this paper, we propose a new Unsupervised Adaptive Feature Selection with Binary Hashing (UAFS-BH) model, which learns binary hash codes as weakly-supervised multi-labels and simultaneously exploits the learned labels to guide feature selection. Specifically, in order to exploit the discriminative information under the unsupervised scenarios, the weakly-supervised multi-labels are learned automatically by specially imposing binary hash constraints on the spectral embedding process to guide the ultimate feature selection. The number of weakly-supervised multi-labels (the number of ""1"" in binary hash codes) is adaptively determined according to the specific data content. Further, to enhance the discriminative capability of binary labels, we model the intrinsic data structure by adaptively constructing the dynamic similarity graph. Finally, we extend UAFS-BH to multi-view setting as Multi-view Feature Selection with Binary Hashing (MVFS-BH) to handle the multi-view feature selection problem. An effective binary optimization method based on the Augmented Lagrangian Multiple (ALM) is derived to iteratively solve the formulated problem. Extensive experiments on widely tested benchmarks demonstrate the state-of-the-art performance of the proposed method on both single-view and multi-view feature selection tasks. For the purpose of reproducibility, we provide the source codes and testing datasets at https://github.com/shidan0122/UMFS.git.."	github.com/shidan0122/UMFS.git..	https://github.com/shidan0122/UMFS.git./	shidan0122	UMFS.git.			0	0		wrong link	https://github.com/shidan0122/UMFS/
35731773	04/07/2023	10.1109/TPAMI.2022.3185316	IEEE transactions on pattern analysis and machine intelligence	Rectified Wasserstein Generative Adversarial Networks for Perceptual Image Restoration.	"Wasserstein generative adversarial network (WGAN) has attracted great attention due to its solid mathematical background, i.e., to minimize the Wasserstein distance between the generated distribution and the distribution of interest. In WGAN, the Wasserstein distance is quantitatively evaluated by the discriminator, also known as the critic. The vanilla WGAN trained the critic with the simple Lipschitz condition, which was later shown less effective for modeling complex distributions, like the distribution of natural images. We try to improve the WGAN training by introducing pairwise constraint on the critic, oriented to image restoration tasks. In principle, pairwise constraint is to suggest the critic assign a higher rating to the original (real) image than to the restored (generated) image, as long as such a pair of images are available. We show that such pairwise constraint may be implemented by rectifying the gradients in WGAN training, which leads to the proposed rectified Wasserstein generative adversarial network (ReWaGAN). In addition, we build interesting connections between ReWaGAN and the perception-distortion tradeoff. We verify ReWaGAN on two representative image restoration tasks: single image super-resolution (4? and 8?) and compression artifact reduction, where our ReWaGAN not only beats the vanilla WGAN consistently, but also outperforms the state-of-the-art perceptual quality-oriented methods significantly. Our code and models are publicly available at https://github.com/mahaichuan/ReWaGAN."	github.com/mahaichuan/ReWaGAN.	https://github.com/mahaichuan/ReWaGAN/	mahaichuan	ReWaGAN			0	0		repo deleted	
34687347	02/14/2022	10.1007/s00330-021-08284-z	European radiology	Automated detection of the contrast phase in MDCT by an artificial neural network improves the accuracy of opportunistic bone mineral density measurements.	"To determine the accuracy of an artificial neural network (ANN) for fully automated detection of the presence and phase of iodinated contrast agent in routine abdominal multidetector computed tomography (MDCT) scans and evaluate the effect of contrast correction for osteoporosis screening. This HIPPA-compliant study retrospectively included 579 MDCT scans in 193 patients (62.4?±?14.6 years, 48 women). Three different ANN models (2D DenseNet with random slice selection, 2D DenseNet with anatomy-guided slice selection, 3D DenseNet) were trained in 462 MDCT scans of 154 patients (threefold cross-validation), who underwent triphasic CT. All ANN models were tested in 117 unseen triphasic scans of 39 patients, as well as in a public MDCT dataset containing 311 patients. In the triphasic test scans, trabecular volumetric bone mineral density (BMD) was calculated using a fully automated pipeline. Root-mean-square errors (RMSE) of BMD measurements with and without correction for contrast application were calculated in comparison to nonenhanced (NE) scans. The 2D DenseNet with anatomy-guided slice selection outperformed the competing models and achieved an F1 score of 0.98 and an accuracy of 98.3% in the test set (public dataset: F1 score 0.93; accuracy 94.2%). Application of contrast agent resulted in significant BMD biases (all p?<?.001; portal-venous (PV): RMSE 18.7 mg/ml, mean difference 17.5 mg/ml; arterial (AR): RMSE 6.92 mg/ml, mean difference 5.68 mg/ml). After the fully automated correction, this bias was no longer significant (p?>?.05; PV: RMSE 9.45 mg/ml, mean difference 1.28 mg/ml; AR: RMSE 3.98 mg/ml, mean difference 0.94 mg/ml). Automatic detection of the contrast phase in multicenter CT data was achieved with high accuracy, minimizing the contrast-induced error in BMD measurements. • A 2D DenseNet with anatomy-guided slice selection achieved an F1 score of 0.98 and an accuracy of 98.3% in the test set. In a public dataset, an F1 score of 0.93 and an accuracy of 94.2% were obtained. • Automated adjustment for contrast injection improved the accuracy of lumbar bone mineral density measurements (RMSE 18.7 mg/ml vs. 9.45 mg/ml respectively, in the portal-venous phase). • An artificial neural network can reliably reveal the presence and phase of iodinated contrast agent in multidetector CT scans ( https://github.com/ferchonavarro/anatomy_guided_contrast_c ). This allows minimizing the contrast-induced error in opportunistic bone mineral density measurements. "	github.com/ferchonavarro/anatomy_guided_contrast_c	https://github.com/ferchonavarro/anatomy_guided_contrast_c/	ferchonavarro	anatomy_guided_contrast_c			0	0		wrong link	https://github.com/ferchonavarro/anatomy_guided_contrast_ct/
37052532	05/01/2023	10.1093/bioinformatics/btad189	"Bioinformatics (Oxford, England)"	Structure-aware protein self-supervised learning.	"Protein representation learning methods have shown great potential to many downstream tasks in biological applications. A few recent studies have demonstrated that the self-supervised learning is a promising solution to addressing insufficient labels of proteins, which is a major obstacle to effective protein representation learning. However, existing protein representation learning is usually pretrained on protein sequences without considering the important protein structural information. In this work, we propose a novel structure-aware protein self-supervised learning method to effectively capture structural information of proteins. In particular, a graph neural network model is pretrained to preserve the protein structural information with self-supervised tasks from a pairwise residue distance perspective and a dihedral angle perspective, respectively. Furthermore, we propose to leverage the available protein language model pretrained on protein sequences to enhance the self-supervised learning. Specifically, we identify the relation between the sequential information in the protein language model and the structural information in the specially designed graph neural network model via a novel pseudo bi-level optimization scheme. We conduct experiments on three downstream tasks: the binary classification into membrane/non-membrane proteins, the location classification into 10 cellular compartments, and the enzyme-catalyzed reaction classification into 384 EC numbers, and these experiments verify the effectiveness of our proposed method. The Alphafold2 database is available in https://alphafold.ebi.ac.uk/. The PDB files are available in https://www.rcsb.org/. The downstream tasks are available in https://github.com/phermosilla/IEConv\_proteins/tree/master/Datasets. The code of the proposed method is available in https://github.com/GGchen1997/STEPS_Bioinformatics. "	github.com/phermosilla/IEConv\_proteins/tree/master/Datasets.	https://github.com/phermosilla/IEConv\_proteins/tree/master/Datasets/	phermosilla	IEConv\_proteins			0	0		wrong link	https://github.com/phermosilla/IEConv_proteins/tree/master/Datasets/
26191646	04/21/2016	10.1111/jmi.12266	Journal of microscopy	Automated tracing of myelinated axons and detection of the nodes of Ranvier in serial images of peripheral nerves.	"The development of realistic neuroanatomical models of peripheral nerves for simulation purposes requires the reconstruction of the morphology of the myelinated fibres in the nerve, including their nodes of Ranvier. Currently, this information has to be extracted by semimanual procedures, which severely limit the scalability of the experiments. In this contribution, we propose a supervised machine learning approach for the detailed reconstruction of the geometry of fibres inside a peripheral nerve based on its high-resolution serial section images. Learning from sparse expert annotations, the algorithm traces myelinated axons, even across the nodes of Ranvier. The latter are detected automatically. The approach is based on classifying the myelinated membranes in a supervised fashion, closing the membrane gaps by solving an assignment problem, and classifying the closed gaps for the nodes of Ranvier detection. The algorithm has been validated on two very different datasets: (i) rat vagus nerve subvolume, SBFSEM microscope, 200 ? 200 ? 200 nm resolution, (ii) rat sensory branch subvolume, confocal microscope, 384 ? 384 ? 800 nm resolution. For the first dataset, the algorithm correctly reconstructed 88% of the axons (241 out of 273) and achieved 92% accuracy on the task of Ranvier node detection. For the second dataset, the gap closing algorithm correctly closed 96.2% of the gaps, and 55% of axons were reconstructed correctly through the whole volume. On both datasets, training the algorithm on a small data subset and applying it to the full dataset takes a fraction of the time required by the currently used semiautomated protocols. Our software, raw data and ground truth annotations are available at http://hci.iwr.uni-heidelberg.de/Benchmarks/. The development version of the code can be found at https://github.com/RWalecki/ATMA."	github.com/RWalecki/ATMA.	https://github.com/RWalecki/ATMA/	RWalecki	ATMA			0	1	04/12/2021	repo deleted	
23272111	06/26/2013	10.1371/journal.pone.0051511	PloS one	MultiMetEval: comparative and multi-objective analysis of genome-scale metabolic models.	"Comparative metabolic modelling is emerging as a novel field, supported by the development of reliable and standardized approaches for constructing genome-scale metabolic models in high throughput. New software solutions are needed to allow efficient comparative analysis of multiple models in the context of multiple cellular objectives. Here, we present the user-friendly software framework Multi-Metabolic Evaluator (MultiMetEval), built upon SurreyFBA, which allows the user to compose collections of metabolic models that together can be subjected to flux balance analysis. Additionally, MultiMetEval implements functionalities for multi-objective analysis by calculating the Pareto front between two cellular objectives. Using a previously generated dataset of 38 actinobacterial genome-scale metabolic models, we show how these approaches can lead to exciting novel insights. Firstly, after incorporating several pathways for the biosynthesis of natural products into each of these models, comparative flux balance analysis predicted that species like Streptomyces that harbour the highest diversity of secondary metabolite biosynthetic gene clusters in their genomes do not necessarily have the metabolic network topology most suitable for compound overproduction. Secondly, multi-objective analysis of biomass production and natural product biosynthesis in these actinobacteria shows that the well-studied occurrence of discrete metabolic switches during the change of cellular objectives is inherent to their metabolic network architecture. Comparative and multi-objective modelling can lead to insights that could not be obtained by normal flux balance analyses. MultiMetEval provides a powerful platform that makes these analyses straightforward for biologists. Sources and binaries of MultiMetEval are freely available from https://github.com/PiotrZakrzewski/MetEval/downloads."	github.com/PiotrZakrzewski/MetEval/downloads.	https://github.com/PiotrZakrzewski/MetEval/downloads/	PiotrZakrzewski	MetEval			0	0		repo deleted	
32031934	02/06/2020	10.1109/TMI.2020.2972059	IEEE transactions on medical imaging	Recalibrating 3D ConvNets with Project & Excite.	"Fully Convolutional Neural Networks (F-CNNs) achieve state-of-the-art performance for segmentation tasks in computer vision and medical imaging. Recently, computational blocks termed squeeze and excitation (SE) have been introduced to recalibrate F-CNN feature maps both channel- and spatial-wise, boosting segmentation performance while only minimally increasing the model complexity. So far, the development of SE blocks has focused on 2D architectures. For volumetric medical images, however, 3D F-CNNs are a natural choice. In this article, we extend existing 2D recalibration methods to 3D and propose a generic compress-process-recalibrate pipeline for easy comparison of such blocks. We further introduce Project & Excite (PE) modules, customized for 3D networks. In contrast to existing modules, Project & Excite does not perform global average pooling but compresses feature maps along different spatial dimensions of the tensor separately to retain more spatial information that is subsequently used in the excitation step. We evaluate the modules on two challenging tasks, whole-brain segmentation of MRI scans and whole-body segmentation of CT scans. We demonstrate that PE modules can be easily integrated into 3D F-CNNs, boosting performance up to 0.3 in Dice Score and outperforming 3D extensions of other recalibration blocks, while only marginally increasing the model complexity. Our code is publicly available on https://github.com/ai-med/squeezeandexcitation."	github.com/ai-med/squeezeandexcitation.	https://github.com/ai-med/squeezeandexcitation/	ai-med	squeezeandexcitation			0	0		renamed	https://github.com/ai-med/squeeze_and_excitation/
33714997	02/01/2023	10.1093/bioinformatics/btab183	"Bioinformatics (Oxford, England)"	HCMMCNVs: hierarchical clustering mixture model of copy number variants detection using whole exome sequencing technology.	"In this article, we introduce a hierarchical clustering and Gaussian mixture model with expectation-maximization (EM) algorithm for detecting copy number variants (CNVs) using whole exome sequencing (WES) data. The R shiny package 'HCMMCNVs' is also developed for processing user-provided bam files, running CNVs detection algorithm and conducting visualization. Through applying our approach to 325 cancer cell lines in 22 tumor types from Cancer Cell Line Encyclopedia (CCLE), we show that our algorithm is competitive with other existing methods and feasible in using multiple cancer cell lines for CNVs estimation. In addition, by applying our approach to WES data of 120 oral squamous cell carcinoma (OSCC) samples, our algorithm, using the tumor sample only, exhibits more power in detecting CNVs as compared with the methods using both tumors and matched normal counterparts. HCMMCNVs R shiny software is freely available at github repository https://github.com/lunching/HCMM_CNVs.and Zenodo https://doi.org/10.5281/zenodo.4593371. Supplementary data are available at Bioinformatics online. "	github.com/lunching/HCMM_CNVs.and	https://github.com/lunching/HCMM_CNVs.and/	lunching	HCMM_CNVs.and			0	0		wrong link	https://github.com/lunching/HCMM_CNVs/
31890138	11/26/2019	10.1016/j.csbj.2019.11.003	Computational and structural biotechnology journal	Cordyceps militaris Optimizing cultivation of  for fast growth and cordycepin overproduction using rational design of synthetic media. 	"is an entomopathogenic fungus which is often used in Asia as a traditional medicine developed from age-old wisdom. Presently, cordycepin from  is a great interest in medicinal applications. However, cellular growth of  and the association with cordycepin production remain poorly understood. To explore the metabolism of  as potential cell factories in medical and biotechnology applications, this study developed a high-quality genome-scale metabolic model of , NR1329, based on its genomic content and physiological data. The model included a total of 1329 genes, 1821 biochemical reactions, and 1171 metabolites among 4 different cellular compartments. Its  growth simulation results agreed well with experimental data on different carbon sources. NR1329 was further used for optimizing the growth and cordycepin overproduction using a novel approach, POPCORN, for rational design of synthetic media. In addition to the high-quality GEM NR1329, the presented POPCORN approach was successfully used to rationally design an optimal synthetic medium with C:N ratio of 8:1 for enhancing 3.5-fold increase in cordycepin production. This study thus provides a novel insight into  physiology and highlights a potential GEM-driven method for synthetic media design and metabolic engineering application. The NR1329 and the POPCORN approach are available at the GitHub repository: https://github.com/sysbiomics/-GEM. "	github.com/sysbiomics/-GEM.	https://github.com/sysbiomics/-GEM/	sysbiomics	#NAME?			0	0		wrong link	https://github.com/sysbiomics/Cordyceps_militaris-GEM/
28714590	01/30/2018	10.1002/gepi.22059	Genetic epidemiology	Adaptive testing for association between two random vectors in moderate to high dimensions.	"Testing for association between two random vectors is a common and important task in many fields, however, existing tests, such as Escoufier's RV test, are suitable only for low-dimensional data, not for high-dimensional data. In moderate to high dimensions, it is necessary to consider sparse signals, which are often expected with only a few, but not many, variables associated with each other. We generalize the RV test to moderate-to-high dimensions. The key idea is to data adaptively weight each variable pair based on its empirical association. As the consequence, the proposed test is adaptive, alleviating the effects of noise accumulation in high-dimensional data, and thus maintaining the power for both dense and sparse alternative hypotheses. We show the connections between the proposed test with several existing tests, such as a generalized estimating equations-based adaptive test, multivariate kernel machine regression (KMR), and kernel distance methods. Furthermore, we modify the proposed adaptive test so that it can be powerful for nonlinear or nonmonotonic associations. We use both real data and simulated data to demonstrate the advantages and usefulness of the proposed new test. The new test is freely available in R package aSPC on CRAN at https://cran.r-project.org/web/packages/aSPC/index.html and https://github.com/jasonzyx/aSPC."	github.com/jasonzyx/aSPC.	https://github.com/jasonzyx/aSPC/	jasonzyx	aSPC			0	1	01/12/2021	repo deleted	
28038834	01/12/2018	10.1016/j.jsb.2016.12.006	Journal of structural biology	Robust image alignment for cryogenic transmission electron microscopy.	"Cryo-electron microscopy recently experienced great improvements in structure resolution due to direct electron detectors with improved contrast and fast read-out leading to single electron counting. High frames rates enabled dose fractionation, where a long exposure is broken into a movie, permitting specimen drift to be registered and corrected. The typical approach for image registration, with high shot noise and low contrast, is multi-reference (MR) cross-correlation. Here we present the software package Zorro, which provides robust drift correction for dose fractionation by use of an intensity-normalized cross-correlation and logistic noise model to weight each cross-correlation in the MR model and filter each cross-correlation optimally. Frames are reliably registered by Zorro with low dose and defocus. Methods to evaluate performance are presented, by use of independently-evaluated even- and odd-frame stacks by trajectory comparison and Fourier ring correlation. Alignment of tiled sub-frames is also introduced, and demonstrated on an example dataset. Zorro source code is available at github.com/CINA/zorro."	github.com/CINA/zorro.	https://github.com/CINA/zorro/	CINA	zorro			0	0		repo deleted	
29265724	02/12/2019	10.1002/pmic.201700232	Proteomics	SIMLR: A Tool for Large-Scale Genomic Analyses by Multi-Kernel Learning.	"SIMLR (Single-cell Interpretation via Multi-kernel LeaRning), an open-source tool that implements a novel framework to learn a sample-to-sample similarity measure from expression data observed for heterogenous samples, is presented here. SIMLR can be effectively used to perform tasks such as dimension reduction, clustering, and visualization of heterogeneous populations of samples. SIMLR was benchmarked against state-of-the-art methods for these three tasks on several public datasets, showing it to be scalable and capable of greatly improving clustering performance, as well as providing valuable insights by making the data more interpretable via better a visualization. SIMLR is available on https://github.com/BatzoglouLabSU/SIMLRGitHub in both R and MATLAB implementations. Furthermore, it is also available as an R package on http://bioconductor.org."	github.com/BatzoglouLabSU/SIMLRGitHub	https://github.com/BatzoglouLabSU/SIMLRGitHub/	BatzoglouLabSU	SIMLRGitHub			0	0		wrong link	https://github.com/BatzoglouLabSU/SIMLR/
37035550	03/23/2023	10.1016/j.csbj.2023.03.035	Computational and structural biotechnology journal	f RNC: Uncovering the dynamic and condition-specific RBP-ncRNA circuits from multi-omics data. 	"The RNA binding protein (RBP) and non-coding RNA (ncRNA) interacting networks are increasingly recognized as the main mechanism in gene regulation, and are tightly associated with cellular malfunction and disease. Here, we present RNC, a systems biology tool to uncover the dynamic spectrum of RBP-ncRNA circuits (RNC) by integrating transcriptomics, interactomics and proteomics data. RNC constructs the RBP-ncRNA network derived from CLIP-seq or PARE experiments. Given scoring on nodes and edges according to differential analysis of expression data, it finds an RNC containing global maximum significant RBPs and ncRNAs. Alternatively, it can also capture the locally maximum scoring RNC according to user-defined starting nodes with the greedy search. When compared with existing tools, RNC can detect more accurate and robust sub-network with scalability. As shown in the cases of esophageal carcinoma, breast cancer and Alzheimer's disease, RNC enables users to analyze the collective behaviors between RBP and the interacting ncRNAs, and reveal novel insights into the disease-associated processes. The RNC R package is available at https://github.com/BioinformaticsSTU/RNC. "	github.com/BioinformaticsSTU/RNC.	https://github.com/BioinformaticsSTU/RNC/	BioinformaticsSTU	RNC			0	0		repo deleted	
29994455	04/26/2021	10.1109/TCBB.2018.2808350	IEEE/ACM transactions on computational biology and bioinformatics	IsoTree: A New Framework for de novo Transcriptome Assembly from RNA-seq Reads.	"High-throughput sequencing of mRNA has made the deep and efficient probing of transcriptome more affordable. However, the vast amounts of short RNA-seq reads make de novo transcriptome assembly an algorithmic challenge. In this work, we present IsoTree, a novel framework for transcripts reconstruction in the absence of reference genomes. Unlike most of de novo assembly methods that build de Bruijn graph or splicing graph by connecting k- mers which are sets of overlapping substrings generated from reads, IsoTree constructs splicing graph by connecting reads directly. For each splicing graph, IsoTree applies an iterative scheme of mixed integer linear program to build a prefix tree, called isoform tree. Each path from the root node of the isoform tree to a leaf node represents a plausible transcript candidate which will be pruned based on the information of paired-end reads. Experiments showed that in most cases IsoTree performs better than other leading transcriptome assembly programs. IsoTree is available at https://github.com/Jane110111107/IsoTree."	github.com/Jane110111107/IsoTree.	https://github.com/Jane110111107/IsoTree/	Jane110111107	IsoTree			0	0		owner deleted	
27884106	07/18/2017	10.1186/s12859-016-1355-4	BMC bioinformatics	SPECtre: a spectral coherence--based classifier of actively translated transcripts from ribosome profiling sequence data.	"Active protein translation can be assessed and measured using ribosome profiling sequencing strategies. Prevailing analytical approaches applied to this technology make use of sequence fragment length profiling or reading frame occupancy enrichment to differentiate between active translation and background noise, however they do not consider additional characteristics inherent to the technology which limits their overall accuracy. Here, we present an analytical tool that models the overall tri-nucleotide periodicity of ribosomal occupancy using a classifier based on spectral coherence. Our software, SPECtre, examines the relationship of normalized ribosome profiling read coverage over a rolling series of windows along a transcript relative to an idealized reference signal without the matched requirement of mRNA-Seq. A comparison of SPECtre against previously published methods on existing data shows a marked improvement in accuracy for detecting active translation and exhibits overall high accuracy at a low false discovery rate. In addition, SPECtre performs comparably to a recently published method similarly based on spectral coherence, however with reduced runtime and memory requirements. SPECtre is available as an open source software package at https://github.com/mills-lab/spectreok . "	github.com/mills-lab/spectreok	https://github.com/mills-lab/spectreok/	mills-lab	spectreok			0	0		repo deleted	
36909428	02/23/2023	10.3389/fpls.2023.1120724	Frontiers in plant science	EADD-YOLO: An efficient and accurate disease detector for apple leaf using improved lightweight YOLOv5.	"Current detection methods for apple leaf diseases still suffer some challenges, such as the high number of parameters, low detection speed and poor detection performance for small dense spots, which limit the practical applications in agriculture. Therefore, an efficient and accurate model for apple leaf disease detection based on YOLOv5 is proposed and named EADD-YOLO. In the EADD-YOLO, the lightweight shufflenet inverted residual module is utilized to reconstruct the backbone network, and an efficient feature learning module designed through depthwise convolution is proposed and introduced to the neck network. The aim is to reduce the number of parameters and floating point of operations (FLOPs) during feature extraction and feature fusion, thus increasing the operational efficiency of the network with less impact on detection performance. In addition, the coordinate attention module is embedded into the critical locations of the network to select the critical spot information and suppress useless information, which is to enhance the detection accuracy of diseases with various sizes from different scenes. Furthermore, the SIoU loss replaces CIoU loss as the bounding box regression loss function to improve the accuracy of prediction box localization. The experimental results indicate that the proposed method can achieve the detection performance of 95.5% on the mean average precision and a speed of 625 frames per second (FPS) on the apple leaf disease dataset (ALDD). Compared to the latest research method on the ALDD, the detection accuracy and speed of the proposed method were improved by 12.3% and 596 FPS, respectively. In addition, the parameter quantity and FLOPs of the proposed method were much less than other relevant popular algorithms. In summary, the proposed method not only has a satisfactory detection effect, but also has fewer parameters and high calculation efficiency compared with the existing approaches. Therefore, the proposed method provides a high-performance solution for the early diagnosis of apple leaf disease and can be applied in agricultural robots. The code repository is open-sourced at https://github.com/AWANWY/EADD-YOLO. "	github.com/AWANWY/EADD-YOLO.	https://github.com/AWANWY/EADD-YOLO/	AWANWY	EADD-YOLO			0	0		repo deleted	
30235130	09/18/2018	10.1109/TIP.2018.2870946	IEEE transactions on image processing : a publication of the IEEE Signal Processing Society	Dynamic Feature Matching for Partial Face Recognition.	"Partial face recognition (PFR) in an unconstrained environment is a very important task, especially in situations where partial face images are likely to be captured due to occlusions, out-of-view, and large viewing angle, e.g., video surveillance and mobile devices. However, little attention has been paid to PFR so far and thus, the problem of recognizing an arbitrary patch of a face image remains largely unsolved. This study proposes a novel partial face recognition approach, called Dynamic Feature Matching (DFM), which combines Fully Convolutional Networks (FCNs) and Sparse Representation Classification (SRC) to address partial face recognition problem regardless of various face sizes. DFM does not require prior position information of partial faces against a holistic face. By sharing computation, the feature maps are calculated from the entire input image once, which yields a significant speedup. Experimental results demonstrate the effectiveness and advantages of DFM in comparison with state-of-the-art PFR methods on several partial face databases, including CAISA-NIR-Distance, CASIA-NIR-Mobile, and LFW databases. The performance of DFM is also impressive in partial person re-identification on Partial RE-ID and iLIDS databases. The source code of DFM can be found at https://github.com/lingxiao-he/dfm new."	github.com/lingxiao-he/dfm	https://github.com/lingxiao-he/dfm/	lingxiao-he	dfm			0	0		repo deleted	
28152981	08/18/2017	10.1186/s12859-017-1506-2	BMC bioinformatics	Classifying kinase conformations using a machine learning approach.	"Signaling proteins such as protein kinases adopt a diverse array of conformations to respond to regulatory signals in signaling pathways. Perhaps the most fundamental conformational change of a kinase is the transition between active and inactive states, and defining the conformational features associated with kinase activation is critical for selectively targeting abnormally regulated kinases in diseases. While manual examination of crystal structures have led to the identification of key structural features associated with kinase activation, the large number of kinase crystal structures (~3,500) and extensive conformational diversity displayed by the protein kinase superfamily poses unique challenges in fully defining the conformational features associated with kinase activation. Although some computational approaches have been proposed, they are typically based on a small subset of crystal structures using measurements biased towards the active site geometry. We utilize an unbiased informatics based machine learning approach to classify all eukaryotic protein kinase conformations deposited in the PDB. We show that the orientation of the activation segment, measured by ?, ?, ?1, and pseudo-dihedral angles more accurately classify kinase crystal conformations than existing methods. We show that the formation of the K-E salt bridge is statistically dependent upon the activation segment orientation and identify evolutionary differences between the activation segment conformation of tyrosine and serine/threonine kinases. We provide evidence that our method can identify conformational changes associated with the binding of allosteric regulatory proteins, and show that the greatest variation in inactive structures comes from kinase group and family specific side chain orientations. We have provided the first comprehensive machine learning based classification of protein kinase active/inactive conformations, taking into account more structures and measurements than any previous classification effort. Further, our unbiased classification of inactive structures reveals residues associated with kinase functional specificity. To enable classification of new crystal structures, we have made our classifier publicly accessible through a stand-alone program housed at https://github.com/esbg/kinconform [DOI: 10.5281/zenodo.249090 ]. "	github.com/esbg/kinconform	https://github.com/esbg/kinconform/	esbg	kinconform			0	1	10/07/2021	repo deleted	
37030870	03/29/2023	10.1109/TPAMI.2023.3262786	IEEE transactions on pattern analysis and machine intelligence	Unsupervised Point Cloud Representation Learning with Deep Neural Networks: A Survey.	"Point cloud data have been widely explored due to its superior accuracy and robustness under various adverse situations. Meanwhile, deep neural networks (DNNs) have achieved very impressive success in various applications such as surveillance and autonomous driving. The convergence of point cloud and DNNs has led to many deep point cloud models, largely trained under the supervision of large-scale and densely-labelled point cloud data. Unsupervised point cloud representation learning, which aims to learn general and useful point cloud representations from unlabelled point cloud data, has recently attracted increasing attention due to the constraint in large-scale point cloud labelling. This paper provides a comprehensive review of unsupervised point cloud representation learning using DNNs. It first describes the motivation, general pipelines as well as terminologies of the recent studies. Relevant background including widely adopted point cloud datasets and DNN architectures is then briefly presented. This is followed by an extensive discussion of existing unsupervised point cloud representation learning methods according to their technical approaches. We also quantitatively benchmark and discuss the reviewed methods over multiple widely adopted point cloud datasets. Finally, we share our humble opinion about several challenges and problems that could be pursued in the future research in unsupervised point cloud representation learning. A project associated with this survey has been built at https://github.com/xiaoaoran/3d url survey."	github.com/xiaoaoran/3d	https://github.com/xiaoaoran/3d/	xiaoaoran	3d			0	0		repo deleted	
36804584	03/10/2023	10.1039/d2ay02072f	Analytical methods : advancing methods and applications	2 via Development of a CH-dependent analytical method using near-infrared spectroscopy  the integration of two algorithms: non-dominated sorting genetic-II and competitive adaptive reweighted sampling (NSGAII-CARS). 	"In most of the near-infrared studies, near-infrared spectra (NIRS) were often mathematically treated. However, these algorithms selected a large number of variables and latent variables, and they caused the over-fitting phenomenon, which became very common. The large number of variables made it impossible to extract the ""chemical information"" directly from the NIRS. To build robust and interpretable mathematical models, the non-dominated sorting genetic-II-competitive adaptive reweighted sampling (NSGAII-CARS) algorithm was proposed to determine influential functional groups for quantitative analysis. In this research, data on a primary mixture of two amino acids (AAs), namely NH(CH)COOH and HOOC(NH)CH(CH)COOH, was used to illustrate the algorithm. The principle of the algorithm was first to find out the different characteristic spectral regions of two amino acids by extreme points according to Non-dominated Sorting Genetic-II (NSGAII). Second, based on the absolute value of the regression coefficient, we found out [(CH) + 2(CH)] and [2(CH)], where the wavenumber ranged from 6165 to 5683 cm, were the influential functional groups for quantitative analysis. Finally, the CARS (competitive adaptive reweighted sampling) algorithm was combined with NSGAII to find the specific fingerprint points for the determination of two AAs. Compared with the previous results, the NSGAII-CARS algorithm not only pointed out the influential quantitative functional groups but also used only 6 points for HOOC(NH)CH(CH)COOH and 18 points for NH(CH)COOH to achieve the full-spectrum quantitative effect. The results proposed a general algorithm for the quantitative analysis of NIRS obtained in the binary or ternary mixed systems. The MATLAB codes of the NSGAII-CARS algorithm are available on the website: https://github.com/Mark1988NK/NSGAII-CARS-Algorithm.git. "	github.com/Mark1988NK/NSGAII-CARS-Algorithm.git.	https://github.com/Mark1988NK/NSGAII-CARS-Algorithm/	Mark1988NK	NSGAII-CARS-Algorithm			0	0		renamed	https://github.com/Mark1988NK/VNSGAII-CARS-Algorithm/
35035263	01/08/2022	10.1007/s11042-021-11601-9	Multimedia tools and applications	COVID-19 and cyberbullying: deep ensemble model to identify cyberbullying from code-switched languages during the pandemic.	"It has been declared by the World Health Organization (WHO) the novel coronavirus a global pandemic due to an exponential spread in COVID-19 in the past months reaching over 100 million cases and resulting in approximately 3 million deaths worldwide. Amid this pandemic, identification of cyberbullying has become a more evolving area of research over posts or comments in social media platforms. In multilingual societies like India, code-switched texts comprise the majority of the Internet. Identifying the online bullying of the code-switched user is bit challenging than monolingual cases. As a first step towards enabling the development of approaches for cyberbullying detection, we developed a new code-switched dataset, collected from Twitter utterances annotated with binary labels. To demonstrate the utility of the proposed dataset, we build different machine learning (Support Vector Machine & Logistic Regression) and deep learning (Multilayer Perceptron, Convolution Neural Network, BiLSTM, BERT) algorithms to detect cyberbullying of English-Hindi (En-Hi) code-switched text. Our proposed model integrates different hand-crafted features and is enriched by sequential and semantic patterns generated by different state-of-the-art deep neural network models. Initial experimental results of the proposed deep ensemble model on our code-switched data reveal that our approach yields state-of-the-art results, i.e., 0.93 in terms of macro-averaged F1 score. The dataset and codes of the present study will be made publicly available on the paper's companion repository [https://github.com/95sayanta/COVID-19-and-Cyberbullying]."	github.com/95sayanta/COVID-19-and-Cyberbullying].	https://github.com/95sayanta/COVID-19-and-Cyberbullying]/	95sayanta	COVID-19-and-Cyberbullying]			0	0		repo deleted	
24876377	11/14/2014	10.1093/bioinformatics/btu363	"Bioinformatics (Oxford, England)"	PatternCNV: a versatile tool for detecting copy number changes from exome sequencing data.	"Exome sequencing (exome-seq) data, which are typically used for calling exonic mutations, have also been utilized in detecting DNA copy number variations (CNVs). Despite the existence of several CNV detection tools, there is still a great need for a sensitive and an accurate CNV-calling algorithm with built-in QC steps, and does not require a paired reference for each sample. We developed a novel method named PatternCNV, which (i) accounts for the read coverage variations between exons while leveraging the consistencies of this variability across different samples; (ii) reduces alignment BAM files to WIG format and therefore greatly accelerates computation; (iii) incorporates multiple QC measures designed to identify outlier samples and batch effects; and (iv) provides a variety of visualization options including chromosome, gene and exon-level views of CNVs, along with a tabular summarization of the exon-level CNVs. Compared with other CNV-calling algorithms using data from a lymphoma exome-seq study, PatternCNV has higher sensitivity and specificity. The software for PatternCNV is implemented using Perl and R, and can be used in Mac or Linux environments. Software and user manual are available at http://bioinformaticstools.mayo.edu/research/patterncnv/, and R package at https://github.com/topsoil/patternCNV/. "	github.com/topsoil/patternCNV/.	https://github.com/topsoil/patternCNV/	topsoil	patternCNV			0	1	07/27/2019	repo deleted	
29860504	11/27/2018	10.1093/gigascience/giy064	GigaScience	SV-plaudit: A cloud-based framework for manually curating thousands of structural variants.	"SV-plaudit is a framework for rapidly curating structural variant (SV) predictions. For each SV, we generate an image that visualizes the coverage and alignment signals from a set of samples. Images are uploaded to our cloud framework where users assess the quality of each image using a client-side web application. Reports can then be generated as a tab-delimited file or annotated Variant Call Format (VCF) file. As a proof of principle, nine researchers collaborated for 1 hour to evaluate 1,350 SVs each. We anticipate that SV-plaudit will become a standard step in variant calling pipelines and the crowd-sourced curation of other biological results.Code available at https://github.com/jbelyeu/SV-plauditDemonstration video available at https://www.youtube.com/watch?v=ono8kHMKxDs."	github.com/jbelyeu/SV-plauditDemonstration	https://github.com/jbelyeu/SV-plauditDemonstration/	jbelyeu	SV-plauditDemonstration			0	0		wrong link	https://github.com/jbelyeu/SV-plaudit/
36249560	10/07/2022	10.1016/j.csbj.2022.10.004	Computational and structural biotechnology journal	Recognition of driver genes with potential prognostic implications in lung adenocarcinoma based on H3K79me2.	"Lung adenocarcinoma is a malignancy with a low overall survival and a poor prognosis. Studies have shown that lung adenocarcinoma progression relates to locus-specific/global changes in histone modifications. To explore the relationship between histone modification and gene expression changes, we focused on 11 histone modifications and quantitatively analyzed their influences on gene expression. We found that, among the studied histone modifications, H3K79me2 displayed the greatest impact on gene expression regulation. Based on the Shannon entropy, 867 genes with differential H3K79me2 levels during tumorigenesis were identified. Enrichment analyses showed that these genes were involved in 16 common cancer pathways and 11 tumors and were target-regulated by -regulatory elements, such as Tp53 and WT1. Then, an open-source computational framework was presented (https://github.com/zlq-imu/Identification-of-potential-LUND-driver-genes). Twelve potential driver genes were extracted from the genes with differential H3K79me2 levels during tumorigenesis. The expression levels of these potential driver genes were significantly increased/decreased in tumor cells, as assayed by RT-qPCR. A risk score model comprising these driver genes was further constructed, and this model was strongly negatively associated with the overall survival of patients in different datasets. The proportional hazards assumption and outlier test indicated that this model could robustly distinguish patients with different survival rates. Immune analyses and responses to immunotherapeutic and chemotherapeutic agents showed that patients in the high and low-risk groups may have distinct tendencies for clinical selection. Finally, the regions with clear H3K79me2 signal changes on these driver genes were accurately identified. Our research may offer potential molecular biomarkers for lung adenocarcinoma treatment. "	github.com/zlq-imu/Identification-of-potential-LUND-driver-genes	https://github.com/zlq-imu/Identification-of-potential-LUND-driver-genes/	zlq-imu	Identification-of-potential-LUND-driver-genes			0	0		repo deleted	
34991450	01/10/2022	10.1186/s12859-021-04547-0	BMC bioinformatics	Lerna: transformer architectures for configuring error correction tools for short- and long-read genome sequencing.	"Sequencing technologies are prone to errors, making error correction (EC) necessary for downstream applications. EC tools need to be manually configured for optimal performance. We find that the optimal parameters (e.g., k-mer size) are both tool- and dataset-dependent. Moreover, evaluating the performance (i.e., Alignment-rate or Gain) of a given tool usually relies on a reference genome, but quality reference genomes are not always available. We introduce Lerna for the automated configuration of k-mer-based EC tools. Lerna first creates a language model (LM) of the uncorrected genomic reads, and then, based on this LM, calculates a metric called the perplexity metric to evaluate the corrected reads for different parameter choices. Next, it finds the one that produces the highest alignment rate without using a reference genome. The fundamental intuition of our approach is that the perplexity metric is inversely correlated with the quality of the assembly after error correction. Therefore, Lerna leverages the perplexity metric for automated tuning of k-mer sizes without needing a reference genome. First, we show that the best k-mer value can vary for different datasets, even for the same EC tool. This motivates our design that automates k-mer size selection without using a reference genome. Second, we show the gains of our LM using its component attention-based transformers. We show the model's estimation of the perplexity metric before and after error correction. The lower the perplexity after correction, the better the k-mer size. We also show that the alignment rate and assembly quality computed for the corrected reads are strongly negatively correlated with the perplexity, enabling the automated selection of k-mer values for better error correction, and hence, improved assembly quality. We validate our approach on both short and long reads. Additionally, we show that our attention-based models have significant runtime improvement for the entire pipeline-18[Formula: see text] faster than previous works, due to parallelizing the attention mechanism and the use of JIT compilation for GPU inferencing. Lerna improves de novo genome assembly by optimizing EC tools. Our code is made available in a public repository at: https://github.com/icanforce/lerna-genomics . "	github.com/icanforce/lerna-genomics	https://github.com/icanforce/lerna-genomics/	icanforce	lerna-genomics			0	0		repo deleted	
25093067	08/05/2014	10.1186/2041-1480-5-26	Journal of biomedical semantics	Generalising semantic category disambiguation with large lexical resources for fun and profit.	"Semantic Category Disambiguation (SCD) is the task of assigning the appropriate semantic category to given spans of text from a fixed set of candidate categories, for example Protein to ""Fibrin"". SCD is relevant to Natural Language Processing tasks such as Named Entity Recognition, coreference resolution and coordination resolution. In this work, we study machine learning-based SCD methods using large lexical resources and approximate string matching, aiming to generalise these methods with regard to domains, lexical resources and the composition of data sets. We specifically consider the applicability of SCD for the purposes of supporting human annotators and acting as a pipeline component for other Natural Language Processing systems. While previous research has mostly cast SCD purely as a classification task, we consider a task setting that allows for multiple semantic categories to be suggested, aiming to minimise the number of suggestions while maintaining high recall. We argue that this setting reflects aspects which are essential for both a pipeline component and when supporting human annotators. We introduce an SCD method based on a recently introduced machine learning-based system and evaluate it on 15 corpora covering biomedical, clinical and newswire texts and ranging in the number of semantic categories from 2 to 91. With appropriate settings, our system maintains an average recall of 99% while reducing the number of candidate semantic categories on average by 65% over all data sets. Machine learning-based SCD using large lexical resources and approximate string matching is sensitive to the selection and granularity of lexical resources, but generalises well to a wide range of text domains and data sets given appropriate resources and parameter settings. By substantially reducing the number of candidate categories while only very rarely excluding the correct one, our method is shown to be applicable to manual annotation support tasks and use as a high-recall component in text processing pipelines. The introduced system and all related resources are freely available for research purposes at: https://github.com/ninjin/simsem. "	github.com/ninjin/simsem.	https://github.com/ninjin/simsem/	ninjin	simsem			0	1	08/06/2016	owner deleted	
36134032	09/05/2022	10.3389/fgene.2022.980497	Frontiers in genetics	Inferring human miRNA-disease associations via multiple kernel fusion on GCNII.	"Increasing evidence shows that the occurrence of human complex diseases is closely related to the mutation and abnormal expression of microRNAs(miRNAs). MiRNAs have complex and fine regulatory mechanisms, which makes it a promising target for drug discovery and disease diagnosis. Therefore, predicting the potential miRNA-disease associations has practical significance. In this paper, we proposed an miRNA-disease association predicting method based on multiple kernel fusion on Graph Convolutional Network via Initial residual and Identity mapping (GCNII), called MKFGCNII. Firstly, we built a heterogeneous network of miRNAs and diseases to extract multi-layer features via GCNII. Secondly, multiple kernel fusion method was applied to weight fusion of embeddings at each layer. Finally, Dual Laplacian Regularized Least Squares was used to predict new miRNA-disease associations by the combined kernel in miRNA and disease spaces. Compared with the other methods, MKFGCNII obtained the highest AUC value of 0.9631. Code is available at https://github.com/cuntjx/bioInfo."	github.com/cuntjx/bioInfo.	https://github.com/cuntjx/bioInfo/	cuntjx	bioInfo			0	0		repo deleted	
29292031	08/13/2018	10.1016/j.ebiom.2017.12.026	EBioMedicine	Deep Convolutional Neural Networks Enable Discrimination of Heterogeneous Digital Pathology Images.	"Pathological evaluation of tumor tissue is pivotal for diagnosis in cancer patients and automated image analysis approaches have great potential to increase precision of diagnosis and help reduce human error. In this study, we utilize several computational methods based on convolutional neural networks (CNN) and build a stand-alone pipeline to effectively classify different histopathology images across different types of cancer. In particular, we demonstrate the utility of our pipeline to discriminate between two subtypes of lung cancer, four biomarkers of bladder cancer, and five biomarkers of breast cancer. In addition, we apply our pipeline to discriminate among four immunohistochemistry (IHC) staining scores of bladder and breast cancers. Our classification pipeline includes a basic CNN architecture, Google's Inceptions with three training strategies, and an ensemble of two state-of-the-art algorithms, Inception and ResNet. Training strategies include training the last layer of Google's Inceptions, training the network from scratch, and fine-tunning the parameters for our data using two pre-trained version of Google's Inception architectures, Inception-V1 and Inception-V3. We demonstrate the power of deep learning approaches for identifying cancer subtypes, and the robustness of Google's Inceptions even in presence of extensive tumor heterogeneity. On average, our pipeline achieved accuracies of 100%, 92%, 95%, and 69% for discrimination of various cancer tissues, subtypes, biomarkers, and scores, respectively. Our pipeline and related documentation is freely available at https://github.com/ih-_lab/CNN_Smoothie."	github.com/ih-_lab/CNN_Smoothie.	https://github.com/ih-_lab/CNN_Smoothie/	ih-_lab	CNN_Smoothie			0	0		wrong link	https://github.com/ih-lab/CNN_Smoothie/
30821318	06/09/2020	10.1093/bioinformatics/btz147	"Bioinformatics (Oxford, England)"	SW-Tandem: a highly efficient tool for large-scale peptide identification with parallel spectrum dot product on Sunway TaihuLight.	"Tandem mass spectrometry based database searching is a widely acknowledged and adopted method that identifies peptide sequence in shotgun proteomics. However, database searching is extremely computationally expensive, which can take days even weeks to process a large spectra dataset. To address this critical issue, this paper presents SW-Tandem, a new tool for large-scale peptide sequencing. SW-Tandem parallelizes the spectrum dot product scoring algorithm and leverages the advantages of Sunway TaihuLight, the No. 1 supercomputer in the world in 2017. Sunway TaihuLight is powered by the brand new many-core SW26010 processors and provides a peak computation performance greater than 100PFlops. To fully utilize the Sunway TaihuLights capacity, SW-Tandem employs three mechanisms to accelerate large-scale peptide identification, memory-access optimizations, double buffering and vectorization. The results of experiments conducted on multiple datasets demonstrate the performance of SW-Tandem against three state-of-the-art tools for peptide identification, including X!! Tandem, MR-Tandem and MSFragger. In addition, it shows high scalability in the experiments on extremely large datasets sized up to 12 GB. SW-Tandem is an open source software tool implemented in C++. The source code and the parameter settings are available at https://github.com/Logic09/SW-Tandem. Supplementary data are available at Bioinformatics online. "	github.com/Logic09/SW-Tandem.	https://github.com/Logic09/SW-Tandem/	Logic09	SW-Tandem			0	1	07/10/2021	repo deleted	
35850048	08/09/2022	10.1016/j.compbiolchem.2022.107735	Computational biology and chemistry	MinimapR: A parallel alignment tool for the analysis of large-scale third-generation sequencing data.	"The development of third-generation sequencing technology has brought significant changes and influences on genomics. Compared to the second-generation sequencing methods, the third-generation technologies produce around 100 times longer reads to reveal new genomic variations that complete long-term gaps in the human reference genome. However, these reads' excessive length and high error rate severely increase the amount of data and alignment cost. The traditional data analysis platform and serial sequence alignment method can not effectively deal with large-scale long read alignment. There is a critical need for a novel data analysis platform that can deliver fast alignment of large-scale sequences to solve the problem of long read alignment. High-performance computing platforms and efficient, scalable algorithms based on these platforms have significant potential to impact sequence analysis approaches. This paper presented minimapR, a multi-level parallel long-read alignment tool based on minimap2, a popular third-generation read aligner. MinimapR is developed based on the new high-performance distributed framework Ray. Ray fully integrates with the Python environment and can be easily installed with pip. MinimapR can utilize the power of multiple computing nodes, significantly accelerating alignment speeds without sacrificing sensitivity. The minimapR tool was tested on 64 nodes and demonstrated a 50 fold increase in speed with 78 % parallel efficiency. The source code and user manual of minimapR are freely available at https://github.com/Geehome/minimapR."	github.com/Geehome/minimapR.	https://github.com/Geehome/minimapR/	Geehome	minimapR			0	0		repo deleted	
33707935	12/14/2020	10.1109/SMC42975.2020.9282993	"Conference proceedings. IEEE International Conference on Systems, Man, and Cybernetics"	Technology Integration Methods for Bi-directional Brain-computer Interfaces and XR-based Interventions.	"Brain stimulation therapies have been established as effective treatments for Parkinson's disease, essential tremor, and epilepsy, as well as having high diagnostic and therapeutic potential in a wide range of neurological and psychiatric conditions. Novel interventions such as extended reality (XR), video games and exergames that can improve physiological and cognitive functioning are also emerging as targets for therapeutic and rehabilitative treatments. Previous studies have proposed specific applications involving non-invasive brain stimulation (NIBS) and virtual environments, but to date these have been uni-directional and restricted to specific applications or proprietary hardware. Here, we describe technology integration methods that enable invasive and non-invasive brain stimulation devices to interface with a cross-platform game engine and development platform for creating bi-directional brain-computer interfaces (BCI) and XR-based interventions. Furthermore, we present a highly-modifiable software framework and methods for integrating deep brain stimulation (DBS) in 2D, 3D, virtual and mixed reality applications, as well as extensible applications for BCI integration in wireless systems. The source code and integrated brain stimulation applications are available online at https://github.com/oxfordbioelectronics/brain-stim-game."	github.com/oxfordbioelectronics/brain-stim-game.	https://github.com/oxfordbioelectronics/brain-stim-game/	oxfordbioelectronics	brain-stim-game			0	1	05/12/2023	repo deleted	
33902725	05/18/2020	10.1186/s40793-020-00358-7	Environmental microbiome	Tax4Fun2: prediction of habitat-specific functional profiles and functional redundancy based on 16S rRNA gene sequences.	"Sequencing of 16S rRNA genes has become a powerful technique to study microbial communities and their responses towards changing environmental conditions in various ecosystems. Several tools have been developed for the prediction of functional profiles from 16S rRNA gene sequencing data, because numerous questions in ecosystem ecology require knowledge of community functions in addition to taxonomic composition. However, the accuracy of these tools relies on functional information derived from genomes available in public databases, which are often not representative of the microorganisms present in the studied ecosystem. In addition, there is also a lack of tools to predict functional gene redundancy in microbial communities. To address these challenges, we developed Tax4Fun2, an R package for the prediction of functional profiles and functional gene redundancies of prokaryotic communities from 16S rRNA gene sequences. We demonstrate that functional profiles predicted by Tax4Fun2 are highly correlated to functional profiles derived from metagenomes of the same samples. We further show that Tax4Fun2 has higher accuracies than PICRUSt and Tax4Fun. By incorporating user-defined, habitat-specific genomic information, the accuracy and robustness of predicted functional profiles is substantially enhanced. In addition, functional gene redundancies predicted with Tax4Fun2 are highly correlated to functional gene redundancies determined for simulated microbial communities. Tax4Fun2 provides researchers with a unique tool to predict and investigate functional profiles of prokaryotic communities based on 16S rRNA gene sequencing data. It is easy-to-use, platform-independent and highly memory-efficient, thus enabling researchers without extensive bioinformatics knowledge or access to high-performance clusters to predict functional profiles. Another unique feature of Tax4Fun2 is that it allows researchers to calculate the redundancy of specific functions, which is a potentially important measure of how resilient a community will be to environmental perturbation. Tax4Fun2 is implemented in R and freely available at https://github.com/bwemheu/Tax4Fun2. "	github.com/bwemheu/Tax4Fun2.	https://github.com/bwemheu/Tax4Fun2/	bwemheu	Tax4Fun2			0	1	07/16/2021	owner deleted	
35767510	10/31/2022	10.1109/TMI.2022.3186677	IEEE transactions on medical imaging	Contrastive and Selective Hidden Embeddings for Medical Image Segmentation.	"Medical image segmentation is fundamental and essential for the analysis of medical images. Although prevalent success has been achieved by convolutional neural networks (CNN), challenges are encountered in the domain of medical image analysis by two aspects: 1) lack of discriminative features to handle similar textures of distinct structures and 2) lack of selective features for potential blurred boundaries in medical images. In this paper, we extend the concept of contrastive learning (CL) to the segmentation task to learn more discriminative representation. Specifically, we propose a novel patch-dragsaw contrastive regularization (PDCR) to perform patch-level tugging and repulsing. In addition, a new structure, namely uncertainty-aware feature re- weighting block (UAFR), is designed to address the potential high uncertainty regions in the feature maps and serves as a better feature re- weighting. Our proposed method achieves state-of-the-art results across 8 public datasets from 6 domains. Besides, the method also demonstrates robustness in the limited-data scenario. The code is publicly available at https://github.com/lzh19961031/PDCR_UAFR-MIShttps://github.com/lzh19961031/PDCR_UAFR-MIS."	github.com/lzh19961031/PDCR_UAFR-MIShttps	https://github.com/lzh19961031/PDCR_UAFR-MIShttps/	lzh19961031	PDCR_UAFR-MIShttps			0	0		wrong link	https://github.com/lzh19961031/PDCR_UAFR-MIS/
37167050	05/11/2023	10.1109/TPAMI.2023.3275162	IEEE transactions on pattern analysis and machine intelligence	Few-Shot Partial Multi-View Learning.	"It is often the case that data are with multiple views in real-world applications. Fully exploring the information of each view is significant for making data more representative. However, due to various limitations and failures in data collection and pre-processing, it is inevitable for real data to suffer from view missing and data scarcity. The coexistence of these two issues makes it more challenging to achieve the pattern classification task. Currently, to our best knowledge, few appropriate methods can well-handle these two issues simultaneously. Aiming to draw more attention from the community to this challenge, we propose a new task in this paper, called few-shot partial multi-view learning, which focuses on overcoming the negative impact of the view-missing issue in the low-data regime. The challenges of this task are twofold: (i) it is difficult to overcome the impact of data scarcity under the interference of missing views; (ii) the limited number of data exacerbates information scarcity, thus making it harder to address the view-missing issue in turn. To address these challenges, we propose a new unified Gaussian dense-anchoring method. The unified dense anchors are learned for the limited partial multi-view data, thereby anchoring them into a unified dense representation space where the influence of data scarcity and view missing can be alleviated. We conduct extensive experiments to evaluate our method. The results on Cub-googlenet-doc2vec, Handwritten, Caltech102, Scene15, Animal, ORL, tieredImagenet, and Birds-200-2011 datasets validate its effectiveness. The codes will be released at https://github.com/zhouyuan888888/UGDA."	github.com/zhouyuan888888/UGDA.	https://github.com/zhouyuan888888/UGDA/	zhouyuan888888	UGDA			0	0		repo deleted	
27153637	08/10/2017	10.1093/bioinformatics/btw201	"Bioinformatics (Oxford, England)"	SCell: integrated analysis of single-cell RNA-seq data.	"Analysis of the composition of heterogeneous tissue has been greatly enabled by recent developments in single-cell transcriptomics. We present SCell, an integrated software tool for quality filtering, normalization, feature selection, iterative dimensionality reduction, clustering and the estimation of gene-expression gradients from large ensembles of single-cell RNA-seq datasets. SCell is open source, and implemented with an intuitive graphical interface. Scripts and protocols for the high-throughput pre-processing of large ensembles of single-cell, RNA-seq datasets are provided as an additional resource. Binary executables for Windows, MacOS and Linux are available at http://sourceforge.net/projects/scell, source code and pre-processing scripts are available from https://github.com/diazlab/SCellSupplementary information: Supplementary data are available at Bioinformatics online. aaron.diaz@ucsf.edu. "	github.com/diazlab/SCellSupplementary	https://github.com/diazlab/SCellSupplementary/	diazlab	SCellSupplementary			0	0		wrong link	https://github.com/diazlab/SCell/
28854978	10/02/2017	10.1186/s13073-017-0468-3	Genome medicine	The neoepitope landscape in pediatric cancers.	"Neoepitopes derived from tumor-specific somatic mutations are promising targets for immunotherapy in childhood cancers. However, the potential for such therapies in targeting these epitopes remains uncertain due to a lack of knowledge of the neoepitope landscape in childhood cancer. Studies to date have focused primarily on missense mutations without exploring gene fusions, which are a major class of oncogenic drivers in pediatric cancer. We developed an analytical workflow for identification of putative neoepitopes based on somatic missense mutations and gene fusions using whole-genome sequencing data. Transcriptome sequencing data were incorporated to interrogate the expression status of the neoepitopes. We present the neoepitope landscape of somatic alterations including missense mutations and oncogenic gene fusions identified in 540 childhood cancer genomes and transcriptomes representing 23 cancer subtypes. We found that 88% of leukemias, 78% of central nervous system tumors, and 90% of solid tumors had at least one predicted neoepitope. Mutation hotspots in KRAS and histone H3 genes encode potential epitopes in multiple patients. Additionally, the ETV6-RUNX1 fusion was found to encode putative neoepitopes in a high proportion (69.6%) of the pediatric leukemia harboring this fusion. Our study presents a comprehensive repertoire of potential neoepitopes in childhood cancers, and will facilitate the development of immunotherapeutic approaches designed to exploit them. The source code of the workflow is available at GitHub ( https://github.com/zhanglabstjude/neoepitope ). "	github.com/zhanglabstjude/neoepitope	https://github.com/zhanglabstjude/neoepitope/	zhanglabstjude	neoepitope			0	0		owner deleted	
34330122	11/09/2021	10.1088/1361-6560/ac195e	Physics in medicine and biology	CrossModalNet: exploiting quality preoperative images for multimodal image registration.	"A long-standing problem in image-guided radiotherapy is that inferior intraoperative images present a difficult problem for automatic registration algorithms. Particularly for digital radiography (DR) and digitally reconstructed radiograph (DRR), the blurred, low-contrast, and noisy DR makes the multimodal registration of DR-DRR challenging. Therefore, we propose a novel CNN-based method called CrossModalNet to exploit the quality preoperative modality (DRR) for handling the limitations of intraoperative images (DR), thereby improving the registration accuracy. The method consists of two parts: DR-DRR contour predictions and contour-based rigid registration. We have designed the CrossModal Attention Module and CrossModal Refine Module to fully exploit the multiscale crossmodal features and implement the crossmodal interactions during the feature encoding and decoding stages. Then, the predicted anatomical contours of DR-DRR are registered by the classic mutual information method. We collected 2486 patient scans to train CrossModalNet and 170 scans to test its performance. The results show that it outperforms the classic and state-of-the-art methods with 95th percentile Hausdorff distance of 5.82 pixels and registration accuracy of 81.2%. The code is available at https://github.com/lc82111/crossModalNet."	github.com/lc82111/crossModalNet.	https://github.com/lc82111/crossModalNet/	lc82111	crossModalNet			0	0		repo deleted	
35323892	05/23/2022	10.1093/bib/bbac058	Briefings in bioinformatics	A knowledge-driven network for fine-grained relationship detection between miRNA and disease.	"Increasing biological evidence indicated that microRNAs (miRNAs) play a vital role in exploring the pathogenesis of various human diseases (especially in tumors). Mining disease-related miRNAs is of great significance for the clinical diagnosis and treatment of diseases. Compared with the traditional experimental methods with the significant limitations of high cost, long cycle and small scale, the methods based on computing have the advantages of being cost-effective. However, although the current methods based on computational biology can accurately predict the correlation between miRNAs and disease, they can not predict the detailed association information at a fine level. We propose a knowledge-driven approach to the fine-grained prediction of disease-related miRNAs (KDFGMDA). Different from the previous methods, this method can finely predict the clear associations between miRNA and disease, such as upregulation, downregulation or dysregulation. Specifically, KDFGMDA extracts triple information from massive experimental data and existing datasets to construct a knowledge graph and then trains a depth graph representation learning model based on knowledge graph to complete fine-grained prediction tasks. Experimental results show that KDFGMDA can predict the relationship between miRNA and disease accurately, which is of far-reaching significance for medical clinical research and early diagnosis, prevention and treatment of diseases. Additionally, the results of case studies on three types of cancers, Kaplan-Meier survival analysis and expression difference analysis further provide the effectiveness and feasibility of KDFGMDA to detect potential candidate miRNAs. Availability: Our work can be downloaded from https://github.com/ShengPengYu/KDFGMDA."	github.com/ShengPengYu/KDFGMDA.	https://github.com/ShengPengYu/KDFGMDA/	ShengPengYu	KDFGMDA			0	0		repo deleted	
26995218	12/13/2016	10.1111/jbg.12200	Journal of animal breeding and genetics = Zeitschrift fur Tierzuchtung und Zuchtungsbiologie	A combined coalescence gene-dropping tool for evaluating genomic selection in complex scenarios (ms2gs).	"We present ms2gs, a combined coalescence - gene dropping (i.e. backward-forward) simulator for complex traits. It therefore aims at combining the advantages of both approaches. It is primarily conceived for very short term, recent scenarios such as those that are of interest in animal and plant breeding. It is very flexible in terms of defining QTL architecture and SNP ascertainment bias, and it allows for easy modelling of alternative markers such as RADs. It can use real sequence or chip data or generate molecular polymorphisms via the coalescence. It can generate QTL conditional on extant molecular information, such as low-density genotyping. It models (simplistically) sequence, imputation or genotyping errors. It requires as input both genotypic data in plink or ms formats, and a pedigree that is used to perform the gene dropping. By default, it compares accuracy for BLUP, SNP ascertained data, sequence, and causal SNPs. It employs VanRaden's linear (GBLUP) and nonlinear method for incorporating molecular information. To illustrate the program, we present a small application in a half-sib population and a multiparental (MAGIC) cross. The program, manual and examples are available at https://github.com/mperezenciso/ms2gs."	github.com/mperezenciso/ms2gs.	https://github.com/mperezenciso/ms2gs/	mperezenciso	ms2gs			0	1	01/10/2018	repo deleted	
37090633	04/12/2023	10.1101/2023.04.10.536302	bioRxiv : the preprint server for biology	A zero-agnostic model for copy number evolution in cancer.	"New low-coverage single-cell DNA sequencing technologies enable the measurement of copy number profiles from thousands of individual cells within tumors. From this data, one can infer the evolutionary history of the tumor by modeling transformations of the genome via copy number aberrations. A widely used model to infer such  is the  (CNT) model in which a genome is represented by an integer vector and a copy number aberration is an event that either increases or decreases the number of copies of a contiguous segment of the genome. The CNT distance between a pair of copy number profiles is the minimum number of events required to transform one profile to another. While this distance can be computed efficiently, no efficient algorithm has been developed to find the most parsimonious phylogeny under the CNT model. We introduce the  (ZCNT) model, a simplification of the CNT model that allows the amplification or deletion of regions with zero copies. We derive a closed form expression for the ZCNT distance between two copy number profiles and show that, unlike the CNT distance, the ZCNT distance forms a metric. We leverage the closed-form expression for the ZCNT distance and an alternative characterization of copy number profiles to derive polynomial time algorithms for two natural relaxations of the small parsimony problem on copy number profiles. While the alteration of zero copy number regions allowed under the ZCNT model is not biologically realistic, we show on both simulated and real datasets that the ZCNT distance is a close approximation to the CNT distance. Extending our polynomial time algorithm for the ZCNT small parsimony problem, we develop an algorithm,  , for solving the large parsimony problem on copy number profiles. We demonstrate that  outperforms existing methods for inferring copy number phylogenies on both simulated and real data. is implemented in C++17 and is freely available at: github.com/raphaelgroup/lazac-copy-number . "	github.com/raphaelgroup/lazac-copy-number	https://github.com/raphaelgroup/lazac-copy-number/	raphaelgroup	lazac-copy-number			0	0		repo deleted	
36648328	01/25/2023	10.1093/bioinformatics/btad014	"Bioinformatics (Oxford, England)"	Protein-to-genome alignment with miniprot.	"Protein-to-genome alignment is critical to annotating genes in non-model organisms. While there are a few tools for this purpose, all of them were developed over 10 years ago and did not incorporate the latest advances in alignment algorithms. They are inefficient and could not keep up with the rapid production of new genomes and quickly growing protein databases. Here, we describe miniprot, a new aligner for mapping protein sequences to a complete genome. Miniprot integrates recent techniques such as k-mer sketch and vectorized dynamic programming. It is tens of times faster than existing tools while achieving comparable accuracy on real data. https://github.com/lh3/miniport. "	github.com/lh3/miniport.	https://github.com/lh3/miniport/	lh3	miniport			0	0		repo deleted	
33703998	09/13/2022	10.1080/07391102.2021.1898474	Journal of biomolecular structure & dynamics	in silico de novo Target2DeNovoDrug: a novel programmatic tool for -deep learning based  drug design for any target of interest. 	"The on-going data-science and Artificial Intelligence (AI) revolution offer researchers a fresh set of tools to approach structure-based drug design problems in the computer-aided drug design space. A novel programmatic tool that incorporates  and deep learning based approaches for  drug design for any target of interest has been reported. Once the user specifies the target of interest in the form of a representative amino acid sequence or corresponding nucleotide sequence, the programmatic workflow of the tool generates compounds from the PubChem ligand library and novel SMILES of compounds not present in any ligand library but are likely to be active against the target. Following this, the tool performs a computationally efficient  modeling of the target and the newly generated compounds and stores the results of the protein-ligand interaction in the working folder of the user. Further, for the protein-ligand complex associated with the best protein-ligand interaction, the tool performs an automated Molecular Dynamics (MD) protocol and generates plots such as RMSD (Root Mean Square Deviation) which reveal the stability of the complex. A demonstrated use of the tool has been shown with the target signatures of Tumor Necrosis Factor-Alpha, an important therapeutic target in the case of anti-inflammatory treatment. The future scope of the tool involves, running the tool on a High-Performance Cluster for all known target signatures to generate data that will be useful to drive AI and Big data driven drug discovery. The code is hosted, maintained, and supported at the GitHub repository given in the link below https://github.com/bengeof/Target2DeNovoDrugCommunicated by Ramaswamy H. Sarma. "	github.com/bengeof/Target2DeNovoDrugCommunicated	https://github.com/bengeof/Target2DeNovoDrugCommunicated/	bengeof	Target2DeNovoDrugCommunicated			0	0		wrong link	https://github.com/bengeof/Target2DeNovoDrug/
28077564	11/20/2017	10.1093/database/baw154	Database : the journal of biological databases and curation	blend4php: a PHP API for galaxy.	"Galaxy is a popular framework for execution of complex analytical pipelines typically for large data sets, and is a commonly used for (but not limited to) genomic, genetic and related biological analysis. It provides a web front-end and integrates with high performance computing resources. Here we report the development of the blend4php library that wraps Galaxy's RESTful API into a PHP-based library. PHP-based web applications can use blend4php to automate execution, monitoring and management of a remote Galaxy server, including its users, workflows, jobs and more. The blend4php library was specifically developed for the integration of Galaxy with Tripal, the open-source toolkit for the creation of online genomic and genetic web sites. However, it was designed as an independent library for use by any application, and is freely available under version 3 of the GNU Lesser General Public License (LPGL v3.0) at https://github.com/galaxyproject/blend4phpDatabase URL: https://github.com/galaxyproject/blend4php."	github.com/galaxyproject/blend4phpDatabase	https://github.com/galaxyproject/blend4phpDatabase/	galaxyproject	blend4phpDatabase			0	0		wrong link	https://github.com/galaxyproject/blend4php/
32003785	10/29/2020	10.1093/bioinformatics/btaa068	"Bioinformatics (Oxford, England)"	GEMtractor: extracting views into genome-scale metabolic models.	"Computational metabolic models typically encode for graphs of species, reactions and enzymes. Comparing genome-scale models through topological analysis of multipartite graphs is challenging. However, in many practical cases it is not necessary to compare the full networks. The GEMtractor is a web-based tool to trim models encoded in SBML. It can be used to extract subnetworks, for example focusing on reaction- and enzyme-centric views into the model. The GEMtractor is licensed under the terms of GPLv3 and developed at github.com/binfalse/GEMtractor-a public version is available at sbi.uni-rostock.de/gemtractor. "	github.com/binfalse/GEMtractor-a	https://github.com/binfalse/GEMtractor-a/	binfalse	GEMtractor-a			0	0		wrong link	https://github.com/binfalse/GEMtractor/
28089956	02/12/2018	10.1093/ije/dyw341	International journal of epidemiology	Robust causal inference using directed acyclic graphs: the R package 'dagitty'.	"Directed acyclic graphs (DAGs), which offer systematic representations of causal relationships, have become an established framework for the analysis of causal inference in epidemiology, often being used to determine covariate adjustment sets for minimizing confounding bias. DAGitty is a popular web application for drawing and analysing DAGs. Here we introduce the R package 'dagitty', which provides access to all of the capabilities of the DAGitty web application within the R platform for statistical computing, and also offers several new functions. We describe how the R package 'dagitty' can be used to: evaluate whether a DAG is consistent with the dataset it is intended to represent; enumerate 'statistically equivalent' but causally different DAGs; and identify exposure-outcome adjustment sets that are valid for causally different but statistically equivalent DAGs. This functionality enables epidemiologists to detect causal misspecifications in DAGs and make robust inferences that remain valid for a range of different DAGs. The R package 'dagitty' is available through the comprehensive R archive network (CRAN) at [https://cran.r-project.org/web/packages/dagitty/]. The source code is available on github at [https://github.com/jtextor/dagitty]. The web application 'DAGitty' is free software, licensed under the GNU general public licence (GPL) version 2 and is available at [http://dagitty.net/]."	github.com/jtextor/dagitty].	https://github.com/jtextor/dagitty]/	jtextor	dagitty]			0	0		wrong link	https://github.com/jtextor/dagitty/
35224614	04/11/2022	10.1093/bib/bbac016	Briefings in bioinformatics	Identifying drug-target interactions via heterogeneous graph attention networks combined with cross-modal similarities.	"Accurate identification of drug-target interactions (DTIs) plays a crucial role in drug discovery. Compared with traditional experimental methods that are labor-intensive and time-consuming, computational methods are more and more popular in recent years. Conventional computational methods almost simply view heterogeneous networks which integrate diverse drug-related and target-related dataset instead of fully exploring drug and target similarities. In this paper, we propose a new method, named DTIHNC, for $\mathbf{D}$rug-$\mathbf{T}$arget $\mathbf{I}$nteraction identification, which integrates $\mathbf{H}$eterogeneous $\mathbf{N}$etworks and $\mathbf{C}$ross-modal similarities calculated by relations between drugs, proteins, diseases and side effects. Firstly, the low-dimensional features of drugs, proteins, diseases and side effects are obtained from original features by a denoising autoencoder. Then, we construct a heterogeneous network across drug, protein, disease and side-effect nodes. In heterogeneous network, we exploit the heterogeneous graph attention operations to update the embedding of a node based on information in its 1-hop neighbors, and for multi-hop neighbor information, we propose random walk with restart aware graph attention to integrate more information through a larger neighborhood region. Next, we calculate cross-modal drug and protein similarities from cross-scale relations between drugs, proteins, diseases and side effects. Finally, a multiple-layer convolutional neural network deeply integrates similarity information of drugs and proteins with the embedding features obtained from heterogeneous graph attention network. Experiments have demonstrated its effectiveness and better performance than state-of-the-art methods. Datasets and a stand-alone package are provided on Github with website https://github.com/ningq669/DTIHNC."	github.com/ningq669/DTIHNC.	https://github.com/ningq669/DTIHNC/	ningq669	DTIHNC			0	0		repo deleted	
32750860	02/17/2022	10.1109/TCBB.2020.3000661	IEEE/ACM transactions on computational biology and bioinformatics	GenSeg and MR-GenSeg: A Novel Segmentation Algorithm and its Parallel MapReduce Based Approach for Identifying Genomic Regions With Copy Number Variations.	"Identifying intragenic as well as intergenic sequences of the DNA, having structural alterations, is a significantly important research area, since this may be the root cause of many neurological and autoimmune diseases, including cancer. Working with whole genome NGS data has provided a new insight in this regard, but has lead to huge explosion of data that is growing exponentially. Hence, the challenges lie in efficient means of storage and processing this big data. In this study, we have developed a novel segmentation algorithm, called GenSeg, and its parallel MapReduce based algorithm, called MR-GenSeg, for detecting copy number variations. In order to annotate CNVs (variants), segments formed by GenSeg/MR-GenSeg have been represented in a novel way using a binary tree, where each node is a CNV event. GenSeg considers each position specific data of whole genome DNA sequence, so that precise identification of breakpoints is possible. GenSeg/MR-GenSeg has been compared with twelve popular CNV detection algorithms, where it has outperformed the others in terms of sensitivity, and has achieved a good F-score value. MR-GenSeg has excelled in terms of SpeedUp, when compared with these algorithms. The effect of CNVs on immunoglobulin (IG) genes has also been analysed in this study. Availability: The source codes are available at https://github.com/rituparna-sinha/MapReduce-GENSEG."	github.com/rituparna-sinha/MapReduce-GENSEG.	https://github.com/rituparna-sinha/MapReduce-GENSEG/	rituparna-sinha	MapReduce-GENSEG			0	1	03/24/2020	repo deleted	
34650190	10/28/2021	10.1038/s41598-021-99986-3	Scientific reports	Development and prospective validation of COVID-19 chest X-ray screening model for patients attending emergency departments.	"Chest X-rays (CXRs) are the first-line investigation in patients presenting to emergency departments (EDs) with dyspnoea and are a valuable adjunct to clinical management of COVID-19 associated lung disease. Artificial intelligence (AI) has the potential to facilitate rapid triage of CXRs for further patient testing and/or isolation. In this work we develop an AI algorithm, CovIx, to differentiate normal, abnormal, non-COVID-19 pneumonia, and COVID-19 CXRs using a multicentre cohort of 293,143 CXRs. The algorithm is prospectively validated in 3289 CXRs acquired from patients presenting to ED with symptoms of COVID-19 across four sites in NHS Greater Glasgow and Clyde. CovIx achieves area under receiver operating characteristic curve for COVID-19 of 0.86, with sensitivity and F1-score up to 0.83 and 0.71 respectively, and performs on-par with four board-certified radiologists. AI-based algorithms can identify CXRs with COVID-19 associated pneumonia, as well as distinguish non-COVID pneumonias in symptomatic patients presenting to ED. Pre-trained models and inference scripts are freely available at https://github.com/beringresearch/bravecx-covid ."	github.com/beringresearch/bravecx-covid	https://github.com/beringresearch/bravecx-covid/	beringresearch	bravecx-covid			0	0		repo deleted	
30601936	06/17/2020	10.1093/bioinformatics/bty1051	"Bioinformatics (Oxford, England)"	DeepPhos: prediction of protein phosphorylation sites with deep learning.	"Phosphorylation is the most studied post-translational modification, which is crucial for multiple biological processes. Recently, many efforts have been taken to develop computational predictors for phosphorylation site prediction, but most of them are based on feature selection and discriminative classification. Thus, it is useful to develop a novel and highly accurate predictor that can unveil intricate patterns automatically for protein phosphorylation sites. In this study we present DeepPhos, a novel deep learning architecture for prediction of protein phosphorylation. Unlike multi-layer convolutional neural networks, DeepPhos consists of densely connected convolutional neuron network blocks which can capture multiple representations of sequences to make final phosphorylation prediction by intra block concatenation layers and inter block concatenation layers. DeepPhos can also be used for kinase-specific prediction varying from group, family, subfamily and individual kinase level. The experimental results demonstrated that DeepPhos outperforms competitive predictors in general and kinase-specific phosphorylation site prediction. The source code of DeepPhos is publicly deposited at https://github.com/USTCHIlab/DeepPhos. Supplementary data are available at Bioinformatics online. "	github.com/USTCHIlab/DeepPhos.	https://github.com/USTCHIlab/DeepPhos/	USTCHIlab	DeepPhos			0	0		owner deleted	
32123556	02/12/2020	10.1016/j.csbj.2020.01.013	Computational and structural biotechnology journal	C-RNNCrispr: Prediction of CRISPR/Cas9 sgRNA activity using convolutional and recurrent neural networks.	"CRISPR/Cas9 is a hot genomic editing tool, but its success is limited by the widely varying target efficiencies among different single guide RNAs (sgRNAs). In this study, we proposed C-RNNCrispr, a hybrid convolutional neural networks (CNNs) and bidirectional gate recurrent unit network (BGRU) framework, to predict CRISPR/Cas9 sgRNA on-target activity. C-RNNCrispr consists of two branches: sgRNA branch and epigenetic branch. The network receives the encoded binary matrix of sgRNA sequence and four epigenetic features as inputs, and produces a regression score. We introduced a transfer learning approach by using small-size datasets to fine-tune C-RNNCrispr model that were pre-trained from benchmark dataset, leading to substantially improved predictive performance. Experiments on commonly used datasets showed C-RNNCrispr outperforms the state-of-the-art methods in terms of prediction accuracy and generalization. Source codes are available at https://github.com/Peppags/C_RNNCrispr."	github.com/Peppags/C_RNNCrispr.	https://github.com/Peppags/C_RNNCrispr/	Peppags	C_RNNCrispr			0	0		wrong link	https://github.com/Peppags/C-RNNCrispr/
27479078	08/22/2017	10.1371/journal.pone.0160334	PloS one	"MetLab: An In Silico Experimental Design, Simulation and Analysis Tool for Viral Metagenomics Studies."	"Metagenomics, the sequence characterization of all genomes within a sample, is widely used as a virus discovery tool as well as a tool to study viral diversity of animals. Metagenomics can be considered to have three main steps; sample collection and preparation, sequencing and finally bioinformatics. Bioinformatic analysis of metagenomic datasets is in itself a complex process, involving few standardized methodologies, thereby hampering comparison of metagenomics studies between research groups. In this publication the new bioinformatics framework MetLab is presented, aimed at providing scientists with an integrated tool for experimental design and analysis of viral metagenomes. MetLab provides support in designing the metagenomics experiment by estimating the sequencing depth needed for the complete coverage of a species. This is achieved by applying a methodology to calculate the probability of coverage using an adaptation of Stevens' theorem. It also provides scientists with several pipelines aimed at simplifying the analysis of viral metagenomes, including; quality control, assembly and taxonomic binning. We also implement a tool for simulating metagenomics datasets from several sequencing platforms. The overall aim is to provide virologists with an easy to use tool for designing, simulating and analyzing viral metagenomes. The results presented here include a benchmark towards other existing software, with emphasis on detection of viruses as well as speed of applications. This is packaged, as comprehensive software, readily available for Linux and OSX users at https://github.com/norling/metlab."	github.com/norling/metlab.	https://github.com/norling/metlab/	norling	metlab			0	1	04/12/2020	repo deleted	
34178986	06/11/2021	10.3389/fcell.2021.659941	Frontiers in cell and developmental biology	Automatic Artery/Vein Classification Using a Vessel-Constraint Network for Multicenter Fundus Images.	"Retinal blood vessel morphological abnormalities are generally associated with cardiovascular, cerebrovascular, and systemic diseases, automatic artery/vein (A/V) classification is particularly important for medical image analysis and clinical decision making. However, the current method still has some limitations in A/V classification, especially the blood vessel edge and end error problems caused by the single scale and the blurred boundary of the A/V. To alleviate these problems, in this work, we propose a vessel-constraint network (VC-Net) that utilizes the information of vessel distribution and edge to enhance A/V classification, which is a high-precision A/V classification model based on data fusion. Particularly, the VC-Net introduces a vessel-constraint (VC) module that combines local and global vessel information to generate a weight map to constrain the A/V features, which suppresses the background-prone features and enhances the edge and end features of blood vessels. In addition, the VC-Net employs a multiscale feature (MSF) module to extract blood vessel information with different scales to improve the feature extraction capability and robustness of the model. And the VC-Net can get vessel segmentation results simultaneously. The proposed method is tested on publicly available fundus image datasets with different scales, namely, DRIVE, LES, and HRF, and validated on two newly created multicenter datasets: Tongren and Kailuan. We achieve a balance accuracy of 0.9554 and F1 scores of 0.7616 and 0.7971 for the arteries and veins, respectively, on the DRIVE dataset. The experimental results prove that the proposed model achieves competitive performance in A/V classification and vessel segmentation tasks compared with state-of-the-art methods. Finally, we test the Kailuan dataset with other trained fusion datasets, the results also show good robustness. To promote research in this area, the Tongren dataset and source code will be made publicly available. The dataset and code will be made available at https://github.com/huawang123/VC-Net."	github.com/huawang123/VC-Net.	https://github.com/huawang123/VC-Net/	huawang123	VC-Net			0	0		repo deleted	
27153653	08/02/2017	10.1093/bioinformatics/btw217	"Bioinformatics (Oxford, England)"	Informed kmer selection for de novo transcriptome assembly.	"De novo transcriptome assembly is an integral part for many RNA-seq workflows. Common applications include sequencing of non-model organisms, cancer or meta transcriptomes. Most de novo transcriptome assemblers use the de Bruijn graph (DBG) as the underlying data structure. The quality of the assemblies produced by such assemblers is highly influenced by the exact word length k As such no single kmer value leads to optimal results. Instead, DBGs over different kmer values are built and the assemblies are merged to improve sensitivity. However, no studies have investigated thoroughly the problem of automatically learning at which kmer value to stop the assembly. Instead a suboptimal selection of kmer values is often used in practice. Here we investigate the contribution of a single kmer value in a multi-kmer based assembly approach. We find that a comparative clustering of related assemblies can be used to estimate the importance of an additional kmer assembly. Using a model fit based algorithm we predict the kmer value at which no further assemblies are necessary. Our approach is tested with different de novo assemblers for datasets with different coverage values and read lengths. Further, we suggest a simple post processing step that significantly improves the quality of multi-kmer assemblies. We provide an automatic method for limiting the number of kmer values without a significant loss in assembly quality but with savings in assembly time. This is a step forward to making multi-kmer methods more reliable and easier to use. A general implementation of our approach can be found under: https://github.com/SchulzLab/KREATIONSupplementary information: Supplementary data are available at Bioinformatics online. mschulz@mmci.uni-saarland.de. "	github.com/SchulzLab/KREATIONSupplementary	https://github.com/SchulzLab/KREATIONSupplementary/	SchulzLab	KREATIONSupplementary			0	0		wrong link	https://github.com/SchulzLab/KREATION/
27708565	09/21/2016	10.3389/fnbeh.2016.00177	Frontiers in behavioral neuroscience	Non-parametric Algorithm to Isolate Chunks in Response Sequences.	"Chunking consists in grouping items of a sequence into small clusters, named chunks, with the assumed goal of lessening working memory load. Despite extensive research, the current methods used to detect chunks, and to identify different chunking strategies, remain discordant and difficult to implement. Here, we propose a simple and reliable method to identify chunks in a sequence and to determine their stability across blocks. This algorithm is based on a ranking method and its major novelty is that it provides concomitantly both the features of individual chunk in a given sequence, and an overall index that quantifies the chunking pattern consistency across sequences. The analysis of simulated data confirmed the validity of our method in different conditions of noise, chunk lengths and chunk numbers; moreover, we found that this algorithm was particularly efficient in the noise range observed in real data, provided that at least 4 sequence repetitions were included in each experimental block. Furthermore, we applied this algorithm to actual reaction time series gathered from 3 published experiments and were able to confirm the findings obtained in the original reports. In conclusion, this novel algorithm is easy to implement, is robust to outliers and provides concurrent and reliable estimation of chunk position and chunking dynamics, making it useful to study both sequence-specific and general chunking effects. The algorithm is available at: https://github.com/artipago/Non-parametric-algorithm-to-isolate-chunks-in-response-sequences."	github.com/artipago/Non-parametric-algorithm-to-isolate-chunks-in-response-sequences.	https://github.com/artipago/Non-parametric-algorithm-to-isolate-chunks-in-response-sequences/	artipago	Non-parametric-algorithm-to-isolate-chunks-in-response-sequences			0	1	10/31/2018	renamed	https://github.com/artipago/Non-parametric-algorithm-to-isolate-chunks-in-response-sequences--Alamia-2016-/
35664040	05/18/2022	10.1016/j.mex.2022.101731	MethodsX	Computationally efficient barycentric interpolation of large grain boundary octonion point sets.	"We present a method for performing efficient barycentric interpolation for large grain boundary octonion point sets which reside on the surface of a hypersphere. This method includes removal of degenerate dimensions via singular value decomposition (SVD) transformations and linear projections, determination of intersecting facets via nearest neighbor (NN) searches, and interpolation. This method is useful for hyperspherical point sets for applications such as grain boundaries structure-property models, robotics, and specialized neural networks. We provide a case study of the method applied to the 7-sphere. We provide 1-sphere and 2-sphere visualizations to illustrate important aspects of these dimension reduction and interpolation methods. A MATLAB implementation is available at github.com/sgbaird-5dof/interp.•Barycentric interpolation is combined with hypersphere facet intersections, dimensionality reduction, and linear projections to reduce computational complexity without loss of information•A max nearest neighbor threshold is used in conjunction with facet intersection determination to reduce computational runtime."	github.com/sgbaird-5dof/interp.•Barycentric	https://github.com/sgbaird-5dof/interp.•Barycentric/	sgbaird-5dof	interp.•Barycentric			0	0		wrong link	https://github.com/sgbaird-5DOF/interp/
35035264	01/08/2022	10.1007/s11042-021-11477-9	Multimedia tools and applications	Screening of breast cancer from thermogram images by edge detection aided deep transfer learning model.	"Breast cancer, the most common invasive cancer, causes deaths of thousands of women in the world every year. Early detection of the same is a remedy to lessen the death rate. Hence, screening of breast cancer in its early stage is utmost required. However, in the developing nations not many can afford the screening and detection procedures owing to its cost. Hence, an effective and less expensive way of detecting breast cancer is performed using thermography which, unlike other methods, can be used on women of various ages. To this end, we propose a computer aided breast cancer detection system that accepts thermal breast images to detect the same. Here, we use the pre-trained DenseNet121 model as a feature extractor to build a classifier for the said purpose. Before extracting features, we work on the original thermal breast images to get outputs using two edge detectors - Prewitt and Roberts. These two edge-maps along with the original image make the input to the DenseNet121 model as a 3-channel image. The thermal breast image dataset namely, Database for Mastology Research (DMR-IR) is used to evaluate performance of our model. We achieve the highest classification accuracy of 98.80% on the said database, which outperforms many state-of-the-art methods, thereby confirming the superiority of the proposed model. Source code of this work is available here: https://github.com/subro608/thermogram_breast_cancer."	github.com/subro608/thermogram_breast_cancer.	https://github.com/subro608/thermogram_breast_cancer/	subro608	thermogram_breast_cancer			0	0		repo deleted	
29994416	07/02/2018	10.1109/TCYB.2018.2846361	IEEE transactions on cybernetics	Stereo Video Object Segmentation Using Stereoscopic Foreground Trajectories.	"We present an unsupervised segmentation framework for stereo videos using stereoscopic trajectories. The proposed stereo trajectory shows favorable properties for modeling the long-term motion information through the whole sequence and explicitly capturing the corresponding relationships between two stereo views. The stereo prior is important for inferring the desired object and guarantees the consistent spatial-temporal segmentation, which contributes to an enjoyable stereo experience. We start by deriving stereo trajectories from left and right views simultaneously, which are represented via a graph structure. Then we detect object-like stereo trajectories via the graph structure to efficiently infer the desired object. Finally, an energy optimization function is proposed to produce the stereo segmentation results via leveraging the object information from stereo trajectories. To benefit potential research, we collected a new stereoscopic video benchmark, which consists of a total of 50 stereo video clips and includes many challenges in segmentation. Extensive experimental results demonstrate that our stereo segmentation method achieves higher performance and preserves better stereo structures, compared with prevailing competitors. The source code and results are available at: https://github.com/shenjianbing/StereoSeg."	github.com/shenjianbing/StereoSeg.	https://github.com/shenjianbing/StereoSeg/	shenjianbing	StereoSeg			0	0		repo deleted	
35580514	06/16/2022	10.1016/j.neunet.2022.04.026	Neural networks : the official journal of the International Neural Network Society	Multi-level landmark-guided deep network for face super-resolution.	"Recent years deep learning-based methods incorporating facial prior knowledge for face super-resolution (FSR) are advancing and have gained impressive performance. However, some important priors such as facial landmarks are not fully exploited in existing methods, leading to noticeable artifacts in the resultant SR face images especially under large magnification. In this paper, we propose a novel multi-level landmark-guided deep network (MLGDN) for FSR. More specifically, to fully exploit the dependencies between low and high resolution images and to reduce network parameters as well as capture more reliable feature representation, we introduce a recursive back-projection network with a particular feedback mechanism for coarse-to-fine FSR. Furthermore, we incorporate an attention fusion module in the front of backbone network to strengthen face components and a feature modulation module to refine features in the middle of backbone network. By this way, the facial landmarks extracted from face images can be fully shared by the modules in different levels, which benefit to produce more faithful facial details. Both quantitative and qualitative performance evaluations on two benchmark databases demonstrate that the proposed MLGDN can achieve more impressive SR results than other state-of-the-art competitors. Code will be available at https://github.com/zhuangcheng31/MLG_Face.git/."	github.com/zhuangcheng31/MLG_Face.git/.	https://github.com/zhuangcheng31/MLG_Face.git/	zhuangcheng31	MLG_Face.git			0	0		wrong link	https://github.com/zhuangcheng31/MLG_Face/
36449588	05/04/2023	10.1109/TMI.2022.3225687	IEEE transactions on medical imaging	Semi-Supervised Medical Image Segmentation Using Adversarial Consistency Learning and Dynamic Convolution Network.	"Popular semi-supervised medical image segmentation networks often suffer from error supervision from unlabeled data since they usually use consistency learning under different data perturbations to regularize model training. These networks ignore the relationship between labeled and unlabeled data, and only compute single pixel-level consistency leading to uncertain prediction results. Besides, these networks often require a large number of parameters since their backbone networks are designed depending on supervised image segmentation tasks. Moreover, these networks often face a high over-fitting risk since a small number of training samples are popular for semi-supervised image segmentation. To address the above problems, in this paper, we propose a novel adversarial self-ensembling network using dynamic convolution (ASE-Net) for semi-supervised medical image segmentation. First, we use an adversarial consistency training strategy (ACTS) that employs two discriminators based on consistency learning to obtain prior relationships between labeled and unlabeled data. The ACTS can simultaneously compute pixel-level and image-level consistency of unlabeled data under different data perturbations to improve the prediction quality of labels. Second, we design a dynamic convolution-based bidirectional attention component (DyBAC) that can be embedded in any segmentation network, aiming at adaptively adjusting the weights of ASE-Net based on the structural information of input samples. This component effectively improves the feature representation ability of ASE-Net and reduces the overfitting risk of the network. The proposed ASE-Net has been extensively tested on three publicly available datasets, and experiments indicate that ASE-Net is superior to state-of-the-art networks, and reduces computational costs and memory overhead. The code is available at: https://github.com/SUST-reynole/ASE-Nethttps://github.com/SUST-reynole/ASE-Net."	github.com/SUST-reynole/ASE-Nethttps	https://github.com/SUST-reynole/ASE-Nethttps/	SUST-reynole	ASE-Nethttps			0	0		wrong link	https://github.com/SUST-reynole/ASE-Net/
28977511	12/04/2017	10.1093/nar/gkx767	Nucleic acids research	Towards enhanced and interpretable clustering/classification in integrative genomics.	"High-throughput technologies have led to large collections of different types of biological data that provide unprecedented opportunities to unravel molecular heterogeneity of biological processes. Nevertheless, how to jointly explore data from multiple sources into a holistic, biologically meaningful interpretation remains challenging. In this work, we propose a scalable and tuning-free preprocessing framework, Heterogeneity Rescaling Pursuit (Hetero-RP), which weighs important features more highly than less important ones in accord with implicitly existing auxiliary knowledge. Finally, we demonstrate effectiveness of Hetero-RP in diverse clustering and classification applications. More importantly, Hetero-RP offers an interpretation of feature importance, shedding light on the driving forces of the underlying biology. In metagenomic contig binning, Hetero-RP automatically weighs abundance and composition profiles according to the varying number of samples, resulting in markedly improved performance of contig binning. In RNA-binding protein (RBP) binding site prediction, Hetero-RP not only improves the prediction performance measured by the area under the receiver operating characteristic curves (AUC), but also uncovers the evidence supported by independent studies, including the distribution of the binding sites of IGF2BP and PUM2, the binding competition between hnRNPC and U2AF2, and the intron-exon boundary of U2AF2 [availability: https://github.com/younglululu/Hetero-RP]."	github.com/younglululu/Hetero-RP].	https://github.com/younglululu/Hetero-RP]/	younglululu	Hetero-RP]			0	0		wrong link	https://github.com/younglululu/Hetero-RP/
29069317	10/17/2018	10.1093/bioinformatics/btx672	"Bioinformatics (Oxford, England)"	Constructing prediction models from expression profiles for large scale lncRNA-miRNA interaction profiling.	"The interaction of miRNA and lncRNA is known to be important for gene regulations. However, not many computational approaches have been developed to analyze known interactions and predict the unknown ones. Given that there are now more evidences that suggest that lncRNA-miRNA interactions are closely related to their relative expression levels in the form of a titration mechanism, we analyzed the patterns in large-scale expression profiles of known lncRNA-miRNA interactions. From these uncovered patterns, we noticed that lncRNAs tend to interact collaboratively with miRNAs of similar expression profiles, and vice versa. By representing known interaction between lncRNA and miRNA as a bipartite graph, we propose here a technique, called EPLMI, to construct a prediction model from such a graph. EPLMI performs its tasks based on the assumption that lncRNAs that are highly similar to each other tend to have similar interaction or non-interaction patterns with miRNAs and vice versa. The effectiveness of the prediction model so constructed has been evaluated using the latest dataset of lncRNA-miRNA interactions. The results show that the prediction model can achieve AUCs of 0.8522 and 0.8447 ± 0.0017 based on leave-one-out cross validation and 5-fold cross validation. Using this model, we show that lncRNA-miRNA interactions can be reliably predicted. We also show that we can use it to select the most likely lncRNA targets that specific miRNAs would interact with. We believe that the prediction models discovered by EPLMI can yield great insights for further research on ceRNA regulation network. To the best of our knowledge, EPLMI is the first technique that is developed for large-scale lncRNA-miRNA interaction profiling. Matlab codes and dataset are available at https://github.com/yahuang1991polyu/EPLMI/. yu-an.huang@connect.polyu.hk or zhuhongyou@ms.xjb.ac.cn. Supplementary data are available at Bioinformatics online. "	github.com/yahuang1991polyu/EPLMI/.	https://github.com/yahuang1991polyu/EPLMI/	yahuang1991polyu	EPLMI			0	0		repo deleted	
32883297	12/14/2020	10.1186/s12984-020-00738-7	Journal of neuroengineering and rehabilitation	Toward a hybrid exoskeleton for crouch gait in children with cerebral palsy: neuromuscular electrical stimulation for improved knee extension.	"Neuromuscular Electrical Stimulation (NMES) has been utilized for many years in cerebral palsy (CP) with limited success despite its inherent potential for improving muscle size and/or strength, inhibiting or reducing spasticity, and enhancing motor performance during functional activities such as gait. While surface NMES has been shown to successfully improve foot drop in CP and stroke, correction of more complex gait abnormalities in CP such as flexed knee (crouch) gait remains challenging due to the level of stimulation needed for the quadriceps muscles that must be balanced with patient tolerability and the ability to deliver NMES assistance at precise times within a gait cycle. This paper outlines the design and evaluation of a custom, noninvasive NMES system that can trigger and adjust electrical stimulation in real-time. Further, this study demonstrates feasibility of one possible application for this digitally-controlled NMES system as a component of a pediatric robotic exoskeleton to provide on-demand stimulation to leg muscles within specific phases of the gait cycle for those with CP and other neurological disorders who still have lower limb sensation and volitional control. A graphical user interface was developed to digitally set stimulation parameters (amplitude, pulse width, and frequency), timing, and intensity during walking. Benchtop testing characterized system delay and power output. System performance was investigated during a single session that consisted of four overground walking conditions in a 15-year-old male with bilateral spastic CP, GMFCS Level III: (1) his current Ankle-Foot Orthosis (AFO); (2) unassisted Exoskeleton; (3) NMES of the vastus lateralis; and (4) NMES of the vastus lateralis and rectus femoris. We hypothesized in this participant with crouch gait that NMES triggered with low latency to knee extensor muscles during stance would have a modest but positive effect on knee extension during stance. The system delivers four channels of NMES with average delays of 16.5?±?13.5?ms. Walking results show NMES to the vastus lateralis and rectus femoris during stance immediately improved mean peak knee extension during mid-stance (p?=?0.003*) and total knee excursion (p?=?0.009*) in the more affected leg. The electrical design, microcontroller software and graphical user interface developed here are included as open source material to facilitate additional research into digitally-controlled surface stimulation ( github.com/NIHFAB/NMES ). The custom, digitally-controlled NMES system can reliably trigger electrical stimulation with low latency. Precisely timed delivery of electrical stimulation to the quadriceps is a promising treatment for crouch. Our ultimate goal is to synchronize NMES with robotic knee extension assistance to create a hybrid NMES-exoskeleton device for gait rehabilitation in children with flexed knee gait from CP as well as from other pediatric disorders. clinicaltrials.gov, ID: NCT01961557 . Registered 11 October 2013; Last Updated 27 January 2020. "	github.com/NIHFAB/NMES	https://github.com/NIHFAB/NMES/	NIHFAB	NMES			0	0		repo deleted	
27913617	05/30/2017	10.1534/genetics.116.194878	Genetics	Evaluating Sequence-Based Genomic Prediction with an Efficient New Simulator.	"The vast amount of sequence data generated to analyze complex traits is posing new challenges in terms of the analysis and interpretation of the results. Although simulation is a fundamental tool to investigate the reliability of genomic analyses and to optimize experimental design, existing software cannot realistically simulate complete genomes. To remedy this, we have developed a new strategy (Sequence-Based Virtual Breeding, SBVB) that uses real sequence data and simulates new offspring genomes and phenotypes in a very efficient and flexible manner. Using this tool, we studied the efficiency of full sequence in genomic prediction compared to SNP arrays. We used real porcine sequences from three breeds as founder genomes of a 2500-animal pedigree and two genetic architectures: ""neutral"" and ""selective."" In the neutral architecture, frequencies and allele effects were sampled independently whereas, in the selective case, SNPs were sites putatively under selection after domestication and a negative correlation between effect and frequency was induced. We compared the effectiveness of different genotyping strategies for genomic selection, including the use of full sequence commercial arrays or randomly chosen SNP sets in both outbred and crossbred experimental designs. We found that accuracy increases using sequence instead of commercial chips but modestly, perhaps by ? 4%. This result was robust to extreme genetic architectures. We conclude that full sequence is unlikely to offset commercial arrays for predicting genetic value when the number of loci is relatively large and the prior given to each SNP is uniform. Using sequence to improve selection thus requires optimized prior information and, likely, increased population sizes. The code and manual for SBVB are available at https://github.com/mperezenciso/sbvb0."	github.com/mperezenciso/sbvb0.	https://github.com/mperezenciso/sbvb0/	mperezenciso	sbvb0			0	1	07/20/2019	repo deleted	
32750802	05/07/2023	10.1109/TPAMI.2020.3007032	IEEE transactions on pattern analysis and machine intelligence	CCNet: Criss-Cross Attention for Semantic Segmentation.	"Contextual information is vital in visual understanding problems, such as semantic segmentation and object detection. We propose a criss-cross network (CCNet) for obtaining full-image contextual information in a very effective and efficient way. Concretely, for each pixel, a novel criss-cross attention module harvests the contextual information of all the pixels on its criss-cross path. By taking a further recurrent operation, each pixel can finally capture the full-image dependencies. Besides, a category consistent loss is proposed to enforce the criss-cross attention module to produce more discriminative features. Overall, CCNet is with the following merits: 1) GPU memory friendly. Compared with the non-local block, the proposed recurrent criss-cross attention module requires 11? less GPU memory usage. 2) High computational efficiency. The recurrent criss-cross attention significantly reduces FLOPs by about 85 percent of the non-local block. 3) The state-of-the-art performance. We conduct extensive experiments on semantic segmentation benchmarks including Cityscapes, ADE20K, human parsing benchmark LIP, instance segmentation benchmark COCO, video segmentation benchmark CamVid. In particular, our CCNet achieves the mIoU scores of 81.9, 45.76 and 55.47 percent on the Cityscapes test set, the ADE20K validation set and the LIP validation set respectively, which are the new state-of-the-art results. The source codes are available at https://github.com/speedinghzl/CCNethttps://github.com/speedinghzl/CCNet."	github.com/speedinghzl/CCNethttps	https://github.com/speedinghzl/CCNethttps/	speedinghzl	CCNethttps			0	0		wrong link	https://github.com/speedinghzl/CCNet/
34754797	09/24/2021	10.1016/j.mex.2021.101527	MethodsX	Python program for spatial reduction and reconstruction method in flood inundation modelling.	"Fast and accurate modelling of flood inundation has gained increasing attention in recent years. One approach gaining popularity recently is the development of emulation models using data driven methods, such as artificial neural networks. These emulation models are often developed to model flood depth for each grid cell in the modelling domain in order to maintain accurate spatial representation of the flood inundation surface. This leads to redundancy in modelling, as well as difficulties in achieving good model performance across floodplains where there are limited data available. In this paper, a spatial reduction and reconstruction (SRR) method is developed to (1) identify representative locations within the model domain where water levels can be used to represent flood inundation surface using deep learning models; and (2) reconstruct the flood inundation surface based on water levels simulated at these representative locations. The SRR method is part of the SRR-Deep-Learning framework for flood inundation modelling and therefore, it needs to be used together with data driven models. The SRR method is programmed using the Python programming language and is freely available from https://github.com/yuerongz/SRR-method.•The SRR method identifies locations which are representative of flood inundation behavior in surrounding areas.•The representative locations selected following the SRR method have sufficient flood data for developing emulation models.•Flood inundation surfaces can be reconstructed using the SRR method with a detection rate of above 99%."	github.com/yuerongz/SRR-method.•The	https://github.com/yuerongz/SRR-method.•The/	yuerongz	SRR-method.•The			0	0		wrong link	https://github.com/yuerongz/SRR-method/
34335711	08/03/2021	10.1155/2021/2883559	Computational intelligence and neuroscience	Stable Median Centre Clustering for Unsupervised Domain Adaptation Person Re-Identification.	"The current unsupervised domain adaptation person re-identification (re-ID) method aims to solve the domain shift problem and applies prior knowledge learned from labelled data in the source domain to unlabelled data in the target domain for person re-ID. At present, the unsupervised domain adaptation person re-ID method based on pseudolabels has obtained state-of-the-art performance. This method obtains pseudolabels via a clustering algorithm and uses these pseudolabels to optimize a CNN model. Although it achieves optimal performance, the model cannot be further optimized due to the existence of noisy labels in the clustering process. In this paper, we propose a stable median centre clustering (SMCC) for the unsupervised domain adaptation person re-ID method. SMCC adaptively mines credible samples for optimization purposes and reduces the impact of label noise and outliers on training to improve the performance of the resulting model. In particular, we use the intracluster distance confidence measure of the sample and its -reciprocal nearest neighbour cluster proportion in the clustering process to select credible samples and assign different weights according to the intracluster sample distance confidence of samples to measure the distances between different clusters, thereby making the clustering results more robust. The experiments show that our SMCC method can select credible and stable samples for training and improve performance of the unsupervised domain adaptation model. Our code is available at https://github.com/sunburst792/SMCC-method/tree/master. "	github.com/sunburst792/SMCC-method/tree/master.	https://github.com/sunburst792/SMCC-method/tree/master/	sunburst792	SMCC-method			0	0		repo deleted	
27587663	07/31/2017	10.1093/bioinformatics/btw435	"Bioinformatics (Oxford, England)"	Mutual enrichment in aggregated ranked lists with applications to gene expression regulation.	"It is often the case in biological measurement data that results are given as a ranked list of quantities-for example, differential expression (DE) of genes as inferred from microarrays or RNA-seq. Recent years brought considerable progress in statistical tools for enrichment analysis in ranked lists. Several tools are now available that allow users to break the fixed set paradigm in assessing statistical enrichment of sets of genes. Continuing with the example, these tools identify factors that may be associated with measured differential expression. A drawback of existing tools is their focus on identifying single factors associated with the observed or measured ranks, failing to address relationships between these factors. For example, a scenario in which genes targeted by multiple miRNAs play a central role in the DE signal but the effect of each single miRNA is too subtle to be detected, as shown in our results. We propose statistical and algorithmic approaches for selecting a sub-collection of factors that can be aggregated into one ranked list that is heuristically most associated with an input ranked list (pivot). We examine performance on simulated data and apply our approach to cancer datasets. We find small sub-collections of miRNA that are statistically associated with gene DE in several types of cancer, suggesting miRNA cooperativity in driving disease related processes. Many of our findings are consistent with known roles of miRNAs in cancer, while others suggest previously unknown roles for certain miRNAs. Code and instructions for our algorithmic framework, MULSEA, are in: https://github.com/YakhiniGroup/MULSEAContact:dalia.cohn@gmail.com Supplementary data are available at Bioinformatics online. "	github.com/YakhiniGroup/MULSEAContact	https://github.com/YakhiniGroup/MULSEAContact/	YakhiniGroup	MULSEAContact			0	0		wrong link	https://github.com/YakhiniGroup/MULSEA/
35578654	05/12/2022	10.1016/j.neucom.2022.05.009	Neurocomputing	Effective multiscale deep learning model for COVID19 segmentation tasks: A further step towards helping radiologist.	"Infection by the SARS-CoV-2 leading to COVID-19 disease is still rising and techniques to either diagnose or evaluate the disease are still thoroughly investigated. The use of CT as a complementary tool to other biological tests is still under scrutiny as the CT scans are prone to many false positives as other lung diseases display similar characteristics on CT scans. However, fully investigating CT images is of tremendous interest to better understand the disease progression and therefore thousands of scans need to be segmented by radiologists to study infected areas. Over the last year, many deep learning models for segmenting CT-lungs were developed. Unfortunately, the lack of large and shared annotated multicentric datasets led to models that were either under-tested (small dataset) or not properly compared (own metrics, none shared dataset), often leading to poor generalization performance. To address, these issues, we developed a model that uses a multiscale and multilevel feature extraction strategy for COVID19 segmentation and extensively validated it on several datasets to assess its generalization capability for other segmentation tasks on similar organs. The proposed model uses a novel encoder and decoder with a proposed kernel-based atrous spatial pyramid pooling module that is used at the bottom of the model to extract small features with a multistage skip connection concatenation approach. The results proved that our proposed model could be applied on a small-scale dataset and still produce generalizable performances on other segmentation tasks. The proposed model produced an efficient Dice score of 90% on a 100 cases dataset, 95% on the NSCLC dataset, 88.49% on the COVID19 dataset, and 97.33 on the StructSeg 2019 dataset as compared to existing state-of-the-art models. The proposed solution could be used for COVID19 segmentation in clinic applications. The source code is publicly available at https://github.com/RespectKnowledge/Mutiscale-based-Covid-_segmentation-usingDeep-Learning-models."	github.com/RespectKnowledge/Mutiscale-based-Covid-_segmentation-usingDeep-Learning-models.	https://github.com/RespectKnowledge/Mutiscale-based-Covid-_segmentation-usingDeep-Learning-models/	RespectKnowledge	Mutiscale-based-Covid-_segmentation-usingDeep-Learning-models			0	0		wrong link	https://github.com/RespectKnowledge/Mutiscale-based-Covid-_segmentation-using-Deep-Learning-models/
24470571	08/15/2014	10.1093/bioinformatics/btu050	"Bioinformatics (Oxford, England)"	Bio Simulators: a web UI for biological simulation.	"A host of formal, textual languages for modeling cellular processes have recently emerged, but their simulation tools often require an installation process which can pose a barrier for use. Bio Simulators is a framework for easy online deployment of simulators, providing a uniform web-based user interface to a diverse pool of tools. The framework is demonstrated through two plugins based on the KaSim Kappa simulator, one running directly in the browser and another running in the cloud. Web tool: bsims.azurewebsites.net. KaSim client side simulator: github.com/NicolasOury/KaSimJS. KaSim cloud simulator: github.com/mdpedersen/KaSimCloud. michael.d.pedersen@gmail.com or Andrew.Phillips@microsoft.com Supplementary data are available at Bioinformatics online. "	github.com/NicolasOury/KaSimJS.	https://github.com/NicolasOury/KaSimJS/	NicolasOury	KaSimJS			0	1	05/17/2021	repo deleted	
33630065	09/09/2021	10.1093/bioinformatics/btab128	"Bioinformatics (Oxford, England)"	Privacy-preserving and robust watermarking on sequential genome data using belief propagation and local differential privacy.	"Genome data is a subject of study for both biology and computer science since the start of the Human Genome Project in 1990. Since then, genome sequencing for medical and social purposes becomes more and more available and affordable. Genome data can be shared on public websites or with service providers (SPs). However, this sharing compromises the privacy of donors even under partial sharing conditions. We mainly focus on the liability aspect ensued by the unauthorized sharing of these genome data. One of the techniques to address the liability issues in data sharing is the watermarking mechanism. To detect malicious correspondents and SPs-whose aim is to share genome data without individuals' consent and undetected-, we propose a novel watermarking method on sequential genome data using belief propagation algorithm. In our method, we have two criteria to satisfy. (i) Embedding robust watermarks so that the malicious adversaries cannot temper the watermark by modification and are identified with high probability. (ii) Achieving ?-local differential privacy in all data sharings with SPs. For the preservation of system robustness against single SP and collusion attacks, we consider publicly available genomic information like Minor Allele Frequency, Linkage Disequilibrium, Phenotype Information and Familial Information. Our proposed scheme achieves 100% detection rate against the single SP attacks with only 3% watermark length. For the worst case scenario of collusion attacks (50% of SPs are malicious), 80% detection is achieved with 5% watermark length and 90% detection is achieved with 10% watermark length. For all cases, the impact of ? on precision remained negligible and high privacy is ensured. https://github.com/acoksuz/PPRW\_SGD\_BPLDP. Supplementary data are available at Bioinformatics online. "	github.com/acoksuz/PPRW\\_SGD\\_BPLDP.	https://github.com/acoksuz/PPRW\\_SGD\\_BPLDP/	acoksuz	PPRW\\_SGD\\_BPLDP			0	0		wrong link	https://github.com/acoksuz/PPRW_SGD_BPLDP/
31793982	12/23/2020	10.1093/bioinformatics/btz825	"Bioinformatics (Oxford, England)"	An efficient approach based on multi-sources information to predict circRNA-disease associations using deep convolutional neural network.	"Emerging evidence indicates that circular RNA (circRNA) plays a crucial role in human disease. Using circRNA as biomarker gives rise to a new perspective regarding our diagnosing of diseases and understanding of disease pathogenesis. However, detection of circRNA-disease associations by biological experiments alone is often blind, limited to small scale, high cost and time consuming. Therefore, there is an urgent need for reliable computational methods to rapidly infer the potential circRNA-disease associations on a large scale and to provide the most promising candidates for biological experiments. In this article, we propose an efficient computational method based on multi-source information combined with deep convolutional neural network (CNN) to predict circRNA-disease associations. The method first fuses multi-source information including disease semantic similarity, disease Gaussian interaction profile kernel similarity and circRNA Gaussian interaction profile kernel similarity, and then extracts its hidden deep feature through the CNN and finally sends them to the extreme learning machine classifier for prediction. The 5-fold cross-validation results show that the proposed method achieves 87.21% prediction accuracy with 88.50% sensitivity at the area under the curve of 86.67% on the CIRCR2Disease dataset. In comparison with the state-of-the-art SVM classifier and other feature extraction methods on the same dataset, the proposed model achieves the best results. In addition, we also obtained experimental support for prediction results by searching published literature. As a result, 7 of the top 15 circRNA-disease pairs with the highest scores were confirmed by literature. These results demonstrate that the proposed model is a suitable method for predicting circRNA-disease associations and can provide reliable candidates for biological experiments. The source code and datasets explored in this work are available at https://github.com/look0012/circRNA-Disease-association. Supplementary data are available at Bioinformatics online. "	github.com/look0012/circRNA-Disease-association.	https://github.com/look0012/circRNA-Disease-association/	look0012	circRNA-Disease-association			0	1	04/21/2020	repo deleted	
32857695	08/28/2020	10.1109/TIP.2020.3018269	IEEE transactions on image processing : a publication of the IEEE Signal Processing Society	Learning Layer-Skippable Inference Network.	"The process of learning good representations for machine learning tasks can be very computationally expensive. Typically, we facilitate the same backbones learned on the training set to infer the labels of testing data. Interestingly, This learning and inference paradigm, however, is quite different from the typical inference scheme of human biological visual systems. Essentially, neuroscience studies have shown that the right hemisphere of the human brain predominantly makes a fast processing of low-frequency spatial signals, while the left hemisphere more focuses on analyzing high-frequency information in a slower way. And the low-pass analysis helps facilitate the high-pass analysis via a feedback form. Inspired by this biological vision mechanism, this paper explores the possibility of learning a layer-skippable inference network. Specifically, we propose a layer-skippable network that dynamically carries out coarse-tofine object categorization. Such a network has two branches to jointly deal with both coarse and fine-grained classification tasks. The layer-skipping mechanism is proposed to learn a gating network by generating dynamic inference graphs, and reducing the computational cost by detouring the inference path from some layers. This adaptive path inference strategy endows the network with better flexibility and larger capacity and makes the high-performance deep networks with dynamic structures. To efficiently train the gating network, a novel ranking-based loss function is presented. Furthermore, the learned representations are enhanced by the proposed top-down feedback facilitation and feature-wise affine transformation, individually. The former one employs features of a coarse branch to help the finegrained object recognition task, while the latter one encodes the selected path to enhance the final feature representations. Extensive experiments are conducted on several widely used coarse-to-fine object categorization benchmarks, and promising results are achieved by our proposed model. Quite surprisingly, our layer-skipping mechanism improves the network robustness to adversarial attacks. The codes and models are released on https://github.com/avalonstrel/DSN."	github.com/avalonstrel/DSN.	https://github.com/avalonstrel/DSN/	avalonstrel	DSN			0	1	03/14/2021	repo deleted	
32386162	01/26/2022	10.1109/TCBB.2020.2992605	IEEE/ACM transactions on computational biology and bioinformatics	Unsupervised Learning Framework With Multidimensional Scaling in Predicting Epithelial-Mesenchymal Transitions.	"Clustering tumor metastasis samples from gene expression data at the whole genome level remains an arduous challenge, in particular, when the number of experimental samples is small and the number of genes is huge. We focus on the prediction of the epithelial-mesenchymal transition (EMT), which is an underlying mechanism of tumor metastasis, here, rather than tumor metastasis itself, to avoid confounding effects of uncertainties derived from various factors. In this paper, we propose a novel model in predicting EMT based on multidimensional scaling (MDS) strategies and integrating entropy and random matrix detection strategies to determine the optimal reduced number of dimension in low dimensional space. We verified our proposed model with the gene expression data for EMT samples of breast cancer and the experimental results demonstrated the superiority over state-of-the-art clustering methods. Furthermore, we developed a novel feature extraction method for selecting the significant genes and predicting the tumor metastasis. The source code is available at ""https://github.com/yushanqiu/yushan.qiu-szu.edu.cn""."	"github.com/yushanqiu/yushan.qiu-szu.edu.cn""."	"https://github.com/yushanqiu/yushan.qiu-szu.edu.cn""/"	yushanqiu	"yushan.qiu-szu.edu.cn"""			0	0		wrong link	https://github.com/yushanqiu/yushan.qiu-szu.edu.cn/
27382152	07/24/2017	10.1073/pnas.1510497113	Proceedings of the National Academy of Sciences of the United States of America	Linear mixed model for heritability estimation that explicitly addresses environmental variation.	"The linear mixed model (LMM) is now routinely used to estimate heritability. Unfortunately, as we demonstrate, LMM estimates of heritability can be inflated when using a standard model. To help reduce this inflation, we used a more general LMM with two random effects-one based on genomic variants and one based on easily measured spatial location as a proxy for environmental effects. We investigated this approach with simulated data and with data from a Uganda cohort of 4,778 individuals for 34 phenotypes including anthropometric indices, blood factors, glycemic control, blood pressure, lipid tests, and liver function tests. For the genomic random effect, we used identity-by-descent estimates from accurately phased genome-wide data. For the environmental random effect, we constructed a covariance matrix based on a Gaussian radial basis function. Across the simulated and Ugandan data, narrow-sense heritability estimates were lower using the more general model. Thus, our approach addresses, in part, the issue of ""missing heritability"" in the sense that much of the heritability previously thought to be missing was fictional. Software is available at https://github.com/MicrosoftGenomics/FaST-LMM."	github.com/MicrosoftGenomics/FaST-LMM.	https://github.com/MicrosoftGenomics/FaST-LMM/	MicrosoftGenomics	FaST-LMM			0	1	01/17/2021	owner deleted	
35753591	08/25/2022	10.1016/j.ymeth.2022.06.005	"Methods (San Diego, Calif.)"	PDSM-LGCN: Prediction of drug sensitivity associated microRNAs via light graph convolution neural network.	"Cancer has become one of the critical diseases threatening human life and health. The sensitivity difference of cancer drugs has always been a critical cause of the treatment come to nothing. Once drug resistance occurs, it will make the anticancer treatment or even various drugs ineffective. With the deepening of cancer research, a growing number of evidence shows that microRNA has a particular regulatory effect on the sensitivity of cancer drugs, which provides new research ideas. However, using traditional biological experiments to verify and discover the relations of microRNA-drug sensitivity is cumbersome and time-consuming, significantly slowing down cancer drug sensitivity's research progress. Therefore, this paper proposes a computational method (PDSM-LGCN) that spreads information through the high-order connection between cancer drug sensitivity and microRNA. At the same time, the model constructs an optimized-GCN as an embedding propagation layer to obtain the practical embeddings of microRNA and medicines. Finally, based on a collaborative filtering algorithm, the model brings the prediction score between microRNA and drug sensitivity. The results of fivefold cross-validation show that the AUC of PDSM-LGCN is 0.8872, and the AUPR is as high as 0.9026. At the same time, we also reproduced the five latest models of similar problems and compared the results. Our model has the best comprehensive effect among them. In addition, the reliability of PDSM-LGCN was further confirmed through the case study of Cisplatin and Doxorubicin, which can be used as a powerful tool for clinical and biological research. The source code and datasets can be obtained from https://github.com/19990915fzy/PDSM-LGCN/."	github.com/19990915fzy/PDSM-LGCN/.	https://github.com/19990915fzy/PDSM-LGCN/	19990915fzy	PDSM-LGCN			0	0		owner deleted	
35529153	10/16/2019	10.1039/c9ra06133a	RSC advances	NCPCDA: network consistency projection for circRNA-disease association prediction.	"A growing body of evidence indicates that circular RNAs (circRNAs) play a pivotal role in various biological processes and have a close association with the initiation and progression of diseases. Moreover, circRNAs are considered as promising biomarkers for disease diagnosis owing to their characteristics of conservation, stability and universality. Inferring disease-circRNA relationships will contribute to the understanding of disease pathology. However, it is costly and laborious to discover novel disease-circRNA interactions by wet-lab experiments, and few computational methods have been devoted to predicting potential circRNAs for diseases. Here, we advance a computational method (NCPCDA) to identify novel circRNA-disease associations based on network consistency projection. For starters, we make use of multi-view similarity data, including circRNA functional similarity, disease semantic similarity, and association profile similarity, to construct the integrated circRNA similarity and disease similarity. Then, we project circRNA space and disease space on the circRNA-disease interaction network, respectively. Finally, we can obtain the predicted circRNA-disease association score matrix by combining the above two space projection scores. Simulation results show that NCPCDA can efficiently infer disease-circRNA relationships with high accuracy, obtaining AUCs of 0.9541 and 0.9201 in leave-one-out cross validation and five-fold cross validation, respectively. Furthermore, case studies also suggest that NCPCDA is promising for discovering new disease-circRNA interactions. The NCPCDA dataset and code, as well as the detailed readme file for our code, can be downloaded from Github (https://github.com/ghli16/NNCPCD)."	github.com/ghli16/NNCPCD	https://github.com/ghli16/NNCPCD/	ghli16	NNCPCD			0	0		renamed	https://github.com/ghli16/NCPCDA/
36531573	07/12/2022	10.1016/j.xops.2022.100195	Ophthalmology science	Association of Environmental Factors with Age-Related Macular Degeneration using the Intelligent Research in Sight Registry.	"Investigate associations of natural environmental exposures with exudative and nonexudative age-related macular degeneration (AMD) across the United States. Database study. Patients aged ? 55 years who were active in the IRIS Registry from 2016 to 2018 were analyzed. Patients were categorized as nonexudative, inactive exudative, and active exudative AMD by International Classification of Diseases 10 Revision and Current Procedural Terminology (CPT) codes. Patients without provider-level ZIP codes matching any ZIP code tabulation area were excluded. Environmental data were obtained from public sources including the US Geological Survey, National Renewable Energy Laboratory, National Oceanic and Atmospheric Administration, and Environmental Protection Agency. Multiple variable, mixed effects logistic regression models with random intercepts per ZIP code tabulation area quantified the association of each environmental variable with any AMD versus non-AMD patients, any exudative AMD versus nonexudative AMD, and active exudative AMD versus inactive exudative and nonexudative AMD using 3 separate models, while adjusting for age, sex, race, insurance type, smoking history, and phakic status. Odds ratios for environmental factors. A total of 9 884 527 patients were included. Elevation, latitude, solar irradiance measured in global horizontal irradiance (GHI) and direct normal irradiance (DNI), temperature and precipitation variables, and pollution variables were included in our models. Statistically significant associations with active exudative AMD were GHI (odds ratio [OR], 3.848; 95% confidence interval [CI] with Bonferroni correction, 1.316-11.250), DNI (OR, 0.581; 95% CI, 0.370-0.913), latitude (OR, 1.110; 95% CI, 1.046-1.178), ozone (OR, 1.014; 95% CI, 1.004-1.025), and nitrogen dioxide (OR, 1.005; 95% CI, 1.000-1.010). The only significant environmental associations with any AMD were inches of snow in the winter (OR, 1.005; 95% CI, 1.001-1.009) and ozone (OR, 1.011; 95% CI, 1.003-1.019). The strongest environmental associations differed between AMD subgroups. The solar variables GHI, DNI, and latitude were significantly associated with active exudative AMD. Two pollutant variables, ozone and nitrogen dioxide, also showed positive associations with AMD. Further studies are warranted to investigate the clinical relevance of these associations. Our curated environmental dataset has been made publicly available at https://github.com/uw-biomedical-ml/AMD_environmental_dataset. "	github.com/uw-biomedical-ml/AMD_environmental_dataset.	https://github.com/uw-biomedical-ml/AMD_environmental_dataset/	uw-biomedical-ml	AMD_environmental_dataset			0	0		repo deleted	
30440487	09/25/2019	10.1109/EMBC.2018.8512305	Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Annual International Conference	A 3D Convolutional Neural Network Framework for Polyp Candidates Detection on the Limited Dataset of CT Colonography.	"Proper training of convolutional neural networks (CNNs) requires annotated training datasets oflarge size, which are not currently available in CT colonography (CTC). In this paper, we propose a well-designed framework to address the challenging problem of data shortage in the training of 3D CNN for the detection of polyp candidates, which is the first and crucial part of the computer-aided diagnosis (CAD) of CTC. Our scheme relies on the following two aspects to reduce overfitting: 1) mass data augmentation, and 2) a flat 3D residual fully convolutional network (FCN). In the first aspect, we utilize extensive rotation, translation, and scaling with continuous value to provide numerous data samples. In the second aspect, we adapt the well-known V-Net to a flat residual FCN to resolve the problem of detection other than segmentation. Our proposed framework does not rely on accurate colon segmentation nor any electrical cleansing of tagged fluid, and experimental results show that it can still achieve high sensitivity with much fewer false positives. Code has been made available at: http://github.com/chenyzstju/ctc_screening_cnn."	github.com/chenyzstju/ctc_screening_cnn.	https://github.com/chenyzstju/ctc_screening_cnn/	chenyzstju	ctc_screening_cnn			0	0		owner deleted	
29659705	09/23/2019	10.1093/bioinformatics/bty220	"Bioinformatics (Oxford, England)"	IRscope: an online program to visualize the junction sites of chloroplast genomes.	"Genome plotting is performed using a wide range of visualizations tools each with emphasis on a different informative dimension of the genome. These tools can provide a deeper insight into the genomic structure of the organism. Here, we announce a new visualization tool that is specifically designed for chloroplast genomes. It allows the users to depict the genetic architecture of up to ten chloroplast genomes in the vicinity of the sites connecting the inverted repeats to the short and long single copy regions. The software and its dependent libraries are fully coded in R and the reflected plot is scaled up to realistic size of nucleotide base pairs in the vicinity of the junction sites. We introduce a website for easier use of the program and R source code of the software to be used in case of preferences to be changed and integrated into personal pipelines. The input of the program is an annotation GenBank (.gb) file, the accession or GI number of the sequence or a DOGMA output file. The software was tested using over a 100 embryophyte chloroplast genomes and in all cases a reliable output was obtained. Source codes and the online suit available at https://irscope.shinyapps.io/irapp/ or https://github.com/Limpfrog/irscope. "	github.com/Limpfrog/irscope.	https://github.com/Limpfrog/irscope/	Limpfrog	irscope			0	0		owner deleted	
32878627	09/15/2020	10.1186/s12967-020-02501-x	Journal of translational medicine	Impact of lockdown on Covid-19 case fatality rate and viral mutations spread in 7 countries in Europe and North America.	"Severe acute respiratory syndrome CoV-2 (SARS-CoV-2) caused the first coronavirus disease 2019 (COVID-19) outbreak in China and has become a public health emergency of international concern. SARS-CoV-2 outbreak has been declared a pandemic by WHO on March 11th, 2020 and the same month several Countries put in place different lockdown restrictions and testing strategies in order to contain the spread of the virus. The calculation of the Case Fatality Rate of SARS-CoV-2 in the Countries selected was made by using the data available at https://github.com/owid/covi-19-data/tree/master/public/data . Case fatality rate was calculated as the ratio between the death cases due to COVID-19, over the total number of SARS-CoV-2 reported cases 14 days before. Standard Case Fatality Rate values were normalized by the Country-specific ? factor, i.e. the number of PCR tests/1 million inhabitants over the number of reported cases/1 million inhabitants. Case-fatality rates between Countries were compared using proportion test. Post-hoc analysis in the case of more than two groups was performed using pairwise comparison of proportions and p value was adjusted using Holm method. We also analyzed 487 genomic sequences from the GISAID database derived from patients infected by SARS-CoV-2 from January 2020 to April 2020 in Italy, Spain, Germany, France, Sweden, UK and USA. SARS-CoV-2 reference genome was obtained from the GenBank database (NC_045512.2). Genomes alignment was performed using Muscle and Jalview software. We, then, calculated the Case Fatality Rate of SARS-CoV-2 in the Countries selected. In this study we analyse how different lockdown strategies and PCR testing capability adopted by Italy, France, Germany, Spain, Sweden, UK and USA have influenced the Case Fatality Rate and the viral mutations spread. We calculated case fatality rates by dividing the death number of a specific day by the number of patients with confirmed COVID-19 infection observed 14 days before and normalized by a ? factor which takes into account the diagnostic PCR testing capability of each Country and the number of positive cases detected. We notice the stabilization of a clear pattern of mutations at sites nt241, nt3037, nt14408 and nt23403. A novel nonsynonymous SARS-CoV-2 mutation in the spike protein (nt24368) has been found in genomes sequenced in Sweden, which enacted a soft lockdown strategy. Strict lockdown strategies together with a wide diagnostic PCR testing of the population were correlated with a relevant decline of the case fatality rate in different Countries. The emergence of specific patterns of mutations concomitant with the decline in case fatality rate needs further confirmation and their biological significance remains unclear. "	github.com/owid/covi-19-data/tree/master/public/data	https://github.com/owid/covi-19-data/tree/master/public/data/	owid	covi-19-data			0	0		wrong link	https://github.com/owid/covid-19-data/
26556385	08/17/2017	10.1093/bioinformatics/btv656	"Bioinformatics (Oxford, England)"	Specific identification and quantification of circular RNAs from sequencing data.	"Circular RNAs (circRNAs) are a poorly characterized class of molecules that have been identified decades ago. Emerging high-throughput sequencing methods as well as first reports on confirmed functions have sparked new interest in this RNA species. However, the computational detection and quantification tools are still limited. We developed the software tandem, DCC and CircTest DCC uses output from the STAR read mapper to systematically detect back-splice junctions in next-generation sequencing data. DCC applies a series of filters and integrates data across replicate sets to arrive at a precise list of circRNA candidates. We assessed the detection performance of DCC on a newly generated mouse brain data set and publicly available sequencing data. Our software achieves a much higher precision than state-of-the-art competitors at similar sensitivity levels. Moreover, DCC estimates circRNA versus host gene expression from counting junction and non-junction reads. These read counts are finally used to test for host gene-independence of circRNA expression across different experimental conditions by our R package CircTest We demonstrate the benefits of this approach on previously reported age-dependent circRNAs in the fruit fly. The source code of DCC and CircTest is licensed under the GNU General Public Licence (GPL) version 3 and available from https://github.com/dieterich-lab/[DCC or CircTest]. christoph.dieterich@age.mpg.de Supplementary data are available at Bioinformatics online. "	github.com/dieterich-lab/[DCC	https://github.com/dieterich-lab/[DCC/	dieterich-lab	[DCC			0	0		wrong link	https://github.com/dieterich-lab/DCC/
36623451	02/07/2023	10.1016/j.compmedimag.2023.102183	Computerized medical imaging and graphics : the official journal of the Computerized Medical Imaging Society	SCCNet: Self-correction boundary preservation with a dynamic class prior filter for high-variability ultrasound image segmentation.	"The highly ambiguous nature of boundaries and similar objects is difficult to address in some ultrasound image segmentation tasks, such as neck muscle segmentation, leading to unsatisfactory performance. Thus, this paper proposes a two-stage network called SCCNet (self-correction context network) using a self-correction boundary preservation module and class-context filter to alleviate these problems. The proposed self-correction boundary preservation module uses a dynamic key boundary point (KBP) map to increase the capability of iteratively discriminating ambiguous boundary points segments, and the predicted segmentation map from one stage is used to obtain a dynamic class prior filter to improve the segmentation performance at Stage 2. Finally, three datasets, Neck Muscle, CAMUS and Thyroid, are used to demonstrate that our proposed SCCNet outperforms other state-of-the art methods, such as BPBnet, DSNnet, and RAGCnet. Our proposed network shows at least a 1.2-3.7% improvement on the three datasets, Neck Muscle, Thyroid, and CAMUS. The source code is available at https://github.com/lijixing0425/SCCNet."	github.com/lijixing0425/SCCNet.	https://github.com/lijixing0425/SCCNet/	lijixing0425	SCCNet			0	0		repo deleted	
35030497	03/17/2022	10.1016/j.compbiomed.2022.105216	Computers in biology and medicine	DFpin: Deep learning-based protein-binding site prediction with feature-based non-redundancy from RNA level.	"The interaction between proteins and RNA is closely related to various human diseases. Computer-aided drug design can be facilitated by detecting the RNA sites that bind proteins. However, due to the aggregation of binding sites in RNA sequences, high sample similarity occurs when extracting RNA fragments by using a sliding window. Considering these problems, we present a method, DFpin, to predict protein-interacting nucleotides in RNA. To retain more key nucleotide sites, we used the redundancy method based on feature similarity, that is, feature redundancy is removed based on the RNA mono-nucleotide composition to maintain the diversity of RNA samples and avoid the residue of redundant data. In addition, to extract key abstract features and avoid over-?tting, we used the cascade structure of a deep forest model to predict protein-interacting nucleotides. Overall, DFpin demonstrated excellent classi?cation with 85.4% accuracy and 93.3% area under the curve. Compared with other methods, the accuracy of DFpin was better, suggesting that feature-based redundancy removal and deep forest can help predict nucleotides of protein interactions. The source code and all dataset are available at: https://github.com/zhaoxj-tech/DFpin.git."	github.com/zhaoxj-tech/DFpin.git.	https://github.com/zhaoxj-tech/DFpin/	zhaoxj-tech	DFpin			0	0		repo deleted	
30544729	02/12/2019	10.3390/molecules23123260	"Molecules (Basel, Switzerland)"	SumSec: Accurate Prediction of Sumoylation Sites Using Predicted Secondary Structure.	"Post Translational Modification (PTM) is defined as the modification of amino acids along the protein sequences after the translation process. These modifications significantly impact on the functioning of proteins. Therefore, having a comprehensive understanding of the underlying mechanism of PTMs turns out to be critical in studying the biological roles of proteins. Among a wide range of PTMs, sumoylation is one of the most important modifications due to its known cellular functions which include transcriptional regulation, protein stability, and protein subcellular localization. Despite its importance, determining sumoylation sites via experimental methods is time-consuming and costly. This has led to a great demand for the development of fast computational methods able to accurately determine sumoylation sites in proteins. In this study, we present a new machine learning-based method for predicting sumoylation sites called SumSec. To do this, we employed the predicted secondary structure of amino acids to extract two types of structural features from neighboring amino acids along the protein sequence which has never been used for this task. As a result, our proposed method is able to enhance the sumoylation site prediction task, outperforming previously proposed methods in the literature. SumSec demonstrated high sensitivity (0.91), accuracy (0.94) and MCC (0.88). The prediction accuracy achieved in this study is 21% better than those reported in previous studies. The script and extracted features are publicly available at: https://github.com/YosvanyLopez/SumSec."	github.com/YosvanyLopez/SumSec.	https://github.com/YosvanyLopez/SumSec/	YosvanyLopez	SumSec			0	0		repo deleted	
37015650	12/30/2022	10.1109/TPAMI.2022.3232854	IEEE transactions on pattern analysis and machine intelligence	WebUAV-3 M: A Benchmark for Unveiling the Power of Million-Scale Deep UAV Tracking.	"Unmanned aerial vehicle (UAV) tracking is of great significance for a wide range of applications, such as delivery and agriculture. Previous benchmarks in this area mainly focused on small-scale tracking problems while ignoring the amounts of data, types of data modalities, diversities of target categories and scenarios, and evaluation protocols involved, greatly hiding the massive power of deep UAV tracking. In this work, we propose WebUAV-3 M, the largest public UAV tracking benchmark to date, to facilitate both the development and evaluation of deep UAV trackers. WebUAV-3 M contains over 3.3 million frames across 4,500 videos and offers 223 highly diverse target categories. Each video is densely annotated with bounding boxes by an efficient and scalable semi-automatic target annotation (SATA) pipeline. Importantly, to take advantage of the complementary superiority of language and audio, we enrich WebUAV-3 M by innovatively providing both natural language specifications and audio descriptions. We believe that such additions will greatly boost future research in terms of exploring language features and audio cues for multi-modal UAV tracking. In addition, a fine-grained UAV tracking-under-scenario constraint (UTUSC) evaluation protocol and seven challenging scenario subtest sets are constructed to enable the community to develop, adapt and evaluate various types of advanced trackers. We provide extensive evaluations and detailed analyses of 43 representative trackers and envision future research directions in the field of deep UAV tracking and beyond. The dataset, toolkits, and baseline results are available at https://github.com/983632847/WebUAV-3 M."	github.com/983632847/WebUAV-3\xa0M.	https://github.com/983632847/WebUAV-3\xa0M/	983632847	WebUAV-3\xa0M			0	0		wrong link	https://github.com/983632847/WebUAV-3M/
33003206	11/18/2021	10.1093/bib/bbaa216	Briefings in bioinformatics	A spectral clustering with self-weighted multiple kernel learning method for single-cell RNA-seq data.	"Single-cell RNA-sequencing (scRNA-seq) data widely exist in bioinformatics. It is crucial to devise a distance metric for scRNA-seq data. Almost all existing clustering methods based on spectral clustering algorithms work in three separate steps: similarity graph construction; continuous labels learning; discretization of the learned labels by k-means clustering. However, this common practice has potential flaws that may lead to severe information loss and degradation of performance. Furthermore, the performance of a kernel method is largely determined by the selected kernel; a self-weighted multiple kernel learning model can help choose the most suitable kernel for scRNA-seq data. To this end, we propose to automatically learn similarity information from data. We present a new clustering method in the form of a multiple kernel combination that can directly discover groupings in scRNA-seq data. The main proposition is that automatically learned similarity information from scRNA-seq data is used to transform the candidate solution into a new solution that better approximates the discrete one. The proposed model can be efficiently solved by the standard support vector machine (SVM) solvers. Experiments on benchmark scRNA-Seq data validate the superior performance of the proposed model. Spectral clustering with multiple kernels is implemented in Matlab, licensed under Massachusetts Institute of Technology (MIT) and freely available from the Github website, https://github.com/Cuteu/SMSC/."	github.com/Cuteu/SMSC/.	https://github.com/Cuteu/SMSC/	Cuteu	SMSC			0	1	02/01/2023	repo deleted	
35446776	08/15/2022	10.1109/JBHI.2022.3169425	IEEE journal of biomedical and health informatics	Automatic Coronary Artery Segmentation of CCTA Images With an Efficient Feature-Fusion-and-Rectification 3D-UNet.	"Automatic coronary artery segmentation is of great value in diagnosing coronary disease. In this paper, we propose an automatic coronary artery segmentation method for coronary computerized tomography angiography (CCTA) images based on a deep convolutional neural network. The proposed method consists of three steps. First, to improve the efficiency and effectiveness of the segmentation, a 2D DenseNet classification network is utilized to screen out the non-coronary-artery slices. Second, we propose a coronary artery segmentation network based on the 3D-UNet, which is capable of extracting, fusing and rectifying features efficiently for accurate coronary artery segmentation. Specifically, in the encoding process of the 3D-UNet network, we adapt the dense block into the 3D-UNet so that it can extract rich and representative features for coronary artery segmentation; In the decoding process, 3D residual blocks with feature rectification capability are applied to improve the segmentation quality further. Third, we introduce a Gaussian weighting method to obtain the final segmentation results. This operation can highlight the more reliable segmentation results at the center of the 3D data blocks while weakening the less reliable segmentations at the block boundary when merging the segmentation results of spatially overlapping data blocks. Experiments demonstrate that our proposed method achieves a Dice Similarity Coefficient (DSC) value of 0.826 on a CCTA dataset constructed by us. The code of the proposed method is available at https://github.com/alongsong/3D_CAS."	github.com/alongsong/3D_CAS.	https://github.com/alongsong/3D_CAS/	alongsong	3D_CAS			0	0		repo deleted	
30768159	07/12/2021	10.1093/bioinformatics/btz095	"Bioinformatics (Oxford, England)"	Dhaka: variational autoencoder for unmasking tumor heterogeneity from single cell genomic data.	"Intra-tumor heterogeneity is one of the key confounding factors in deciphering tumor evolution. Malignant cells exhibit variations in their gene expression, copy numbers and mutation even when originating from a single progenitor cell. Single cell sequencing of tumor cells has recently emerged as a viable option for unmasking the underlying tumor heterogeneity. However, extracting features from single cell genomic data in order to infer their evolutionary trajectory remains computationally challenging due to the extremely noisy and sparse nature of the data. Here we describe 'Dhaka', a variational autoencoder method which transforms single cell genomic data to a reduced dimension feature space that is more efficient in differentiating between (hidden) tumor subpopulations. Our method is general and can be applied to several different types of genomic data including copy number variation from scDNA-Seq and gene expression from scRNA-Seq experiments. We tested the method on synthetic and six single cell cancer datasets where the number of cells ranges from 250 to 6000 for each sample. Analysis of the resulting feature space revealed subpopulations of cells and their marker genes. The features are also able to infer the lineage and/or differentiation trajectory between cells greatly improving upon prior methods suggested for feature extraction and dimensionality reduction of such data. All the datasets used in the paper are publicly available and developed software package and supporting info is available on Github https://github.com/MicrosoftGenomics/Dhaka. Supplementary data are available at Bioinformatics online. "	github.com/MicrosoftGenomics/Dhaka.	https://github.com/MicrosoftGenomics/Dhaka/	MicrosoftGenomics	Dhaka			0	1	01/02/2021	owner deleted	
33892388	10/25/2021	10.1016/j.compmedimag.2021.101912	Computerized medical imaging and graphics : the official journal of the Computerized Medical Imaging Society	A benchmark bone marrow aspirate smear dataset and a multi-scale cell detection model for the diagnosis of hematological disorders.	"Research on pathological diagnosis of hematopoietic disorders based on bone marrow aspirate smear images has attracted more and more attention with the development of deep learning methods. However, high quality bone marrow aspirate smear image datasets are not readily available because of the time, the efforts, and the medical knowledge required in the acquisition and manual annotation images. In order to facilitate the research of automated diagnosis of hematological disorders, we constructed a high quality Bone Marrow Aspirate Smear Image Dataset (BMASID), which contains 230 bone marrow aspirate smear images, all with the corresponding labeled images. We used additional clinical images as testing data, which are more challenging because of image noise, cell overlap, cell adhesion, blurred borders of cells and ambiguous types of cells. We also proposed a Cell Recognition Network (CRNet) that was trained on this benchmark dataset. CRNet is comprised of a cell detector to locate and recognize cells in the bone marrow aspirate images, and a cell classifier to classify the types of cells. New anchors and novel evaluation metrics are proposed and applied in CRNet. Benchmark evaluations of the proposed CRNet demonstrated the satisfactory performance of our state-of-the-art methods. Experimental results show that the detection precision by detector is more than 83%, and it is better when compared with other detection methods. After the cell type confirmation by the cell classifier, the precision is more than 95%. Compared with the most popular evaluation metrics Intersection over Union (IoU) and the newly proposed Generalized Intersection over Union (GIoU) used in the object detection benchmarks, our evaluation metrics are more suitable for the cell detection task with ambiguous cell boundaries. The proposed bone marrow aspirate smear image dataset and the proposed evaluation metrics can be used in the training and the evaluation of cell detection models, which contributes to future research in the pathological analysis and auxiliary diagnostic methods of hematological disorders. The codes are available at: https://github.com/SuJie-Med/hematolgical-disorders."	github.com/SuJie-Med/hematolgical-disorders.	https://github.com/SuJie-Med/hematolgical-disorders/	SuJie-Med	hematolgical-disorders			0	0		repo deleted	
31943015	04/27/2021	10.1093/ije/dyz244	International journal of epidemiology	EpiMetal: an open-source graphical web browser tool for easy statistical analyses in epidemiology and metabolomics.	"An intuitive graphical interface that allows statistical analyses and visualizations of extensive data without any knowledge of dedicated statistical software or programming. EpiMetal is a single-page web application written in JavaScript, to be used via a modern desktop web browser. Standard epidemiological analyses and self-organizing maps for data-driven metabolic profiling are included. Multiple extensive datasets with an arbitrary number of continuous and category variables can be integrated with the software. Any snapshot of the analyses can be saved and shared with others via a www-link. We demonstrate the usage of EpiMetal using pilot data with over 500 quantitative molecular measures for each sample as well as in two large-scale epidemiological cohorts (N?>10 000). The software usage exemplar and the pilot data are open access online at [http://EpiMetal.computationalmedicine.fi]. MIT licensed source code is available at the Github repository at [https://github.com/amergin/epimetal]. "	github.com/amergin/epimetal].	https://github.com/amergin/epimetal]/	amergin	epimetal]			0	0		wrong link	https://github.com/amergin/epimetal/
34048986	09/16/2021	10.1016/j.compbiolchem.2021.107518	Computational biology and chemistry	FPDock: Protein-protein docking using flower pollination algorithm.	"Proteins play their vital role in biological systems through interaction and complex formation with other biological molecules. Indeed, abnormalities in the interaction patterns affect the proteins' structure and have detrimental effects on living organisms. Research in structure prediction gains its gravity as the functions of proteins depend on their structures. Protein-protein docking is one of the computational methods devised to understand the interaction between proteins. Metaheuristic algorithms are promising to use owing to the hardness of the structure prediction problem. In this paper, a variant of the Flower Pollination Algorithm (FPA) is applied to get an accurate protein-protein complex structure. The algorithm begins execution from a randomly generated initial population, which gets flourished in different isolated islands, trying to find their local optimum. The abiotic and biotic pollination applied in different generations brings diversity and intensity to the solutions. Each round of pollination applies an energy-based scoring function whose value influences the choice to accept a new solution. Analysis of final predictions based on CAPRI quality criteria shows that the proposed method has a success rate of 58% in top10 ranks, which in comparison with other methods like SwarmDock, pyDock, ZDOCK is better. Source code of the work is available at: https://github.com/Sharon1989Sunny/_FPDock_."	github.com/Sharon1989Sunny/_FPDock_.	https://github.com/Sharon1989Sunny/_FPDock_/	Sharon1989Sunny	_FPDock_			0	1	04/19/2023	repo deleted	
30403647	11/05/2018	10.1109/TCYB.2018.2876511	IEEE transactions on cybernetics	Text Image Deblurring Using Kernel Sparsity Prior.	"Previous methods on text image motion deblurring seldom consider the sparse characteristics of the blur kernel. This paper proposes a new text image motion deblurring method by exploiting the sparse properties of both text image itself and kernel. It incorporates the L  -norm for regularizing the blur kernel in the deblurring model, besides the L  sparse priors for the text image and its gradient. Such a L  -norm-based model is efficiently optimized by half-quadratic splitting coupled with the fast conjugate descent method. To further improve the quality of the recovered kernel, a structure-preserving kernel denoising method is also developed to filter out the noisy pixels, yielding a clean kernel curve. Experimental results show the superiority of the proposed method. The source code and results are available at: https://github.com/shenjianbing/text-image-deblur. "	github.com/shenjianbing/text-image-deblur.	https://github.com/shenjianbing/text-image-deblur/	shenjianbing	text-image-deblur			0	0		repo deleted	
31350559	09/17/2020	10.1093/bioinformatics/btz585	"Bioinformatics (Oxford, England)"	THETA: a new genotypic approach for predicting HIV-1 CRF02-AG coreceptor usage.	"The circulating recombinant form of HIV-1 CRF02-AG is the most frequent non-B subtype in Europe. Anti-HIV therapy and pathophysiological studies on the impact of HIV-1 tropism require genotypic determination of HIV-1 tropism for non-B subtypes. But genotypic approaches based on analysis of the V3 envelope region perform poorly when used to determine the tropism of CRF02-AG. We, therefore, designed an algorithm based on information from the gp120 and gp41 ectodomain that better predicts the tropism of HIV-1 subtype CRF02-AG. We used a bio-statistical method to identify the genotypic determinants of CRF02-AG coreceptor use. Toulouse HIV Extended Tropism Algorithm (THETA), based on a Least Absolute Shrinkage and Selection Operator method, uses HIV envelope sequence from phenotypically characterized clones. Prediction of R5X4/X4 viruses was 86% sensitive and that of R5 viruses was 89% specific with our model. The overall accuracy of THETA was 88%, making it sufficiently reliable for predicting the tropism of subtype CRF02-AG sequences. Binaries are freely available for download at https://github.com/viro-tls/THETA. It was implemented in Matlab and supported on MS Windows platform. The sequence data used in this work are available from GenBank under the accession numbers MK618182-MK618417. "	github.com/viro-tls/THETA.	https://github.com/viro-tls/THETA/	viro-tls	THETA			0	1	06/12/2020	repo deleted	
32356764	09/24/2021	10.1109/JBHI.2020.2991172	IEEE journal of biomedical and health informatics	SCCLRR: A Robust Computational Method for Accurate Clustering Single Cell RNA-Seq Data.	"Single-cell RNA transcriptome data present a tremendous opportunity for studying the cellular heterogeneity. Identifying subpopulations based on scRNA-seq data is a hot topic in recent years, although many researchers have been focused on designing elegant computational methods for identifying new cell types; however, the performance of these methods is still unsatisfactory due to the high dimensionality, sparsity and noise of scRNA-seq data. In this study, we propose a new cell type detection method by learning a robust and accurate similarity matrix, named SCCLRR. The method simultaneously captures both global and local intrinsic properties of data based on a low rank representation (LRR) framework mathematical model. The integrated normalized Euclidean distance and cosine similarity are used to balance the intrinsic linear and nonlinear manifold of data in the local regularization term. To solve the non-convex optimization model, we present an iterative optimization procedure using the alternating direction method of multipliers (ADMM) algorithm. We evaluate the performance of the SCCLRR method on nine real scRNA-seq datasets and compare it with seven state-of-the-art methods. The simulation results show that the SCCLRR outperforms other methods and is robust and effective for clustering scRNA-seq data. (The code of SCCLRR is free available for academic https://github.com/wzhangwhu/SCCLRR)."	github.com/wzhangwhu/SCCLRR	https://github.com/wzhangwhu/SCCLRR/	wzhangwhu	SCCLRR			0	1	03/06/2023	repo deleted	
31681437	10/17/2019	10.3389/fgene.2019.01022	Frontiers in genetics	Embracing Ambiguity in the Taxonomic Classification of Microbiome Sequencing Data.	"The advent of high throughput sequencing has enabled in-depth characterization of human and environmental microbiomes. Determining the taxonomic origin of microbial sequences is one of the first, and frequently only, analysis performed on microbiome samples. Substantial research has focused on the development of methods for taxonomic annotation, often making trade-offs in computational efficiency and classification accuracy. A side-effect of these efforts has been a reexamination of the bacterial taxonomy itself. Taxonomies developed prior to the genomic revolution captured complex relationships between organisms that went beyond uniform taxonomic levels such as species, genus, and family. Driven in part by the need to simplify computational workflows, the bacterial taxonomies used most commonly today have been regularized to fit within a standard seven taxonomic levels. Consequently, modern analyses of microbial communities are relatively coarse-grained. Few methods make classifications below the genus level, impacting our ability to capture biologically relevant signals. Here, we present ATLAS, a novel strategy for taxonomic annotation that uses significant outliers within database search results to group sequences in the database into partitions. These partitions capture the extent of taxonomic ambiguity within the classification of a sample. The ATLAS pipeline can be found on GitHub [https://github.com/shahnidhi/outlier_in_BLAST_hits]. We demonstrate that ATLAS provides similar annotations to phylogenetic placement methods, but with higher computational efficiency. When applied to human microbiome data, ATLAS is able to identify previously characterized taxonomic groupings, such as those in the class  and the genus . Furthermore, the majority of partitions identified by ATLAS are at the subgenus level, replacing higher-level annotations with specific groups of species. These more precise partitions improve our detection power in determining differential abundance in microbiome association studies. "	github.com/shahnidhi/outlier_in_BLAST_hits].	https://github.com/shahnidhi/outlier_in_BLAST_hits]/	shahnidhi	outlier_in_BLAST_hits]			0	0		repo deleted	
34527200	08/31/2021	10.1016/j.csbj.2021.08.044	Computational and structural biotechnology journal	EMCBOW-GPCR: A method for identifying G-protein coupled receptors based on word embedding and wordbooks.	"G Protein-Coupled Receptors (GPCRs) are one of the largest membrane protein receptor family in human, which are also important targets for many drugs. Thence, it's of great significance to judge whether a protein is a GPCR or not. However, identifying GPCRs by experimental methods is very expensive and time-consuming. As more and more GPCR primary sequences are accumulated, it's feasible to develop a computational model to predict GPCRs precisely and quickly. In this paper, a novel method called EMCBOW-GPCR has been proposed to improve the accuracy of identifying GPCRs based on natural language processing (NLP). For representing GPCRs, three word-embedding models and a bag-of-words model are used to extract original features. Then, the original features are thrown into a Deep-learning algorithm to extract features further and reduce the dimension. Finally, the obtained features are fed into Extreme Gradient Boosting. As shown with the results comparison, the overall prediction metrics of EMCBOW-GPCR are higher than the state of the arts. In order to be convenient for more researchers to use EMCBOW-GPCR, the method and source code have been opened in github, which are available at https://github.com/454170054/EMCBOW-GPCR, and a user-friendly web-server for EMCBOW-GPCR has been established at http://www.jci-bioinfo.cn/emcbowgpcr."	github.com/454170054/EMCBOW-GPCR	https://github.com/454170054/EMCBOW-GPCR/	454170054	EMCBOW-GPCR			0	0		repo deleted	
36713887	12/22/2022	10.1016/j.patcog.2022.109268	Pattern recognition	Invariance encoding in sliced-Wasserstein space for image classification with limited training data.	"Deep convolutional neural networks (CNNs) are broadly considered to be state-of-the-art generic end-to-end image classification systems. However, they are known to underperform when training data are limited and thus require data augmentation strategies that render the method computationally expensive and not always effective. Rather than using a data augmentation strategy to encode invariances as typically done in machine learning, here we propose to mathematically augment a nearest subspace classification model in sliced-Wasserstein space by exploiting certain mathematical properties of the Radon Cumulative Distribution Transform (R-CDT), a recently introduced image transform. We demonstrate that for a particular type of learning problem, our mathematical solution has advantages over data augmentation with deep CNNs in terms of classification accuracy and computational complexity, and is particularly effective under a limited training data setting. The method is simple, effective, computationally efficient, non-iterative, and requires no parameters to be tuned. Python code implementing our method is available at https://github.com/rohdelab/mathematical augmentation. Our method is integrated as a part of the software package PyTransKit, which is available at https://github.com/rohdelab/PyTransKit."	github.com/rohdelab/mathematical	https://github.com/rohdelab/mathematical/	rohdelab	mathematical			0	0		wrong link	https://github.com/rohdelab/mathematical_augmentation/
35713588	09/26/2020	10.1007/978-3-030-60548-3_9	"Domain adaptation and representation transfer, and distributed and collaborative learning : second MICCAI Workshop, DART 2020, and first MICCAI Workshop, DCL 2020, held in conjunction with MICCAI 2020, Lima, Peru, October 4-8, 2020, Pro..."	Parts2Whole: Self-supervised Contrastive Learning via Reconstruction.	"Contrastive representation learning is the state of the art in computer vision, but requires huge mini-batch sizes, special network design, or memory banks, making it unappealing for 3D medical imaging, while in 3D medical imaging, reconstruction-based self-supervised learning reaches a new height in performance, but lacks mechanisms to learn contrastive representation; therefore, this paper proposes a new framework for self-supervised contrastive learning via reconstruction, called Parts2Whole, because it exploits the  and  part-whole relationship to learn contrastive representation without using contrastive loss: Reconstructing an image (whole) from its own parts compels the model to learn similar latent features for all its own parts, while reconstructing different images (wholes) from their respective parts forces the model to simultaneously push those parts belonging to different wholes farther apart from each other in the latent space; thereby the trained model is capable of distinguishing images. We have evaluated our Parts2Whole on five distinct imaging tasks covering both classification and segmentation, and compared it with four competing publicly available 3D pretrained models, showing that Parts2Whole significantly outperforms in two out of five tasks while achieves competitive performance on the rest three. This superior performance is attributable to the contrastive representations learned with Parts2Whole. Codes and pretrained models are available at github.com/JLiangLab/Parts2Whole. "	github.com/JLiangLab/Parts2Whole.	https://github.com/JLiangLab/Parts2Whole/	JLiangLab	Parts2Whole			0	0		repo deleted	
36434954	12/16/2022	10.1016/j.neunet.2022.10.034	Neural networks : the official journal of the International Neural Network Society	BASeg: Boundary aware semantic segmentation for autonomous driving.	"Semantic segmentation is a critical component for street understanding task in autonomous driving field. Existing various methods either focus on constructing the object's inner consistency by aggregating global or multi-scale context information, or simply combine semantic features with boundary features to refine object details. Despite impressive, most of them neglect the long-range dependences between the inner objects and boundaries. To this end, we present a Boundary Aware Network (BASeg) for semantic segmentation by exploiting boundary information as a significant cue to guide context aggregation. Specifically, a Boundary Refined Module (BRM) is proposed in the BASeg to refine coarse low-level boundary features from a Canny detector by high-level multi-scale semantic features from the backbone, and based on which, the Context Aggregation Module (CAM) is further proposed to capture long-range dependences between the boundary regions and the object inner pixels, achieving mutual gains and enhancing the intra-class consistency. Moreover, our method can be plugged into other CNN backbones for higher performance with a minor computation budget, and obtains 45.72%, 81.2%, and 77.3% of mIoU on the datasets ADE20K, Cityscapes, and CamVid, respectively. Compared with some state-of-the-art ResNet101-based segmentation methods, extensive experiments demonstrate the effectiveness of our method. Our code is available at https://github.com/Lature-Yang/BASeg."	github.com/Lature-Yang/BASeg.	https://github.com/Lature-Yang/BASeg/	Lature-Yang	BASeg			0	0		owner deleted	
28130232	03/26/2018	10.1093/bioinformatics/btx038	"Bioinformatics (Oxford, England)"	ANAQUIN: a software toolkit for the analysis of spike-in controls for next generation sequencing.	"Spike-in controls are synthetic nucleic-acid sequences that are added to a user's sample and constitute internal standards for subsequent steps in the next generation sequencing workflow. : The software is implemented in C?++/R and is freely available under BSD license. The source code is available from github.com/student-t/Anaquin , binaries and user manual from www.sequin.xyz/software and R package from bioconductor.org/packages/Anaquin. anaquin@garvan.org.au or t.mercer@garvan.org.au. Supplementary data are available at Bioinformatics online. "	github.com/student-t/Anaquin	https://github.com/student-t/Anaquin/	student-t	Anaquin			0	1	02/16/2018	repo deleted	
33973997	10/25/2021	10.1093/bioinformatics/btab241	"Bioinformatics (Oxford, England)"	MANIEA: a microbial association network inference method based on improved Eclat association rule mining algorithm.	"Modeling microbiome systems as complex networks are known as the problem of network inference. Microbial association network inference is of great significance in applications on clinical diagnosis, disease treatment, pathological analysis, etc. However, most current network inference methods focus on mining strong pairwise associations between microorganisms, which is defective in reflecting the comprehensive interactive patterns participated by multiple microorganisms. It is also possible that the microorganisms involved in the generated network are not dominant in the microbiome due to the mere focus on the strength of pairwise associations. Some scholars tried to mine comprehensive microbial associations by association rule mining methods, but the adopted algorithms are relatively basic and have severe limitations such as low calculation efficiency, lacking the ability of mining negative correlations and high redundancy in results, making it difficult to mine high-quality microbial association rules and accurately infer microbial association networks. We proposed a microbial association network inference method 'MANIEA' based on the improved Eclat algorithm for mining positive and negative microbial association rules. We also proposed a new method for transforming association rules into microbial association networks, which can effectively demonstrate the co-occurrence and causal correlations in association rules. An experiment was conducted on three authentic microbial abundance datasets to compare the 'MANIEA' with currently popular network inference methods, which demonstrated that the proposed 'MANIEA' show advantages in aspects of correlation forms, computation efficiency, adjustability and network characteristics. The algorithms and data are available at: https://github.com/MaidiL/MANIEA. "	github.com/MaidiL/MANIEA.	https://github.com/MaidiL/MANIEA/	MaidiL	MANIEA			0	1	04/12/2023	repo deleted	
36086223	09/13/2022	10.1109/EMBC48229.2022.9871372	Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Annual International Conference	Data-Efficient Training of Pure Vision Transformers for the Task of Chest X-ray Abnormality Detection Using Knowledge Distillation.	"It is generally believed that vision transformers (ViTs) require a huge amount of data to generalize well, which limits their adoption. The introduction of data-efficient algorithms such as data-efficient image transformers (DeiT) provided an opportunity to explore the application of ViTs in medical imaging, where data scarcity is a limiting factor. In this work, we investigated the possibility of using pure transformers for the task of chest x-ray abnormality detection on a small dataset. Our proposed framework is built on a DeiT structure benefiting from a teacher-student scheme for training, with a DenseNet with strong classification performance as the teacher and an adapted ViT as the student. The results show that the performance of transformers is on par with that of convolutional neural networks (CNNs). We achieved a test accuracy of 92.2% for the task of classifying chest x-ray images (normal/pneumonia/COVID-19) on a carefully selected dataset using pure transformers. The results show the capability of transformers to accompany or replace CNNs for achieving state-of-the-art in medical imaging applications. The code and models of this work are available at https://github.com/Ouantimb-Lab/DeiTCovid."	github.com/Ouantimb-Lab/DeiTCovid.	https://github.com/Ouantimb-Lab/DeiTCovid/	Ouantimb-Lab	DeiTCovid			0	0		owner deleted	
33245108	07/15/2021	10.1093/bioinformatics/btaa993	"Bioinformatics (Oxford, England)"	A span-graph neural model for overlapping entity relation extraction in biomedical texts.	"Entity relation extraction is one of the fundamental tasks in biomedical text mining, which is usually solved by the models from natural language processing. Compared with traditional pipeline methods, joint methods can avoid the error propagation from entity to relation, giving better performances. However, the existing joint models are built upon sequential scheme, and fail to detect overlapping entity and relation, which are ubiquitous in biomedical texts. The main reason is that sequential models have relatively weaker power in capturing long-range dependencies, which results in lower performance in encoding longer sentences. In this article, we propose a novel span-graph neural model for jointly extracting overlapping entity relation in biomedical texts. Our model treats the task as relation triplets prediction, and builds the entity-graph by enumerating possible candidate entity spans. The proposed model captures the relationship between the correlated entities via a span scorer and a relation scorer, respectively, and finally outputs all valid relational triplets. Experimental results on two biomedical entity relation extraction tasks, including drug-drug interaction detection and protein-protein interaction detection, show that the proposed method outperforms previous models by a substantial margin, demonstrating the effectiveness of span-graph-based method for overlapping relation extraction in biomedical texts. Further in-depth analysis proves that our model is more effective in capturing the long-range dependencies for relation extraction compared with the sequential models. Related codes are made publicly available at http://github.com/Baxelyne/SpanBioER. "	github.com/Baxelyne/SpanBioER.	https://github.com/Baxelyne/SpanBioER/	Baxelyne	SpanBioER			0	0		repo deleted	
31536029	09/12/2019	10.1109/TCYB.2019.2936503	IEEE transactions on cybernetics	Visual Object Tracking by Hierarchical Attention Siamese Network.	"Visual tracking addresses the problem of localizing an arbitrary target in video according to the annotated bounding box. In this article, we present a novel tracking method by introducing the attention mechanism into the Siamese network to increase its matching discrimination. We propose a new way to compute attention weights to improve matching performance by a sub-Siamese network [Attention Net (A-Net)], which locates attentive parts for solving the searching problem. In addition, features in higher layers can preserve more semantic information while features in lower layers preserve more location information. Thus, in order to solve the tracking failure cases by the higher layer features, we fully utilize location and semantic information by multilevel features and propose a new way to fuse multiscale response maps from each layer to obtain a more accurate position estimation of the object. We further propose a hierarchical attention Siamese network by combining the attention weights and multilayer integration for tracking. Our method is implemented with a pretrained network which can outperform most well-trained Siamese trackers even without any fine-tuning and online updating. The comparison results with the state-of-the-art methods on popular tracking benchmarks show that our method achieves better performance. Our source code and results will be available at https://github.com/shenjianbing/HASN."	github.com/shenjianbing/HASN.	https://github.com/shenjianbing/HASN/	shenjianbing	HASN			0	0		repo deleted	
29758091	01/25/2019	10.1111/1556-4029.13813	Journal of forensic sciences	Z-Transform Method for Pairwise Osteometric Pair-matching.	"A new pairwise osteometric pair-matching approach based on the Z-transform method is presented. In contrast to previous methods that perform a global t-test on the summed skeletal element pair measurement distances, this approach performs t-tests on each individual distance, facilitating the capture of measurement-specific variation. This new approach is compared to published pairwise sorting methods using a standard reference dataset of postcranial remains maintained by the Defense POW/MIA Accounting Agency. Receiver operating characteristic curve analysis indicates significantly improved performance for the clavicle and radius over all previous methods (p < 0.01). The z-transform method weighted by the effect size outperformed the t-test (Byrd and Adams) and the mean t-test (Lynch) for all elements (p < 0.01). The method performed better than the absolute value t-test (Lynch) for five elements (p < 0.01) and performed at least as well for the remainder. To facilitate usability all methods are available at: https://github.com/spawaskar-cora/z-transform-method."	github.com/spawaskar-cora/z-transform-method.	https://github.com/spawaskar-cora/z-transform-method/	spawaskar-cora	z-transform-method			0	0		repo deleted	
31510665	06/09/2020	10.1093/bioinformatics/btz332	"Bioinformatics (Oxford, England)"	Estimating the predictability of cancer evolution.	"How predictable is the evolution of cancer? This fundamental question is of immense relevance for the diagnosis, prognosis and treatment of cancer. Evolutionary biologists have approached the question of predictability based on the underlying fitness landscape. However, empirical fitness landscapes of tumor cells are impossible to determine in vivo. Thus, in order to quantify the predictability of cancer evolution, alternative approaches are required that circumvent the need for fitness landscapes. We developed a computational method based on conjunctive Bayesian networks (CBNs) to quantify the predictability of cancer evolution directly from mutational data, without the need for measuring or estimating fitness. Using simulated data derived from >200 different fitness landscapes, we show that our CBN-based notion of evolutionary predictability strongly correlates with the classical notion of predictability based on fitness landscapes under the strong selection weak mutation assumption. The statistical framework enables robust and scalable quantification of evolutionary predictability. We applied our approach to driver mutation data from the TCGA and the MSK-IMPACT clinical cohorts to systematically compare the predictability of 15 different cancer types. We found that cancer evolution is remarkably predictable as only a small fraction of evolutionary trajectories are feasible during cancer progression. https://github.com/cbg-ethz/predictability\_of\_cancer\_evolution. Supplementary data are available at Bioinformatics online. "	github.com/cbg-ethz/predictability\\_of\\_cancer\\_evolution.	https://github.com/cbg-ethz/predictability\\_of\\_cancer\\_evolution/	cbg-ethz	predictability\\_of\\_cancer\\_evolution			0	0		wrong link	https://github.com/cbg-ethz/predictability_of_cancer_evolution/
31796388	04/01/2021	10.1109/TPAMI.2019.2956703	IEEE transactions on pattern analysis and machine intelligence	Dynamical Hyperparameter Optimization via Deep Reinforcement Learning in Tracking.	"Hyperparameters are numerical pre-sets whose values are assigned prior to the commencement of a learning process. Selecting appropriate hyperparameters is often critical for achieving satisfactory performance in many vision problems, such as deep learning-based visual object tracking. However, it is often difficult to determine their optimal values, especially if they are specific to each video input. Most hyperparameter optimization algorithms tend to search a generic range and are imposed blindly on all sequences. In this paper, we propose a novel dynamical hyperparameter optimization method that adaptively optimizes hyperparameters for a given sequence using an action-prediction network leveraged on continuous deep Q-learning. Since the observation space for object tracking is significantly more complex than those in traditional control problems, existing continuous deep Q-learning algorithms cannot be directly applied. To overcome this challenge, we introduce an efficient heuristic strategy to handle high dimensional state space, while also accelerating the convergence behavior. The proposed algorithm is applied to improve two representative trackers, a Siamese-based one and a correlation-filter-based one, to evaluate its generalizability. Their superior performances on several popular benchmarks are clearly demonstrated. Our source code is available at https://github.com/shenjianbing/dqltracking."	github.com/shenjianbing/dqltracking.	https://github.com/shenjianbing/dqltracking/	shenjianbing	dqltracking			0	0		repo deleted	
35896914	09/13/2022	10.1007/s11548-022-02715-y	International journal of computer assisted radiology and surgery	Deep-learning-based instrument detection for intra-operative robotic assistance.	"Robotic scrub nurses have the potential to become an attractive solution for the operating room. Surgical instrument detection is a fundamental task for these systems, which is the focus of this work. We address the detection of the complete surgery set for wisdom teeth extraction, and propose a data augmentation technique tailored for this task. Using a robotic scrub nurse system, we create a dataset of 369 unique multi-instrument images with manual annotations. We then propose the Mask-Based Object Insertion method, capable of automatically generating a large amount of synthetic images. By using both real and artificial data, different Mask R-CNN models are trained and evaluated. Our experiments reveal that models trained on the synthetic data created with our method achieve comparable performance to that of models trained on real images. Moreover, we demonstrate that the combination of real and our artificial data can lead to a superior level of generalization. The proposed data augmentation technique is capable of dramatically reducing the labelling work required for training a deep-learning-based detection algorithm. A dataset for the complete instrument set for wisdom teeth extraction is made available for the scientific community, as well as the raw information required for the generation of the synthetic data ( https://github.com/Jorebs/Deep-learning-based-instrument-detection-for-intra operative-robotic-assistance ). "	github.com/Jorebs/Deep-learning-based-instrument-detection-for-intra	https://github.com/Jorebs/Deep-learning-based-instrument-detection-for-intra/	Jorebs	Deep-learning-based-instrument-detection-for-intra			0	0		wrong link	https://github.com/Jorebs/Deep-learning-based-instrument-detection-for-intra-operative-robotic-assistance/
33609108	08/25/2021	10.1093/bioinformatics/btab110	"Bioinformatics (Oxford, England)"	Graph contextualized attention network for predicting synthetic lethality in human cancers.	"Synthetic Lethality (SL) plays an increasingly critical role in the targeted anticancer therapeutics. In addition, identifying SL interactions can create opportunities to selectively kill cancer cells without harming normal cells. Given the high cost of wet-lab experiments, in silico prediction of SL interactions as an alternative can be a rapid and cost-effective way to guide the experimental screening of candidate SL pairs. Several matrix factorization-based methods have recently been proposed for human SL prediction. However, they are limited in capturing the dependencies of neighbors. In addition, it is also highly challenging to make accurate predictions for new genes without any known SL partners. In this work, we propose a novel graph contextualized attention network named GCATSL to learn gene representations for SL prediction. First, we leverage different data sources to construct multiple feature graphs for genes, which serve as the feature inputs for our GCATSL method. Second, for each feature graph, we design node-level attention mechanism to effectively capture the importance of local and global neighbors and learn local and global representations for the nodes, respectively. We further exploit multi-layer perceptron (MLP) to aggregate the original features with the local and global representations and then derive the feature-specific representations. Third, to derive the final representations, we design feature-level attention to integrate feature-specific representations by taking the importance of different feature graphs into account. Extensive experimental results on three datasets under different settings demonstrated that our GCATSL model outperforms 14 state-of-the-art methods consistently. In addition, case studies further validated the effectiveness of our proposed model in identifying novel SL pairs. Python codes and dataset are freely available on GitHub (https://github.com/longyahui/GCATSL) and Zenodo (https://zenodo.org/record/4522679) under the MIT license. Supplementary data are available at Bioinformatics online. "	github.com/longyahui/GCATSL	https://github.com/longyahui/GCATSL/	longyahui	GCATSL			0	1	05/11/2023	repo deleted	
36129860	10/13/2022	10.1109/TIP.2022.3207006	IEEE transactions on image processing : a publication of the IEEE Signal Processing Society	Optimized Dual Fire Attention Network and Medium-Scale Fire Classification Benchmark.	"Vision-based fire detection systems have been significantly improved by deep models; however, higher numbers of false alarms and a slow inference speed still hinder their practical applicability in real-world scenarios. For a balanced trade-off between computational cost and accuracy, we introduce dual fire attention network (DFAN) to achieve effective yet efficient fire detection. The first attention mechanism highlights the most important channels from the features of an existing backbone model, yielding significantly emphasized feature maps. Then, a modified spatial attention mechanism is employed to capture spatial details and enhance the discrimination potential of fire and non-fire objects. We further optimize the DFAN for real-world applications by discarding a significant number of extra parameters using a meta-heuristic approach, which yields around 50% higher FPS values. Finally, we contribute a medium-scale challenging fire classification dataset by considering extremely diverse, highly similar fire/non-fire images and imbalanced classes, among many other complexities. The proposed dataset advances the traditional fire detection datasets by considering multiple classes to answer the following question: what is on fire? We perform experiments on four widely used fire detection datasets, and the DFAN provides the best results compared to 21 state-of-the-art methods. Consequently, our research provides a baseline for fire detection over edge devices with higher accuracy and better FPS values, and the proposed dataset extension provides indoor fire classes and a greater number of outdoor fire classes; these contributions can be used in significant future research. Our codes and dataset will be publicly available at https://github.com/tanveer-hussain/DFAN."	github.com/tanveer-hussain/DFAN.	https://github.com/tanveer-hussain/DFAN/	tanveer-hussain	DFAN			0	0		repo deleted	
34310328	03/14/2022	10.1109/JBHI.2021.3099127	IEEE journal of biomedical and health informatics	NMFLRR: Clustering scRNA-Seq Data by Integrating Nonnegative Matrix Factorization With Low Rank Representation.	"Fast-developing single-cell technologies create unprecedented opportunities to reveal cell heterogeneity and diversity. Accurate classification of single cells is a critical prerequisite for recovering the mechanisms of heterogeneity. However, the scRNA-seq profiles we obtained at present have high dimensionality, sparsity, and noise, which pose challenges for existing clustering methods in grouping cells that belong to the same subpopulation based on transcriptomic profiles. Although many computational methods have been proposed developing novel and effective computational methods to accurately identify cell types remains a considerable challenge. We present a new computational framework to identify cell types by integrating low-rank representation (LRR) and nonnegative matrix factorization (NMF); this framework is named NMFLRR. The LRR captures the global properties of original data by using nuclear norms, and a locality constrained graph regularization term is introduced to characterize the data's local geometric information. The similarity matrix and low-dimensional features of data can be simultaneously obtained by applying the alternating direction method of multipliers (ADMM) algorithm to handle each variable alternatively in an iterative way. We finally obtained the predicted cell types by using a spectral algorithm based on the optimized similarity matrix. Nine real scRNA-seq datasets were used to test the performance of NMFLRR and fifteen other competitive methods, and the accuracy and robustness of the simulation results suggest the NMFLRR is a promising algorithm for the classification of single cells. The simulation code is freely available at: https://github.com/wzhangwhu/NMFLRR_code."	github.com/wzhangwhu/NMFLRR_code.	https://github.com/wzhangwhu/NMFLRR_code/	wzhangwhu	NMFLRR_code			0	0		repo deleted	
32293263	06/08/2020	10.1186/s12859-020-3449-2	BMC bioinformatics	QuaDMutNetEx: a method for detecting cancer driver genes with low mutation frequency.	"Cancer is caused by genetic mutations, but not all somatic mutations in human DNA drive the emergence or growth of cancers. While many frequently-mutated cancer driver genes have already been identified and are being utilized for diagnostic, prognostic, or therapeutic purposes, identifying driver genes that harbor mutations occurring with low frequency in human cancers is an ongoing endeavor. Typically, mutations that do not confer growth advantage to tumors - passenger mutations - dominate the mutation landscape of tumor cell genome, making identification of low-frequency driver mutations a challenge. The leading approach for discovering new putative driver genes involves analyzing patterns of mutations in large cohorts of patients and using statistical methods to discriminate driver from passenger mutations. We propose a novel cancer driver gene detection method, QuaDMutNetEx. QuaDMutNetEx discovers cancer drivers with low mutation frequency by giving preference to genes encoding proteins that are connected in human protein-protein interaction networks, and that at the same time show low deviation from the mutual exclusivity pattern that characterizes driver mutations occurring in the same pathway or functional gene group across a cohort of cancer samples. Evaluation of QuaDMutNetEx on four different tumor sample datasets show that the proposed method finds biologically-connected sets of low-frequency driver genes, including many genes that are not found if the network connectivity information is not considered. Improved quality and interpretability of the discovered putative driver gene sets compared to existing methods shows that QuaDMutNetEx is a valuable new tool for detecting driver genes. QuaDMutNetEx is available for download from https://github.com/bokhariy/QuaDMutNetExunder the GNU GPLv3 license. "	github.com/bokhariy/QuaDMutNetExunder	https://github.com/bokhariy/QuaDMutNetExunder/	bokhariy	QuaDMutNetExunder			0	0		renamed	https://github.com/bokhariy/QuadMutNetEx/
33819146	12/03/2021	10.1109/TBME.2021.3070875	IEEE transactions on bio-medical engineering	Improved Prediction of Cognitive Outcomes via Globally Aligned Imaging Biomarker Enrichments Over Progressions.	"Longitudinal neuroimaging data have been widely used to predict clinical scores for automatic diagnosis of Alzheimer's Disease (AD) in recent years. However, incomplete temporal neuroimaging records of the patients pose a major challenge to use these data for accurately diagnosing AD. In this paper, we propose a novel method to learn an enriched representation for imaging biomarkers, which simultaneously captures the information conveyed by both the baseline neuroimaging records of all the participants in a studied cohort and the progressive variations of the available follow-up records of every individual participant. Taking into account that different participants usually take different numbers of medical records at different time points, we develop a robust learning objective that minimizes the summations of a number of not-squared l-norm distances, which, though, is difficult to efficiently solve in general. Thus we derive a new efficient iterative algorithm with rigorously proved convergence. We have conducted extensive experiments using the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset. Clear performance gains have been achieved when we predict different cognitive scores using the enriched biomarker representations learned by our new method. We further observe that the top selected biomarkers by our proposed method are in perfect accordance with the known knowledge in existing clinical AD studies. All these promising experimental results have demonstrated the effectiveness of our new method. We anticipate that our new method is of interest to biomedical engineering communities beyond AD research and have open-sourced the code of our method online.The code package of this paper have been made publicly available online at https://github.com/lyujian/Improved-Prediction-of-Cognitive-Outcomes. "	github.com/lyujian/Improved-Prediction-of-Cognitive-Outcomes.	https://github.com/lyujian/Improved-Prediction-of-Cognitive-Outcomes/	lyujian	Improved-Prediction-of-Cognitive-Outcomes			0	1	01/22/2023	repo deleted	
31946144	03/12/2020	10.1109/EMBC.2019.8857598	Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Annual International Conference	Protein Subcellular Localization Prediction Based on Internal Micro-similarities of Markov Chains.	"Elucidating protein subcellular localization is an essential topic in proteomics research due to its importance in the process of drug discovery. Unfortunately, experimentally uncovering protein subcellular targets is an arduous process that may not result in a successful localization. In contrast, computational methods can rapidly predict protein subcellular targets and are an efficient alternative to experimental methods for unannotated proteins. In this work, we introduce a new method to predict protein subcellular localization which increases the predictive power of generative probabilistic models while preserving their explanatory benefit. Our method exploits Markov models to produce a feature vector that records micro-similarities between the underlying probability distributions of a given sequence and their counterparts in reference models. Compared to ordinary Markov chain inference, we show that our method improves overall accuracy by 10% under 10-fold cross-validation on a dataset consisting of 10 subcellular locations. The source code is publicly available on https://github.com/aametwally/MC MicroSimilarities."	github.com/aametwally/MC	https://github.com/aametwally/MC/	aametwally	MC			0	0		wrong link	https://github.com/aametwally/MC_MicroSimilarities/
36383500	07/09/2022	10.1007/978-3-031-11203-4_12	"Biomedical image registration : 10th international workshop, WBIR 2022, Munich, Germany, July 10-12, 2022 : proceedings. WBIR (Workshop : 2006- ) (10th : 2022 : Munich, Germany)"	SuperWarp: Supervised Learning and Warping on U-Net for Invariant Subvoxel-Precise Registration.	"In recent years, learning-based image registration methods have gradually moved away from direct supervision with target warps to instead use self-supervision, with excellent results in several registration benchmarks. These approaches utilize a loss function that penalizes the intensity differences between the fixed and moving images, along with a suitable regularizer on the deformation. However, since images typically have large untextured regions, merely maximizing similarity between the two images is not sufficient to recover the true deformation. This problem is exacerbated by texture in other regions, which introduces severe non-convexity into the landscape of the training objective and ultimately leads to overfitting. In this paper, we argue that the relative failure of supervised registration approaches can in part be blamed on the use of regular U-Nets, which are jointly tasked with feature extraction, feature matching and deformation estimation. Here, we introduce a simple but crucial modification to the U-Net that disentangles feature extraction and matching from deformation prediction, allowing the U-Net to warp the features, across levels, as the deformation field is evolved. With this modification, direct supervision using target warps begins to outperform self-supervision approaches that require segmentations, presenting new directions for registration when images do not have segmentations. We hope that our findings in this preliminary workshop paper will re-ignite research interest in supervised image registration techniques. Our code is publicly available from http://github.com/balbasty/superwarp."	github.com/balbasty/superwarp.	https://github.com/balbasty/superwarp/	balbasty	superwarp			0	0		repo deleted	
29293920	07/12/2019	10.1093/bioinformatics/btx837	"Bioinformatics (Oxford, England)"	Towards self-learning based hypotheses generation in biomedical text domain.	"The overwhelming amount of research articles in the domain of bio-medicine might cause important connections to remain unnoticed. Literature Based Discovery is a sub-field within biomedical text mining that peruses these articles to formulate high confident hypotheses on possible connections between medical concepts. Although many alternate methodologies have been proposed over the last decade, they still suffer from scalability issues. The primary reason, apart from the dense inter-connections between biological concepts, is the absence of information on the factors that lead to the edge-formation. In this work, we formulate this problem as a collaborative filtering task and leverage a relatively new concept of word-vectors to learn and mimic the implicit edge-formation process. Along with single-class classifier, we prune the search-space of redundant and irrelevant hypotheses to increase the efficiency of the system and at the same time maintaining and in some cases even boosting the overall accuracy. We show that our proposed framework is able to prune up to 90% of the hypotheses while still retaining high recall in top-K results. This level of efficiency enables the discovery algorithm to look for higher-order hypotheses, something that was infeasible until now. Furthermore, the generic formulation allows our approach to be agile to perform both open and closed discovery. We also experimentally validate that the core data-structures upon which the system bases its decision has a high concordance with the opinion of the experts.This coupled with the ability to understand the edge formation process provides us with interpretable results without any manual intervention. The relevant JAVA codes are available at: https://github.com/vishrawas/Medline-Code_v2. Supplementary data are available at Bioinformatics online. "	github.com/vishrawas/Medline-Code_v2.	https://github.com/vishrawas/Medline-Code_v2/	vishrawas	Medline-Code_v2			0	0		wrong link	https://github.com/vishrawas/Medline--code_v2/
34396127	05/13/2021	10.1088/2632-2153/abe6d6	Machine learning: science and technology	PASSer: Prediction of Allosteric Sites Server.	"Allostery is considered important in regulating protein's activity. Drug development depends on the understanding of allosteric mechanisms, especially the identification of allosteric sites, which is a prerequisite in drug discovery and design. Many computational methods have been developed for allosteric site prediction using pocket features and protein dynamics. Here, we present an ensemble learning method, consisting of eXtreme gradient boosting (XGBoost) and graph convolutional neural network (GCNN), to predict allosteric sites. Our model can learn physical properties and topology without any  information, and shows good performance under multiple indicators. Prediction results showed that 84.9% of allosteric pockets in the test set appeared in the top 3 positions. The PASSer: Protein Allosteric Sites Server (https://passer.smu.edu), along with a command line interface (CLI, https://github.com/smutaogroup/passerCLI) provide insights for further analysis in drug discovery. "	github.com/smutaogroup/passerCLI	https://github.com/smutaogroup/passerCLI/	smutaogroup	passerCLI			0	1	04/27/2023	repo deleted	
34529576	09/16/2021	10.1109/TNNLS.2021.3107362	IEEE transactions on neural networks and learning systems	DPSNet: Multitask Learning Using Geometry Reasoning for Scene Depth and Semantics.	"Multitask joint learning technology continues gaining more attention as a paradigm shift and has shown promising performance in many applications. Depth estimation and semantic understanding from monocular images emerge as a challenging problem in computer vision. While the other joint learning frameworks establish the relationship between the semantics and depth from stereo pairs, the lack of learning camera motion renders the frameworks that fail to model the geometric structure of the image scene. We make a further step in this article by proposing a multitask learning method, namely DPSNet, which can jointly perform depth and camera pose estimation and semantic scene segmentation. Our core idea for depth and camera pose prediction is that we present the rigid semantic consistency loss to overcome the limitation of moving pixels from image reconstruction technology and further infer the segmentation of moving instances based on them. In addition, our proposed model performs semantic segmentation by reasoning the geometric correspondences between the pixel semantic outputs and the semantic labels at multiscale resolutions. Experiments on open-source datasets and a video dataset captured on a micro-smart car show the effectiveness of each component of DPSNet, and DPSNet achieves state-of-the-art results in all three tasks compared with the best popular methods. All our models and code are available at https://github.com/jn-z/DPSNet: Multitask Learning Using Geometry Reasoning for Scene Depth and semantics."	github.com/jn-z/DPSNet	https://github.com/jn-z/DPSNet/	jn-z	DPSNet			0	0		wrong link	https://github.com/jn-z/DPSNet-Multi-Task-Learning-Using-Geometry-Reasoning-for-Scene-Depth-and-Semantics/
31937236	03/18/2020	10.1186/s12859-019-3316-1	BMC bioinformatics	A pipeline to create predictive functional networks: application to the tumor progression of hepatocellular carcinoma.	"Integrating genome-wide gene expression patient profiles with regulatory knowledge is a challenging task because of the inherent heterogeneity, noise and incompleteness of biological data. From the computational side, several solvers for logic programs are able to perform extremely well in decision problems for combinatorial search domains. The challenge then is how to process the biological knowledge in order to feed these solvers to gain insights in a biological study. It requires formalizing the biological knowledge to give a precise interpretation of this information; currently, very few pathway databases offer this possibility. The presented work proposes an automatic pipeline to extract automatically regulatory knowledge from pathway databases and generate novel computational predictions related to the state of expression or activity of biological molecules. We applied it in the context of hepatocellular carcinoma (HCC) progression, and evaluate the precision and the stability of these computational predictions. Our working base is a graph of 3383 nodes and 13,771 edges extracted from the KEGG database, in which we integrate 209 differentially expressed genes between low and high aggressive HCC across 294 patients. Our computational model predicts the shifts of expression of 146 initially non-observed biological components. Our predictions were validated at 88% using a larger experimental dataset and cross-validation techniques. In particular, we focus on the protein complexes predictions and show for the first time that NFKB1/BCL-3 complexes are activated in aggressive HCC. In spite of the large dimension of the reconstructed models, our analyses over the computational predictions discover a well constrained region where KEGG regulatory knowledge constrains gene expression of several biomolecules. These regions can offer interesting windows to perturb experimentally such complex systems. This new pipeline allows biologists to develop their own predictive models based on a list of genes. It facilitates the identification of new regulatory biomolecules using knowledge graphs and predictive computational methods. Our workflow is implemented in an automatic python pipeline which is publicly available at https://github.com/LokmaneChebouba/key-pipeand contains as testing data all the data used in this paper. "	github.com/LokmaneChebouba/key-pipeand	https://github.com/LokmaneChebouba/key-pipeand/	LokmaneChebouba	key-pipeand			0	0		wrong link	https://github.com/LokmaneChebouba/key-pipe/
35853071	12/06/2022	10.1109/TMI.2022.3192483	IEEE transactions on medical imaging	Personalized Retrogress-Resilient Federated Learning Toward Imbalanced Medical Data.	"Clinically oriented deep learning algorithms, combined with large-scale medical datasets, have significantly promoted computer-aided diagnosis. To address increasing ethical and privacy issues, Federated Learning (FL) adopts a distributed paradigm to collaboratively train models, rather than collecting samples from multiple institutions for centralized training. Despite intensive research on FL, two major challenges are still existing when applying FL in the real-world medical scenarios, including the performance degradation (i.e., retrogress) after each communication and the intractable class imbalance. Thus, in this paper, we propose a novel personalized FL framework to tackle these two problems. For the retrogress problem, we first devise a Progressive Fourier Aggregation (PFA) at the server side to gradually integrate parameters of client models in the frequency domain. Then, at the client side, we design a Deputy-Enhanced Transfer (DET) to smoothly transfer global knowledge to the personalized local model. For the class imbalance problem, we propose the Conjoint Prototype-Aligned (CPA) loss to facilitate the balanced optimization of the FL framework. Considering the inaccessibility of private local data to other participants in FL, the CPA loss calculates the global conjoint objective based on global imbalance, and then adjusts the client-side local training through the prototype-aligned refinement to eliminate the imbalance gap with such a balanced goal. Extensive experiments are performed on real-world dermoscopic and prostate MRI FL datasets. The experimental results demonstrate the advantages of our FL framework in real-world medical scenarios, by outperforming state-of-the-art FL methods with a large margin. The source code is available at https://github.com/CityU-AIM-Group/PRR-Imbalancehttps://github.com/CityU-AIM-Group/PRR-Imbalance."	github.com/CityU-AIM-Group/PRR-Imbalancehttps	https://github.com/CityU-AIM-Group/PRR-Imbalancehttps/	CityU-AIM-Group	PRR-Imbalancehttps			0	0		wrong link	https://github.com/CityU-AIM-Group/PRR-Imbalance/
29040602	10/05/2017	10.1093/ije/dyx204	International journal of epidemiology	Software Application Profile: PHESANT: a tool for performing automated phenome scans in UK Biobank.	"Epidemiological cohorts typically contain a diverse set of phenotypes such that automation of phenome scans is non-trivial, because they require highly heterogeneous models. For this reason, phenome scans have to date tended to use a smaller homogeneous set of phenotypes that can be analysed in a consistent fashion. We present PHESANT (PHEnome Scan ANalysis Tool), a software package for performing comprehensive phenome scans in UK Biobank. PHESANT tests the association of a specified trait with all continuous, integer and categorical variables in UK Biobank, or a specified subset. PHESANT uses a novel rule-based algorithm to determine how to appropriately test each trait, then performs the analyses and produces plots and summary tables. The PHESANT phenome scan is implemented in R. PHESANT includes a novel Javascript D3.js visualization and accompanying Java code that converts the phenome scan results to the required JavaScript Object Notation (JSON) format. PHESANT is available on GitHub at [https://github.com/MRCIEU/PHESANT]. Git tag v0.5 corresponds to the version presented here. "	github.com/MRCIEU/PHESANT].	https://github.com/MRCIEU/PHESANT]/	MRCIEU	PHESANT]			0	0		wrong link	https://github.com/MRCIEU/PHESANT/
32176694	06/29/2020	10.1371/journal.pcbi.1007665	PLoS computational biology	CAncer bioMarker Prediction Pipeline (CAMPP)-A standardized framework for the analysis of quantitative biological data.	"With the improvement of -omics and next-generation sequencing (NGS) methodologies, along with the lowered cost of generating these types of data, the analysis of high-throughput biological data has become standard both for forming and testing biomedical hypotheses. Our knowledge of how to normalize datasets to remove latent undesirable variances has grown extensively, making for standardized data that are easily compared between studies. Here we present the CAncer bioMarker Prediction Pipeline (CAMPP), an open-source R-based wrapper (https://github.com/ELELAB/CAncer-bioMarker-Prediction-Pipeline -CAMPP) intended to aid bioinformatic software-users with data analyses. CAMPP is called from a terminal command line and is supported by a user-friendly manual. The pipeline may be run on a local computer and requires little or no knowledge of programming. To avoid issues relating to R-package updates, a renv .lock file is provided to ensure R-package stability. Data-management includes missing value imputation, data normalization, and distributional checks. CAMPP performs (I) k-means clustering, (II) differential expression/abundance analysis, (III) elastic-net regression, (IV) correlation and co-expression network analyses, (V) survival analysis, and (VI) protein-protein/miRNA-gene interaction networks. The pipeline returns tabular files and graphical representations of the results. We hope that CAMPP will assist in streamlining bioinformatic analysis of quantitative biological data, whilst ensuring an appropriate bio-statistical framework."	github.com/ELELAB/CAncer-bioMarker-Prediction-Pipeline	https://github.com/ELELAB/CAncer-bioMarker-Prediction-Pipeline/	ELELAB	CAncer-bioMarker-Prediction-Pipeline			0	0		wrong link	https://github.com/ELELAB/CAncer-bioMarker-Prediction-Pipeline-CAMPP/
27087308	01/05/2017	10.1093/database/baw051	Database : the journal of biological databases and curation	A crowdsourcing workflow for extracting chemical-induced disease relations from free text.	"Relations between chemicals and diseases are one of the most queried biomedical interactions. Although expert manual curation is the standard method for extracting these relations from the literature, it is expensive and impractical to apply to large numbers of documents, and therefore alternative methods are required. We describe here a crowdsourcing workflow for extracting chemical-induced disease relations from free text as part of the BioCreative V Chemical Disease Relation challenge. Five non-expert workers on the CrowdFlower platform were shown each potential chemical-induced disease relation highlighted in the original source text and asked to make binary judgments about whether the text supported the relation. Worker responses were aggregated through voting, and relations receiving four or more votes were predicted as true. On the official evaluation dataset of 500 PubMed abstracts, the crowd attained a 0.505F-score (0.475 precision, 0.540 recall), with a maximum theoretical recall of 0.751 due to errors with named entity recognition. The total crowdsourcing cost was $1290.67 ($2.58 per abstract) and took a total of 7 h. A qualitative error analysis revealed that 46.66% of sampled errors were due to task limitations and gold standard errors, indicating that performance can still be improved. All code and results are publicly available athttps://github.com/SuLab/crowd_cid_relexDatabase URL:https://github.com/SuLab/crowd_cid_relex."	github.com/SuLab/crowd_cid_relexDatabase	https://github.com/SuLab/crowd_cid_relexDatabase/	SuLab	crowd_cid_relexDatabase			0	0		wrong link	https://github.com/SuLab/crowd_cid_relex/
34481183	10/11/2021	10.1016/j.compbiomed.2021.104778	Computers in biology and medicine	iAtbP-Hyb-EnC: Prediction of antitubercular peptides via heterogeneous feature representation and genetic algorithm based ensemble learning model.	"Tuberculosis (TB) is a worldwide illness caused by the bacteria Mycobacterium tuberculosis. Owing to the high prevalence of multidrug-resistant tuberculosis, numerous traditional strategies for developing novel alternative therapies have been presented. The effectiveness and dependability of these procedures are not always consistent. Peptide-based therapy has recently been regarded as a preferable alternative due to its excellent selectivity in targeting specific cells without affecting the normal cells. However, due to the rapid growth of the peptide samples, predicting TB accurately has become a challenging task. To effectively identify antitubercular peptides, an intelligent and reliable prediction model is indispensable. An ensemble learning approach was used in this study to improve expected results by compensating for the shortcomings of individual classification algorithms. Initially, three distinct representation approaches were used to formulate the training samples: k-space amino acid composition, composite physiochemical properties, and one-hot encoding. The feature vectors of the applied feature extraction methods are then combined to generate a heterogeneous vector. Finally, utilizing individual and heterogeneous vectors, five distinct nature classification models were used to evaluate prediction rates. In addition, a genetic algorithm-based ensemble model was used to improve the suggested model's prediction and training capabilities. Using Training and independent datasets, the proposed ensemble model achieved an accuracy of 94.47% and 92.68%, respectively. It was observed that our proposed ""iAtbP-Hyb-EnC"" model outperformed and reported ~10% highest training accuracy than existing predictors. The ""iAtbP-Hyb-EnC"" model is suggested to be a reliable tool for scientists and might play a valuable role in academic research and drug discovery. The source code and all datasets are publicly available at https://github.com/Farman335/iAtbP-Hyb-EnC."	github.com/Farman335/iAtbP-Hyb-EnC.	https://github.com/Farman335/iAtbP-Hyb-EnC/	Farman335	iAtbP-Hyb-EnC			0	0		repo deleted	
34892526	01/04/2022	10.1109/EMBC46164.2021.9630724	Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Annual International Conference	A canonical visualization tool for SEEG electrodes.	"Stereoencephalographic (SEEG) electrodes are clinically implanted into the brains of patients with refractory epilepsy to locate foci of seizure onset. They are increasingly used in neurophysiology research to determine focal human brain activity in response to tasks or stimuli. Clear visualization of SEEG electrode location with respect to patient anatomy on magnetic resonance image (MRI) scan is vital to neuroscientific understanding. An intuitive way to accomplish this is to plot brain activity and labels at electrode locations on closest MRI slices along the canonical axial, coronal, and sagittal planes. Therefore, we've developed an open-source software tool in Matlab for visualizing SEEG electrode positions, determined from computed tomography (CT), onto canonical planes of resliced brain MRI. The code and graphical user interface are available at: https://github.com/MultimodalNeuroimagingLab/mnl_seegviewClinical Relevance- This tool enables precise communication of SEEG electrode activity and location by visualization on slices of MRI in canonical axial, coronal, and sagittal planes."	github.com/MultimodalNeuroimagingLab/mnl_seegviewClinical	https://github.com/MultimodalNeuroimagingLab/mnl_seegviewClinical/	MultimodalNeuroimagingLab	mnl_seegviewClinical			0	0		wrong link	https://github.com/MultimodalNeuroimagingLab/mnl_seegview/
36525892	01/09/2023	10.1016/j.neunet.2022.11.014	Neural networks : the official journal of the International Neural Network Society	CT-Loc: Cross-domain visual localization with a channel-wise transformer.	"We tackle the cross-domain visual localization problem of estimating camera position and orientation from real images without three-dimensional (3D) spatial mapping or modeling. Recent studies have shown suboptimal performance in this task owing to the photometric and geometric differences between synthetic and real images. In this study, we present a deep learning approach that uses a channel-wise transformer localization (CT-Loc) framework. Inspired by the human behavior of looking for structural landmarks to estimate one's location, CT-Loc encodes the most salient features of task-relevant objects in target scenes. To evaluate the efficacy of the proposed method in a real-world application, we built a complex and large-scale dataset of the interior of the mechanical room during operations and conducted extensive performance comparisons with the publicly available state-of-the-art University of Melbourne Corridor and Virtual KITTI 2 datasets. Compared with the otherwise best-performing BIM-PoseNet indoor camera localization model, our method significantly reduces position and orientation errors through the application of attention weights and saliency maps while also learning only the visual structural patterns (e.g., floors and doors) that are most relevant to localization tasks. Our model successfully ignores uninformative objects. This approach yields higher-level robust camera-pose regression localization results without requiring prebuilt maps. The code is available at https://github.com/kdaeho27/CT-Loc."	github.com/kdaeho27/CT-Loc.	https://github.com/kdaeho27/CT-Loc/	kdaeho27	CT-Loc			0	0		repo deleted	
28267312	02/06/2019	10.1021/acs.analchem.6b03745	Analytical chemistry	Quirks of Error Estimation in Cross-Linking/Mass Spectrometry.	"Cross-linking/mass spectrometry is an increasingly popular approach to obtain structural information on proteins and their complexes in solution. However, methods for error assessment are under current development. We note that false-discovery rates can be estimated at different points during data analysis, and are most relevant for residue or protein pairs. Missing this point led in our example analysis to an actual 8.4% error when 5% error was targeted. In addition, prefiltering of peptide-spectrum matches and of identified peptide pairs substantially improved results. In our example, this prefiltering increased the number of residue pairs (5% FDR) by 33% (n = 108 to n = 144). This number improvement did not come at the expense of reduced accuracy as the added data agreed with an available crystal structure. We provide an open-source tool, xiFDR ( https://github.com/rappsilberlab/xiFDR ), that implements our observations for routine application. Data are available via ProteomeXchange with identifier PXD004749."	github.com/rappsilberlab/xiFDR	https://github.com/rappsilberlab/xiFDR/	rappsilberlab	xiFDR			0	0		owner deleted	
32416316	06/18/2021	10.1016/j.jprot.2020.103820	Journal of proteomics	PB-Net: Automatic peak integration by sequential deep learning for multiple reaction monitoring.	"Mass spectrometry (MS) based proteomics has become an indispensable component of modern molecular and cellular biochemistry analysis. Multiple reaction monitoring (MRM) is one of the most well-established MS techniques for molecule detection and quantification. Despite its wide usage, there lacks an accurate computational framework to analyze MRM data, and expert annotation is often required, especially to perform peak integration. Here we propose a deep learning method PB-Net (Peak Boundary Neural Network), built upon recent advances in sequential neural networks, for fully automatic chromatographic peak integration. To train PB-Net, we generated a large dataset of over 170,000 expert annotated peaks from MS transitions spanning a wide dynamic range, including both peptides and intact glycopeptides. Our model demonstrated outstanding performances on unseen test samples, reaching near-perfect agreement (Pearson's r 0.997) with human annotated ground truth. Systematic evaluations also show that PB-Net is substantially more robust and accurate compared to previous state-of-the-art peak integration software. PB-Net can benefit the wide community of mass spectrometry data analysis, especially in applications involving high-throughput MS experiments. Codes and test data used in this work are available at https://github.com/miaecle/PB-net. SIGNIFICANCE: Human annotations serve an important role in accurate quantification of multiple reaction monitoring (MRM) experiments, though they are costly to collect and limit analysis throughput. In this work we proposed and developed a novel technique for the peak-integration step in MRM, based on recent innovations in sequential deep learning models. We collected in total 170,000 expert-annotated MRM peaks and trained a set of accurate and robust neural networks for the task. Results demonstrated a substantial improvement over the current state-of-the-art software for mass spectrometry analysis and comparable level of accuracy and precision as human annotators."	github.com/miaecle/PB-net.	https://github.com/miaecle/PB-net/	miaecle	PB-net			0	0		repo deleted	
29994594	02/27/2018	10.1109/TCYB.2018.2803217	IEEE transactions on cybernetics	Multiobject Tracking by Submodular Optimization.	"In this paper, we propose a new multiobject visual tracking algorithm by submodular optimization. The proposed algorithm is composed of two main stages. At the first stage, a new selecting strategy of tracklets is proposed to cope with occlusion problem. We generate low-level tracklets using overlap criteria and min-cost flow, respectively, and then integrate them into a candidate tracklets set. In the second stage, we formulate the multiobject tracking problem as the submodular maximization problem subject to related constraints. The submodular function selects the correct tracklets from the candidate set of tracklets to form the object trajectory. Then, we design a connecting process which connects the corresponding trajectories to overcome the occlusion problem. Experimental results demonstrate the effectiveness of our tracking algorithm. Our source code is available at https://github.com/shenjianbing/submodulartrack."	github.com/shenjianbing/submodulartrack.	https://github.com/shenjianbing/submodulartrack/	shenjianbing	submodulartrack			0	0		repo deleted	
31523183	04/13/2020	10.7150/ijbs.32142	International journal of biological sciences	SWPepNovo: An Efficient De Novo Peptide Sequencing Tool for Large-scale MS/MS Spectra Analysis.	"Tandem mass spectrometry (MS/MS)-based de novo peptide sequencing is a powerful method for high-throughput protein analysis. However, the explosively increasing size of MS/MS spectra dataset inevitably and exponentially raises the computational demand of existing de novo peptide sequencing methods, which is an issue urgently to be solved in computational biology. This paper introduces an efficient tool based on SW26010 many-core processor, namely SWPepNovo, to process the large-scale peptide MS/MS spectra using a parallel peptide spectrum matches (PSMs) algorithm. Our design employs a two-level parallelization mechanism: (1) the task-level parallelism between MPEs using MPI based on a data transformation method and a dynamic feedback task scheduling algorithm, (2) the thread-level parallelism across CPEs using asynchronous task transfer and multithreading. Moreover, three optimization strategies, including vectorization, double buffering and memory access optimizations, have been employed to overcome both the compute-bound and the memory-bound bottlenecks in the parallel PSMs algorithm. The results of experiments conducted on multiple spectra datasets demonstrate the performance of SWPepNovo against three state-of-the-art tools for peptide sequencing, including PepNovo+, PEAKS and DeepNovo-DIA. The SWPepNovo also shows high scalability in experiments on extremely large datasets sized up to 11.22 GB. The software and the parameter settings are available at https://github.com/ChuangLi99/SWPepNovo."	github.com/ChuangLi99/SWPepNovo.	https://github.com/ChuangLi99/SWPepNovo/	ChuangLi99	SWPepNovo			0	1	04/06/2020	repo deleted	
34478499	11/25/2021	10.1093/database/baab055	Database : the journal of biological databases and curation	Peptipedia: a user-friendly web application and a comprehensive database for peptide research supported by Machine Learning approach.	"Peptides have attracted attention during the last decades due to their extraordinary therapeutic properties. Different computational tools have been developed to take advantage of existing information, compiling knowledge and making available the information for common users. Nevertheless, most related tools available are not user-friendly, present redundant information, do not clearly display the data, and usually are specific for particular biological activities, not existing so far, an integrated database with consolidated information to help research peptide sequences. To solve these necessities, we developed Peptipedia, a user-friendly web application and comprehensive database to search, characterize and analyse peptide sequences. Our tool integrates the information from 30 previously reported databases with a total of 92?055 amino acid sequences, making it the biggest repository of peptides with recorded activities to date. Furthermore, we make available a variety of bioinformatics services and statistical modules to increase our tool's usability. Moreover, we incorporated a robust assembled binary classification system to predict putative biological activities for peptide sequences. Our tools' significant differences with other existing alternatives become a substantial contribution for developing biotechnological and bioengineering applications for peptides. Peptipedia is available for non-commercial use as an open-access software, licensed under the GNU General Public License, version GPL 3.0. The web platform is publicly available at peptipedia.cl. Database URL: Both the source code and sample data sets are available in the GitHub repository https://github.com/ProteinEngineering-PESB2/peptipedia."	github.com/ProteinEngineering-PESB2/peptipedia.	https://github.com/ProteinEngineering-PESB2/peptipedia/	ProteinEngineering-PESB2	peptipedia			0	0		repo deleted	
33381844	03/08/2021	10.1093/bioinformatics/btaa891	"Bioinformatics (Oxford, England)"	Ensembling graph attention networks for human microbe-drug association prediction.	"Human microbes get closely involved in an extensive variety of complex human diseases and become new drug targets. In silico methods for identifying potential microbe-drug associations provide an effective complement to conventional experimental methods, which can not only benefit screening candidate compounds for drug development but also facilitate novel knowledge discovery for understanding microbe-drug interaction mechanisms. On the other hand, the recent increased availability of accumulated biomedical data for microbes and drugs provides a great opportunity for a machine learning approach to predict microbe-drug associations. We are thus highly motivated to integrate these data sources to improve prediction accuracy. In addition, it is extremely challenging to predict interactions for new drugs or new microbes, which have no existing microbe-drug associations. In this work, we leverage various sources of biomedical information and construct multiple networks (graphs) for microbes and drugs. Then, we develop a novel ensemble framework of graph attention networks with a hierarchical attention mechanism for microbe-drug association prediction from the constructed multiple microbe-drug graphs, denoted as EGATMDA. In particular, for each input graph, we design a graph convolutional network with node-level attention to learn embeddings for nodes (i.e. microbes and drugs). To effectively aggregate node embeddings from multiple input graphs, we implement graph-level attention to learn the importance of different input graphs. Experimental results under different cross-validation settings (e.g. the setting for predicting associations for new drugs) showed that our proposed method outperformed seven state-of-the-art methods. Case studies on predicted microbe-drug associations further demonstrated the effectiveness of our proposed EGATMDA method. Source codes and supplementary materials are available at: https://github.com/longyahui/EGATMDA/. Supplementary data are available at Bioinformatics online. "	github.com/longyahui/EGATMDA/.	https://github.com/longyahui/EGATMDA/	longyahui	EGATMDA			0	1	04/20/2021	repo deleted	
36436356	12/15/2022	10.1016/j.media.2022.102687	Medical image analysis	Information bottleneck-based interpretable multitask network for breast cancer classification and segmentation.	"Breast cancer is one of the most common causes of death among women worldwide. Early signs of breast cancer can be an abnormality depicted on breast images (e.g., mammography or breast ultrasonography). However, reliable interpretation of breast images requires intensive labor and physicians with extensive experience. Deep learning is evolving breast imaging diagnosis by introducing a second opinion to physicians. However, most deep learning-based breast cancer analysis algorithms lack interpretability because of their black box nature, which means that domain experts cannot understand why the algorithms predict a label. In addition, most deep learning algorithms are formulated as a single-task-based model that ignores correlations between different tasks (e.g., tumor classification and segmentation). In this paper, we propose an interpretable multitask information bottleneck network (MIB-Net) to accomplish simultaneous breast tumor classification and segmentation. MIB-Net maximizes the mutual information between the latent representations and class labels while minimizing information shared by the latent representations and inputs. In contrast from existing models, our MIB-Net generates a contribution score map that offers an interpretable aid for physicians to understand the model's decision-making process. In addition, MIB-Net implements multitask learning and further proposes a dual prior knowledge guidance strategy to enhance deep task correlation. Our evaluations are carried out on three breast image datasets in different modalities. Our results show that the proposed framework is not only able to help physicians better understand the model's decisions but also improve breast tumor classification and segmentation accuracy over representative state-of-the-art models. Our code is available at https://github.com/jxw0810/MIB-Net."	github.com/jxw0810/MIB-Net.	https://github.com/jxw0810/MIB-Net/	jxw0810	MIB-Net			0	0		repo deleted	
35964322	08/16/2022	10.31857/S0026898422040139	Molekuliarnaia biologiia	[Analysis of Multiple Protein Alignments Using 3D-Structural Information on the Orientation of Amino Acid Side-Chains].	"Multiple alignment of amino acid sequences of homologous proteins is a key tool in state-of-the-art bioinformatics and evolutionary analysis. Differences in the spatial orientation of amino acid side-chains can predetermine significant functional diversity among members of one superfamily; however, this is usually not taken into account in any way when constructing alignments and during subsequent comparative analysis. First of all, this is due to the limitation of existing algorithms, which are guided by the biochemical similarity of the ""alphabet"" of amino acid substitutions and either do not use information about the 3D-structural organization of proteins at all, or are limited to comparing the backbone only (i.e., the atoms of the main-chain). In this work, for the first time, we introduce new software for a systematic analysis of specific orientations of amino acid side-chains in equivalent positions of homologous protein structures. The program is intended to assist the analysis of protein multiple sequence alignments. The new algorithm, based on the machine learning HDBSCAN method, can identify statistically significant differences in the side-chain orientations and classify them into subfamilies at each position of multiple alignment. The method has been tested on a wide set of real biological data. The results allow us to speak of the specific orientation of amino acid side-chains as a common phenomenon that requires further study and deserves attention in a comparative analysis of functionally diverse protein superfamilies. The software is freely available at https://github.com/LimoninaDaria/Sub-family-Specific-Sidechain-Orientations."	github.com/LimoninaDaria/Sub-family-Specific-Sidechain-Orientations.	https://github.com/LimoninaDaria/Sub-family-Specific-Sidechain-Orientations/	LimoninaDaria	Sub-family-Specific-Sidechain-Orientations			0	0		owner deleted	
35947011	08/10/2022	10.1094/PDIS-06-22-1325-PDN	Plant disease	First report of Impatiens necrotic spot orthotospovirus infecting Tulbaghia violacia Harv. in China.	"Tulbaghia violacea Harv. indigenous to southern African countries, is an herbaceous perennial bulbous plant belonging to the family Amaryllidaceae. It is a popular garden plant in China. This attractive plant is traditionally used as medicine and repellent (Kubec et al. 2002; Moodley et al. 2015). In June 2021, T. violacea plants showing typical tospovirus-like symptoms of chlorotic rings patterns, were found at the campus of Yunnan University of Chinese Medicine (Fig.S1). Disease incidence was about 11.0% during the field survey. Total RNA was extracted from symptomatic leaves of T. violacea plants using the TRIzol reagent (ambio, Carlsbad, CA). Reverse transcription (RT)-PCR was conducted to identify the virus using RNA extract as the template. The degenerate primers (dTospo-F2 and dTospo-R2) (Huang et al. 2018) were used to amplify the conserved regions of the orthotospoviral L RNA sequences. No amplification was obtained from extracts of two asymptomatic plants. The amplicons from four symptomatic samples were cloned into the pMD19-T vector (TaKaRa) and sequenced (three clones for each amplicon) by Tsingke (Shanghai, China). The obtained DNA fragments were determined to be 312 bp. The sequences from four symptomatic samples were identical (GenBank acc.no. OK258285) and shared the highest nucleotide identities (98.0%) with a corresponding sequence of segment L of impatiens necrotic spot virus (INSV) isolated (GQ336991) from Phalaenopsis amabilis in Yunnan province, China. To further confirm the INSV infection to T. violacea, the samples were analyzed with the specific primers for the N, NSs and NSm genes of INSV (Table S1), respectively. Amplicons of the expected size, 789 bp, 1344 bp and 912 bp, were produced, respectively. Amplicons were cloned and sequenced. The 789-bp N (ON529554) and 1344-bp NSs (ON529554) gene sequences had 99.1% and 99.3% nucleotide identities with the corresponding region of previously described INSV Phalenopsis isolate (GQ336989), respectively. The 912-bp NSm (ON529553) gene sequence shared 99.5% nucleotide identity with the corresponding region of INSV Phalenopsis isolate (GQ336990). Metavirome and Sanger sequencing were used to complete the genome of INSV from T. violacea. The leaves of the symptomatic sample were used to construct an rRNA-depleted library using Nextera XT reagents (Illumina, San Diego, CA). The library was subjected to RNA-Seq a NovaSeq 6000 platform (Illumina, San Diego, CA). A total of 33,193,233 quality-filtered reads were obtained using BBMAP (https://github.com/BioInfoTools/BBMapBBMap - Bushnell B. - sourceforge.net/projects/bbmap/). Among 161052 reads mapped to virus sequences, 151407 reads (read ratios 94.0%) were mapped to INSV. Three complete segments of INSV genome were determined to 8,778 nt (L segment, Acc. No. ON529552), 4,958 nt (M segment, Acc. No. ON529553), and 2,983 nt (S segment, Acc. No. ON529554) in length. These segments were validated by RT-PCR and Sanger sequencing. Three segments share nucleotide sequence identities of 99.6%, 99.3% and 98.9% with the L (GQ336991), M (GQ336990) and S segments (GQ336989) of INSV Phalenopsis isolate, respectively. The results of sequence comparisons showed no evidence of reassortment between INSV and another orthotospovirus. There was a report of tomato spotted wilt virus infecting T. violacea in Florida, USA (Dey et al. 2019). No other virus infecting T. violacea was reported. INSV has been reported to infect several economically important crops including Phalenopsis, pepper etc. in China (Chen et al. 2016). INSV-infected T. violacea not only losses landscaping value but also plays an important intermedia host role in the spread of INSV. Additional surveys and evaluation will be needed to understand the potential medicinal effect of this virus on this plant. To our knowledge, this is first report of INSV in T. violacea."	github.com/BioInfoTools/BBMapBBMap\xa0-\xa0Bushnell\xa0B.\xa0-\xa0sourceforge.net/projects/bbmap/	https://github.com/BioInfoTools/BBMapBBMap\xa0-\xa0Bushnell\xa0B.\xa0-\xa0sourceforge.net/projects/bbmap/	BioInfoTools	BBMapBBMap\xa0-\xa0Bushnell\xa0B.\xa0-\xa0sourceforge.net			0	0		wrong link	https://github.com/BioInfoTools/BBMap/
33395989	06/25/2021	10.1016/j.nicl.2020.102499	NeuroImage. Clinical	Progressive multifocal leukoencephalopathy lesion and brain parenchymal segmentation from MRI using serial deep convolutional neural networks.	"Progressive multifocal leukoencephalopathy (PML) is a rare opportunistic brain infection caused by the JC virus and associated with substantial morbidity and mortality. Accurate MRI assessment of PML lesion burden and brain parenchymal atrophy is of decisive value in monitoring the disease course and response to therapy. However, there are currently no validated automatic methods for quantification of PML lesion burden or associated parenchymal volume loss. Furthermore, manual brain or lesion delineations can be tedious, require the use of valuable time resources by radiologists or trained experts, and are often subjective. In this work, we introduce JCnet (named after the causative viral agent), an end-to-end, fully automated method for brain parenchymal and lesion segmentation in PML using consecutive 3D patch-based convolutional neural networks. The network architecture consists of multi-view feature pyramid networks with hierarchical residual learning blocks containing embedded batch normalization and nonlinear activation functions. The feature maps across the bottom-up and top-down pathways of the feature pyramids are merged, and an output probability membership generated through convolutional pathways, thus rendering the method fully convolutional. Our results show that this approach outperforms and improves longitudinal consistency compared to conventional, state-of-the-art methods of healthy brain and multiple sclerosis lesion segmentation, utilized here as comparators given the lack of available methods validated for use in PML. The ability to produce robust and accurate automated measures of brain atrophy and lesion segmentation in PML is not only valuable clinically but holds promise toward including standardized quantitative MRI measures in clinical trials of targeted therapies. Code is available at: https://github.com/omarallouz/JCnet."	github.com/omarallouz/JCnet.	https://github.com/omarallouz/JCnet/	omarallouz	JCnet			0	0		repo deleted	
29994408	01/03/2020	10.1109/JBHI.2018.2852274	IEEE journal of biomedical and health informatics	"Ensemble Prediction of Synergistic Drug Combinations Incorporating Biological, Chemical, Pharmacological, and Network Knowledge."	"Combinatorial therapy may reduce drug side effects and improve drug efficacy, making combination therapy a promising strategy to treat complex diseases. However, in the existing computational methods, the natural properties and network knowledge of drugs have not been adequately and simultaneously considered, making it difficult to identify effective drug combinations. Computational methods that incorporate multiple sources of information (biological, chemical, pharmacological, and network knowledge) offer more opportunities to screen synergistic drug combinations. Therefore, we developed a novel Ensemble Prediction framework of Synergistic Drug Combinations (EPSDC) to accurately and efficiently predict drug combinations by integrating information from multiple-sources. EPSDC constructs feature vector of drug pair by concatenating different types of drug similarities, and then uses these groups in a feature-based base predictor. Next, transductive learning is applied on heterogeneous drug-target networks to achieve a network-based score for the drug pair. Finally, two types of ensemble rules are introduced to combine the feature-based score and the network-based score, and then potential drug combinations are prioritized. To demonstrate the effect of the ensemble rule, comprehensive experiments were conducted to compare single models and ensemble models. The experimental results indicated that our method outperformed the state-of-the-art method in five-fold cross validation and de novo prediction tests on the two benchmark datasets. We further analyzed the effect of maximum length of the meta-path and the impacts of different types of features. Moreover, the practical usefulness of our method was confirmed in the predicted novel drug combinations. The source code of EPSDC is available at https://github.com/KDDing/EPSDC."	github.com/KDDing/EPSDC.	https://github.com/KDDing/EPSDC/	KDDing	EPSDC			0	1	03/18/2020	repo deleted	
31764961	09/16/2020	10.1093/bioinformatics/btz867	"Bioinformatics (Oxford, England)"	"CRISPRitz: rapid, high-throughput and variant-aware in silico off-target site identification for CRISPR genome editing."	"Clustered regularly interspaced short palindromic repeats (CRISPR) technologies allow for facile genomic modification in a site-specific manner. A key step in this process is the in silico design of single guide RNAs to efficiently and specifically target a site of interest. To this end, it is necessary to enumerate all potential off-target sites within a given genome that could be inadvertently altered by nuclease-mediated cleavage. Currently available software for this task is limited by computational efficiency, variant support or annotation, and assessment of the functional impact of potential off-target effects. To overcome these limitations, we have developed CRISPRitz, a suite of software tools to support the design and analysis of CRISPR/CRISPR-associated (Cas) experiments. Using efficient data structures combined with parallel computation, we offer a rapid, reliable, and exhaustive search mechanism to enumerate a comprehensive list of putative off-target sites. As proof-of-principle, we performed a head-to-head comparison with other available tools on several datasets. This analysis highlighted the unique features and superior computational performance of CRISPRitz including support for genomic searching with DNA/RNA bulges and mismatches of arbitrary size as specified by the user as well as consideration of genetic variants (variant-aware). In addition, graphical reports are offered for coding and non-coding regions that annotate the potential impact of putative off-target sites that lie within regions of functional genomic annotation (e.g. insulator and chromatin accessible sites from the ENCyclopedia Of DNA Elements [ENCODE] project). The software is freely available at: https://github.com/pinellolab/CRISPRitzhttps://github.com/InfOmics/CRISPRitz. Supplementary data are available at Bioinformatics online. "	github.com/pinellolab/CRISPRitzhttps	https://github.com/pinellolab/CRISPRitzhttps/	pinellolab	CRISPRitzhttps			0	0		wrong link	https://github.com/pinellolab/CRISPRitz/
29037244	06/18/2018	10.1186/s12967-017-1304-7	Journal of translational medicine	Prediction of microbe-disease association from the integration of neighbor and graph with collaborative recommendation model.	"Accumulating clinical researches have shown that specific microbes with abnormal levels are closely associated with the development of various human diseases. Knowledge of microbe-disease associations can provide valuable insights for complex disease mechanism understanding as well as the prevention, diagnosis and treatment of various diseases. However, little effort has been made to predict microbial candidates for human complex diseases on a large scale. In this work, we developed a new computational model for predicting microbe-disease associations by combining two single recommendation methods. Based on the assumption that functionally similar microbes tend to get involved in the mechanism of similar disease, we adopted neighbor-based collaborative filtering and a graph-based scoring method to compute association possibility of microbe-disease pairs. The promising prediction performance could be attributed to the use of hybrid approach based on two single recommendation methods as well as the introduction of Gaussian kernel-based similarity and symptom-based disease similarity. To evaluate the performance of the proposed model, we implemented leave-one-out and fivefold cross validations on the HMDAD database, which is recently built as the first database collecting experimentally-confirmed microbe-disease associations. As a result, NGRHMDA achieved reliable results with AUCs of 0.9023 ± 0.0031 and 0.9111 in the validation frameworks of fivefold CV and LOOCV. In addition, 78.2% microbe samples and 66.7% disease samples are found to be consistent with the basic assumption of our work that microbes tend to get involved in the similar disease clusters, and vice versa. Compared with other methods, the prediction results yielded by NGRHMDA demonstrate its effective prediction performance for microbe-disease associations. It is anticipated that NGRHMDA can be used as a useful tool to search the most potential microbial candidates for various diseases, and therefore boosts the medical knowledge and drug development. The codes and dataset of our work can be downloaded from https://github.com/yahuang1991/NGRHMDA . "	github.com/yahuang1991/NGRHMDA	https://github.com/yahuang1991/NGRHMDA/	yahuang1991	NGRHMDA			0	0		repo deleted	
32525207	07/05/2021	10.1093/database/baaa041	Database : the journal of biological databases and curation	Identifying main finding sentences in clinical case reports.	"Clinical case reports are the 'eyewitness reports' of medicine and provide a valuable, unique, albeit noisy and underutilized type of evidence. Generally, a case report has a single main finding that represents the reason for writing up the report in the first place. However, no one has previously created an automatic way of identifying main finding sentences in case reports. We previously created a manual corpus of main finding sentences extracted from the abstracts and full text of clinical case reports. Here, we have utilized the corpus to create a machine learning-based model that automatically predicts which sentence(s) from abstracts state the main finding. The model has been evaluated on a separate manual corpus of clinical case reports and found to have good performance. This is a step toward setting up a retrieval system in which, given one case report, one can find other case reports that report the same or very similar main findings. The code and necessary files to run the main finding model can be downloaded from https://github.com/qi29/main_ finding_recognition, released under the Apache License, Version 2.0."	github.com/qi29/main_	https://github.com/qi29/main_/	qi29	main_			0	0		wrong link	https://github.com/qi29/main_finding_recognition/
